{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to scrape articles from one topic\n",
    "def scrape_one_page(topic):\n",
    "    \n",
    "    base_url = 'https://github.com/VincentBanuelos/nba_salary_predictor'\n",
    "    \n",
    "    response = get(base_url + topic)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    project_title = soup.find('a', name='user-content-top')\n",
    "    \n",
    "    summaries = soup.find('div', itemprop='articleBody')\n",
    "    \n",
    "    summary_list = []\n",
    "    \n",
    "    for i in range(len(titles)):\n",
    "        \n",
    "        temp_dict = {}\n",
    "        \n",
    "        temp_dict['project_title'] = project_title.text\n",
    "        \n",
    "        temp_dict['content'] = summaries[i].text\n",
    "        \n",
    "        temp_dict['category'] = topic\n",
    "        \n",
    "        summary_list.append(temp_dict)\n",
    "        \n",
    "    return summary_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com/VincentBanuelos/nba_salary_predictor'\n",
    "\n",
    "response = get(base_url)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "readmebox = soup.find('div', id='readme').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPredicting NBA Salaries using Regression\\nProject Description/Goals:\\nInitial Questions:\\nPlanning:\\nData Dictionary\\nReproduction Requirements:\\nPipeline Conclusions and Takeaways:\\nWrangling Takeaways\\nExploration Summary\\nModeling takeaways\\nConclusion, and Next Steps:\\n\\n\\n\\n\\n\\nREADME.md\\n\\n\\n\\n\\nPredicting NBA Salaries using Regression\\n\\nby: Vincent Banuelos\\n\\n[Project Description/Goals]\\n[Initial Questions]\\n[Planning]\\n[Data Dictionary]\\n[Reproduction Requirements]\\n[Pipeline Takeaways]\\n[Conclusion]\\n\\nProject Description/Goals:\\n\\n\\nUsing both basic stats and advanced stats can I predict an NBA player's salary as well as what which stat(s) are the biggest driver's of an NBA players Salary.\\n\\n\\nThis project runs through the entire Data Science Pipeline using regression models to attmept to predict NBA Players' salaries.\\n\\n\\n[Back to top]\\nInitial Questions:\\n\\nDoes the county a property is located in affect it's log error?\\nDoes the tax variables of a house affect the logerror?\\nDoes the ratio of home sqft to lot sqft affect logerror?\\nDoes the year a house was built affect logerror?\\n\\n[Back to top]\\nPlanning:\\n\\nCreate README.md with data dictionary, project goals, and come up with initial hypotheses.\\nAcquire data from the Basketball Reference website, turn into a CSV and create a function to automate this process.\\nClean and prepare data for the first iteration through the pipeline, MVP preparation. Create a function to automate the process.\\nStore the acquisition and preparation functions in a wrangle.py module function, and prepare data in Final Report Notebook by importing and using the function.\\nClearly define at least two hypotheses, set an alpha, run the statistical tests needed, reject or fail to reject the Null Hypothesis, and document findings and takeaways.\\nEstablish a baseline accuracy and document well.\\nTrain at least 3 different regression models.\\nEvaluate models on train and validate datasets.\\nChoose the model that performs the best and evaluate that single model on the test dataset.\\nDocument conclusions, takeaways, and next steps in the Final Report Notebook.\\n\\n[Back to top]\\nData Dictionary\\n\\n\\n\\nTarget Attribute\\nDefinition\\nData Type\\n\\n\\n\\n\\nsalary\\nThe NBA Player's salary for the 2017-2018 season\\nfloat\\n\\n\\n\\n\\n\\n\\n\\nFeature\\nDefinition\\nData Type\\n\\n\\n\\n\\nage\\nPlayer's Age on Feb 1 of the season\\nfloat\\n\\n\\ngp\\nGames Played in 2017-2018 season\\nfloat\\n\\n\\ngs\\nGames Started in 2017-2018 season\\nfloat\\n\\n\\nmp\\nMinutes Played in 2017-2018 season\\nfloat\\n\\n\\nfg\\nNumber of Field Goals made in 2017-2018 season\\nfloat\\n\\n\\nfga\\nNumber of Field Goals attempted in 2017-2018 season\\nfloat\\n\\n\\n2p\\nNumber of 2-pointers made in 2017-2018 season\\nfloat\\n\\n\\n2pa\\nNumber of 2-pointers attempted in 2017-2018 season\\nfloat\\n\\n\\n3p\\nNumber of 3-pointers made in 2017-2018 season\\nfloat\\n\\n\\n3pa\\nNumber of 3-pointers attempted in 2017-2018 season\\nfloat\\n\\n\\nft\\nNumber of Freethrows made in 2017-2018 season\\nfloat\\n\\n\\nfta\\nNumber of Freethrows attempted in 2017-2018 season\\nfloat\\n\\n\\norb\\nOffensive rebounds per game\\nfloat\\n\\n\\ndrb\\nDefensive rebounds per game\\nfloat\\n\\n\\ntrb\\nTotal rebounds per game\\nfloat\\n\\n\\nast\\nAsists per game\\nfloat\\n\\n\\nstl\\nSteals per game\\nfloat\\n\\n\\nblk\\nBlocks per game\\nfloat\\n\\n\\ntov\\nTurnovers per game\\nfloat\\n\\n\\npf\\nPersonal Fouls per game\\nfloat\\n\\n\\nppg\\nPoints per game\\nfloat\\n\\n\\nfg_pct\\nField Goal Percentage\\nfloat\\n\\n\\n2p_pct\\n2 Point Field Goal Percentage\\nfloat\\n\\n\\n3p_pct\\n3 Point Field Goal Percentage\\nfloat\\n\\n\\nft_pct\\nFreethrow Percentage\\nfloat\\n\\n\\nts_pct\\nTrue Shooting Percentage, True shooting percentage is a measure of shooting efficiency that takes into account field goals, 3-point field goals, and free throws.\\nfloat\\n\\n\\nefg_pct\\nEffective Field Goal Percentage, This statistic adjusts for the fact that a 3-point field goal is worth one more point than a 2-point field goal\\nfloat\\n\\n\\npos\\nPlayer's position\\nobject\\n\\n\\nws\\nWin Shares; an estimate of the number of wins contributed by a player.\\nfloat\\n\\n\\nortg\\nOffensive Rating for players it is points produced per 100 posessions\\nfloat\\n\\n\\ndrtg\\nDefensive Rating for players it is points allowed per 100 posessions.\\nfloat\\n\\n\\nows\\nOffensive Win Shares\\nfloat\\n\\n\\ndws\\nDefensive Win Shares\\nfloat\\n\\n\\nbpm\\nBox Plus/Minus a box score estimate of the points per 100 possessions that a player contributed above a league-average player, translated to an average team.\\nfloat\\n\\n\\nobpm\\nOffensive Box Plus/Minus\\nfloat\\n\\n\\ndbpm\\nOffensive Box Plus/Minus\\nfloat\\n\\n\\nvorp\\nValue Over Replacement Player; a box score estimate of the points per 100 TEAM possessions that a player contributed above a replacement-level (-2.0) player, translated to an average team and prorated to an 82-game season.\\nfloat\\n\\n\\nper\\nPlayer Efficiency Rating; PER sums up all a player's positive accomplishments, subtracts the negative accomplishments, and returns a per-minute rating of a player's performance.\\nfloat\\n\\n\\norb_pct\\nAn estimate of the percentage of available offensive rebounds a player grabbed while they were on the floor\\nfloat\\n\\n\\ndrb_pct\\nAn estimate of the percentage of available defensive rebounds a player grabbed while they were on the floor\\nfloat\\n\\n\\ntrb_pct\\nAn estimate of the percentage of available rebounds a player grabbed while they were on the floor\\nfloat\\n\\n\\nast_pct\\nAssist percentage is an estimate of the percentage of teammate field goals a player assisted while he was on the floor.\\nfloat\\n\\n\\nstl_pct\\nSteal Percentage is an estimate of the percentage of opponent possessions that end with a steal by the player while he was on the floor.\\nfloat\\n\\n\\nblk_pct\\nBlock percentage is an estimate of the percentage of opponent two-point field goal attempts blocked by the player while he was on the floor.\\nfloat\\n\\n\\ntov_pct\\nTurnover percentage is an estimate of turnovers per 100 plays.\\nfloat\\n\\n\\nusg_pct\\nUsage percentage is an estimate of the percentage of team plays used by a player while he was on the floor.\\nfloat\\n\\n\\nabove_avg_scorer\\n1 if a player is above the league average in scoring. 0 if not above average.\\nfloat\\n\\n\\nabove_avg_3ball\\n1 if a player is above the league average in 3pt %. 0 if not above average.\\nfloat\\n\\n\\nabove_avg_ft\\n1 if a player is above the league average in Freethrow %. 0 if not above average.\\nfloat\\n\\n\\nabove_avg_usg_pct\\n1 if a player is above the league average in Usage %. 0 if not above average.\\nfloat\\n\\n\\nC\\n1 if a player is a Center. 0 if not.\\nfloat\\n\\n\\nF\\n1 if a player is a Forward. 0 if not.\\nfloat\\n\\n\\nG\\n1 if a player is a Guard. 0 if not.\\nfloat\\n\\n\\n\\n\\nReproduction Requirements:\\nYou will need your own env.py file with database credentials then follow the steps below:\\n\\nDownload the csv files, allplayers_wrangle.py, model.py, explore.py, and final_report.ipynb files\\nRun the final_report.ipynb notebook\\n\\n[Back to top]\\nPipeline Conclusions and Takeaways:\\nWrangling Takeaways\\n\\nUsing data from basketball reference we pulled in players' statistical and salary data from the 2017-2018 NBA Season.\\nFollowing the Data Acquisition the following preparation work was done to the acquired data:\\n\\nRemoved any players who did have complete statistical lines or salaries from the dataset.\\nCreated features that compare and find players who are above average in a few commonly used stats.\\nFollowing data prepartion, we were left with a dataframe consisting of 415 observations and 55 statistical columns.\\nSplit data into 3 datasets, train, validate and test\\n\\n\\n\\nExploration Summary\\n\\n\\nPlayers with an above avg TS% and PPG DO earn a significantly different salary than then the rest of the league.\\n\\n\\nPlayers with an above avg USG % DO earn a significantly different salary than then the rest of the league.\\n\\n\\nPlayers with an above avg VORP DO earn a significantly different salary than then the rest of the league.\\n\\n\\nWe saw that a position that a player pays does have a impact on their salary.\\n\\n\\nModeling takeaways\\n\\n\\nThe Tweedie Regressor model did the most consistent out of all the models tested and did not overfit.\\n\\n\\nWith the model for all three data sets roughly falling 4-5 million dollars off of a players actual salary.\\n\\n\\n[Back to top]\\nConclusion, and Next Steps:\\n\\n\\nAlthough this number seems far off without context it must be remembered that there are factors at play that simply cannot be measured by statistics alone.\\n\\n\\nFactors such as player popularity in the team's fanbase, a player's potential to improve, the market value of a player with similar skillsets, whether a player is willing to take a pay cut for a better chance at winning, personal achievements by a player such as MVP, ALL-NBA, ALL-DEFENSE, All-Star selections, whether a player has been injured, etc.\\n\\n\\nFor the next steps after this project I would like to incorporate a player's personal achievements into consideration and see how much those achievements affect players' salaries.\\n\\n\\nAs well as pulling in shot chart data that shows a player's shot distribution, seeing as how certain players may perform best in certain roles, such as a spot-up shooter, pick and roll maestro or rollman, etc.\\n\\n\\nWith the NBA being an everchanging league, certain players will fill roles that are seen as better contributors to winning, and thus salaries will continue to fluctuate for players outside or the elite of the elite players.\\n\\n\\nIn conclusion, I believe my models provided a good starting point for giving a player an initial offer based solely on statistics alone.\\n\\n\\n[Back to top]\\n\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readmebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com/VincentBanuelos/nba_salary_predictor'\n",
    "\n",
    "response = get(base_url)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "gl = soup.find_all('span', class_='color-fg-default text-bold mr-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"color-fg-default text-bold mr-1\">Jupyter Notebook</span>,\n",
       " <span class=\"color-fg-default text-bold mr-1\">Python</span>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "gl = soup.find_all('span', class_='color-fg-default text-bold mr-1')\n",
    "for i in gl:\n",
    "    lst.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jupyter Notebook', 'Python']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com/dragonflydb/dragonfly'\n",
    "\n",
    "response = get(base_url)\n",
    "    \n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "gl = soup.find_all('span', class_='color-fg-default text-bold mr-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"color-fg-default text-bold mr-1\">C++</span>,\n",
       " <span class=\"color-fg-default text-bold mr-1\">C</span>,\n",
       " <span class=\"color-fg-default text-bold mr-1\">CMake</span>,\n",
       " <span class=\"color-fg-default text-bold mr-1\">Python</span>,\n",
       " <span class=\"color-fg-default text-bold mr-1\">Shell</span>,\n",
       " <span class=\"color-fg-default text-bold mr-1\">Smarty</span>,\n",
       " <span class=\"color-fg-default text-bold mr-1\">Dockerfile</span>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "gl = soup.find_all('span', class_='color-fg-default text-bold mr-1')\n",
    "for i in gl:\n",
    "    lst.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C++', 'C', 'CMake', 'Python', 'Shell', 'Smarty', 'Dockerfile']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://github.com/VincentBanuelos/nba_salary_predictor','https://github.com/dragonflydb/dragonfly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to collect the information and cache it as a json file\n",
    "def get_readme(article_list):\n",
    "    file = 'readme_s.json'\n",
    "    \n",
    "    if os.path.exists(file):\n",
    "        \n",
    "        with open(file) as f:\n",
    "        \n",
    "            return json.load(f)\n",
    "        \n",
    "    github_info = []\n",
    "\n",
    "    for article in article_list:\n",
    "            \n",
    "        github_dict = {}\n",
    "        \n",
    "        response = get(article)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        github_dict['readme_txt'] = soup.find('div', id='readme').text\n",
    "        \n",
    "        list = []\n",
    "        lang = soup.find_all('span', class_='color-fg-default text-bold mr-1')\n",
    "        for i in lang:\n",
    "            list.append(i.text)\n",
    "\n",
    "        if list[0] == 'Jupyter Notebook':\n",
    "            github_dict['languages'] = list[1]\n",
    "        \n",
    "        else:\n",
    "            github_dict['languages'] = list[0]\n",
    "        \n",
    "        github_info.append(github_dict)\n",
    "\n",
    "        with open(file, 'w') as f:\n",
    "        \n",
    "            json.dump(github_info, f)\n",
    "        \n",
    "    return github_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = {\"https://github.com/search?o=desc&p=12&q=basketball&s=stars&type=Repositories\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(search_result):\n",
    "    file = 'repo_list.json'\n",
    "    \n",
    "    if os.path.exists(file):\n",
    "        \n",
    "        with open(file) as f:\n",
    "        \n",
    "            return json.load(f)\n",
    "        \n",
    "    repo_list = []\n",
    "\n",
    "    for search in search_result:\n",
    "            \n",
    "        search_dict = {}\n",
    "        \n",
    "        response = get(search)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        list = []\n",
    "        repoes = soup.find_all('a', class_='v-align-middle')\n",
    "        for i in repoes:\n",
    "            list.append(i.text)\n",
    "\n",
    "        search_dict['repoes'] = list\n",
    "\n",
    "        repo_list.append(search_dict)\n",
    "\n",
    "        with open(file, 'w') as f:\n",
    "        \n",
    "            json.dump(repo_list, f)\n",
    "        \n",
    "    return repo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'repoes': ['kgilbert-cmu/basketball-gm',\n",
       "   'nlgcat/sport_sett_basketball',\n",
       "   'dimgold/Artificial_Curiosity',\n",
       "   'JKH-HCA2/BasketballRecLeague',\n",
       "   'devinmancuso/nba-start-active-players-bot',\n",
       "   'cryptopunksnotdead/punks.bodies',\n",
       "   'tutsplus/BasketballFreeThrowUnity',\n",
       "   'chrisdesilva/pickup',\n",
       "   'alfremedpal/PandasBasketball',\n",
       "   'chenyukang/Basketball_demo']}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_search_results(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A module for obtaining repo readme and language data from the github API.\n",
    "Before using this module, read through it, and follow the instructions marked\n",
    "TODO.\n",
    "After doing so, run it like this:\n",
    "    python acquire.py\n",
    "To create the `data.json` file that contains the data.\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "\n",
    "from env import github_token, github_username\n",
    "\n",
    "# TODO: Make a github personal access token.\n",
    "#     1. Go here and generate a personal access token: https://github.com/settings/tokens\n",
    "#        You do _not_ need select any scopes, i.e. leave all the checkboxes unchecked\n",
    "#     2. Save it in your env.py file under the variable `github_token`\n",
    "# TODO: Add your github username to your env.py file under the variable `github_username`\n",
    "# TODO: Add more repositories to the `REPOS` list below.\n",
    "\n",
    "REPOS = ['homerchen19/nba-go',\n",
    "   'hegaojian/JetpackMvvm',\n",
    "   'naoyashiga/Dunk',\n",
    "   'chonyy/AI-basketball-analysis',\n",
    "   'hegaojian/WanAndroid',\n",
    "   'bttmly/nba',\n",
    "   'smuyyh/SprintNBA',\n",
    "   'linouk23/NBA-Player-Movements',\n",
    "   'FaridSafi/react-native-basketball',\n",
    "   'TryKickoff/kickoff',\n",
    " 'kshvmdn/nba.js',\n",
    "   'jaebradley/basketball_reference_web_scraper',\n",
    "   'cwendt94/espn-api',\n",
    "   'hegaojian/MvvmHelper',\n",
    "   'zengm-games/zengm',\n",
    "   'jrbadiabo/Bet-on-Sibyl',\n",
    "   'stephanj/basketballVideoAnalysis',\n",
    "   'KengoA/fantasy-basketball',\n",
    "   'vishaalagartha/basketball_reference_scraper',\n",
    "   'neilmj/BasketballData',\n",
    " 'xwjdsh/nba-live',\n",
    "   'neeilan/DeepPlayByPlay',\n",
    "   'lbenz730/ncaahoopR',\n",
    "   'RobRomijnders/RNN_basketball',\n",
    "   'andrewgiessel/basketballcrawler',\n",
    "   'simonefrancia/SpaceJam',\n",
    "   'danchyy/Basketball_Analytics',\n",
    "   'alexnoob/BasketBall-GM-Rosters',\n",
    "   'jbkuczma/NBAreact',\n",
    "   'FranGoitia/basketball_reference',\n",
    " 'rajshah4/NBA_SportVu',\n",
    "   'gmf05/nba',\n",
    "   'FranGoitia/basketball-analytics',\n",
    "   'alexmonti19/dagnet',\n",
    "   'historicalsource/nba-jam',\n",
    "   'browlm13/Basketball-Shot-Detection',\n",
    "   'andrewstellman/pbprdf',\n",
    "   'adeshpande3/March-Madness-2017',\n",
    "   'octonion/basketball',\n",
    "   'skekre98/NBA-Search',\n",
    " 'chonyy/basketball-shot-detection',\n",
    "   'virajsanghvi/d3.basketball-shot-chart',\n",
    "   'OwlTing/AI_basketball_games_video_editor',\n",
    "   'jflancer/bigballR',\n",
    "   'evansloan/sports.py',\n",
    "   'dtarlow/Machine-March-Madness',\n",
    "   'chychen/BasketballGAN',\n",
    "   'skakac/2d-basketball-unity3d',\n",
    "   'VamshiIITBHU14/BasketBallARKit',\n",
    " 'AdaRoseCannon/basketball-demo',\n",
    "   'lbenz730/NCAA_Hoops',\n",
    "   'sportsdataverse/hoopR',\n",
    "   'rtelmore/ballr',\n",
    "   'lbenz730/NCAA_Hoops_Play_By_Play',\n",
    "   'rodzam/ncaab-stats-scraper',\n",
    "   'aoru45/LFFD-Pytorch',\n",
    "   'octonion/basketball-m',\n",
    "   'wcrasta/ESPN-Fantasy-Basketball',\n",
    "   'srlesrle/betting','kjaisingh/march-madness-2019',\n",
    "   'ayushpai/Basketball-Detector',\n",
    "   'BonbonLemon/basketball',\n",
    "   'arbues6/BueStats',\n",
    "   'fivethirtyeight/nba-player-advanced-metrics',\n",
    "   'leerichardson/game_simulation',\n",
    "   'zachwill/ESPN-Basketball',\n",
    "   'lujinzhong/Live_basketball_room',\n",
    "   'rizkyikhwan/miracle-basketball',\n",
    "   'sndmrc/BasketballAnalyzeR',\n",
    "   'sportsdataverse/sportsdataverse-js',\n",
    "   'solmos/eurolig',\n",
    "   'zhaoyu611/basketball_trajectory_prediction',\n",
    "   'basketballrelativity/basketball_data_science',\n",
    "   'ed-word/Activity-Recognition',\n",
    "   'historicalsource/nba-jam-tournament-edition',\n",
    "   'mbjoseph/bbr',\n",
    "   'owenauch/NBA-Fantasy-Optimizer',\n",
    "   'cfahlgren1/Bounce',\n",
    "   'JonnyBurger/basketball-tracker',\n",
    "   'nguyenank/shot-plotter',\n",
    "   'oussamabonnor1/Ball-Fall-game-Unity2D',\n",
    "   'llimllib/ncaa-bracket-randomizer',\n",
    "   'brettfazio/CVBallTracking',\n",
    "   'sunkuo/joi-router',\n",
    "   'hubsif/kodi-magentasport',\n",
    "   'ngbede/hoop',\n",
    "   'liang3472/BasketBall',\n",
    "   'rukmal/Scoreboard',\n",
    "   'imadmali/bball-hmm',\n",
    "    'thunky-monk/kawhi',\n",
    "   'EddM/boxscorereplay',\n",
    "   'elwan9880/Yahoo_fantasy_basketball_analyzer',\n",
    "   'Franpanozzo/nba-api-rest',\n",
    "   'arbues6/Euroleague-ML',\n",
    "   'minimaxir/ncaa-basketball',\n",
    "   'kpascual/basketball-data-scraper',\n",
    "   'gabarlacchi/MASK-CNN-for-actions-recognition-',\n",
    "   'dsscollection/basketball',\n",
    "   'gogonzo/sport',\n",
    "   'kgilbert-cmu/basketball-gm',\n",
    "   'nlgcat/sport_sett_basketball',\n",
    "   'dimgold/Artificial_Curiosity',\n",
    "   'JKH-HCA2/BasketballRecLeague',\n",
    "   'devinmancuso/nba-start-active-players-bot',\n",
    "   'cryptopunksnotdead/punks.bodies',\n",
    "   'tutsplus/BasketballFreeThrowUnity',\n",
    "   'chrisdesilva/pickup',\n",
    "   'alfremedpal/PandasBasketball',\n",
    "   'chenyukang/Basketball_demo']\n",
    "\n",
    "headers = {\"Authorization\": f\"token {github_token}\", \"User-Agent\": github_username}\n",
    "\n",
    "if headers[\"Authorization\"] == \"token \" or headers[\"User-Agent\"] == \"\":\n",
    "    raise Exception(\n",
    "        \"You need to follow the instructions marked TODO in this script before trying to use it\"\n",
    "    )\n",
    "\n",
    "\n",
    "def github_api_request(url: str) -> Union[List, Dict]:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response_data = response.json()\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Error response from github api! status code: {response.status_code}, \"\n",
    "            f\"response: {json.dumps(response_data)}\"\n",
    "        )\n",
    "    return response_data\n",
    "\n",
    "\n",
    "def get_repo_language(repo: str) -> str:\n",
    "    url = f\"https://api.github.com/repos/{repo}\"\n",
    "    repo_info = github_api_request(url)\n",
    "    if type(repo_info) is dict:\n",
    "        repo_info = cast(Dict, repo_info)\n",
    "        if \"language\" not in repo_info:\n",
    "            raise Exception(\n",
    "                \"'language' key not round in response\\n{}\".format(json.dumps(repo_info))\n",
    "            )\n",
    "        return repo_info[\"language\"]\n",
    "    raise Exception(\n",
    "        f\"Expecting a dictionary response from {url}, instead got {json.dumps(repo_info)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_repo_contents(repo: str) -> List[Dict[str, str]]:\n",
    "    url = f\"https://api.github.com/repos/{repo}/contents/\"\n",
    "    contents = github_api_request(url)\n",
    "    if type(contents) is list:\n",
    "        contents = cast(List, contents)\n",
    "        return contents\n",
    "    raise Exception(\n",
    "        f\"Expecting a list response from {url}, instead got {json.dumps(contents)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_readme_download_url(files: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Takes in a response from the github api that lists the files in a repo and\n",
    "    returns the url that can be used to download the repo's README file.\n",
    "    \"\"\"\n",
    "    for file in files:\n",
    "        if file[\"name\"].lower().startswith(\"readme\"):\n",
    "            return file[\"download_url\"]\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def process_repo(repo: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Takes a repo name like \"gocodeup/codeup-setup-script\" and returns a\n",
    "    dictionary with the language of the repo and the readme contents.\n",
    "    \"\"\"\n",
    "    contents = get_repo_contents(repo)\n",
    "    readme_download_url = get_readme_download_url(contents)\n",
    "    if readme_download_url == \"\":\n",
    "        readme_contents = \"\"\n",
    "    else:\n",
    "        readme_contents = requests.get(readme_download_url).text\n",
    "    return {\n",
    "        \"repo\": repo,\n",
    "        \"language\": get_repo_language(repo),\n",
    "        \"readme_contents\": readme_contents,\n",
    "    }\n",
    "\n",
    "\n",
    "def scrape_github_data() -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Loop through all of the repos and process them. Returns the processed data.\n",
    "    \"\"\"\n",
    "    return [process_repo(repo) for repo in REPOS]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = scrape_github_data()\n",
    "    json.dump(data, open(\"data.json\", \"w\"), indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)\n",
    "df.rename(columns= {'readme_contents' : 'readme_txt'},inplace=True)\n",
    "df.to_csv('search_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
