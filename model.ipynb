{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#use multinomial naive bayes algorithm after the other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import wrangle, model\n",
    "\n",
    "from importlib import reload\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wrangle' from '/Users/sinao/codeup-data-science/nlp_project/wrangle.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(wrangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 190 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n",
      "\n",
      "Removed 211 stopwords\n",
      "---\n",
      "\n",
      "Removed 401 stopwords\n",
      "---\n",
      "\n",
      "Removed 50 stopwords\n",
      "---\n",
      "\n",
      "Removed 8 stopwords\n",
      "---\n",
      "\n",
      "Removed 158 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 32 stopwords\n",
      "---\n",
      "\n",
      "Removed 110 stopwords\n",
      "---\n",
      "\n",
      "Removed 500 stopwords\n",
      "---\n",
      "\n",
      "Removed 494 stopwords\n",
      "---\n",
      "\n",
      "Removed 31 stopwords\n",
      "---\n",
      "\n",
      "Removed 427 stopwords\n",
      "---\n",
      "\n",
      "Removed 76 stopwords\n",
      "---\n",
      "\n",
      "Removed 175 stopwords\n",
      "---\n",
      "\n",
      "Removed 731 stopwords\n",
      "---\n",
      "\n",
      "Removed 68 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 358 stopwords\n",
      "---\n",
      "\n",
      "Removed 41 stopwords\n",
      "---\n",
      "\n",
      "Removed 15 stopwords\n",
      "---\n",
      "\n",
      "Removed 48 stopwords\n",
      "---\n",
      "\n",
      "Removed 100 stopwords\n",
      "---\n",
      "\n",
      "Removed 111 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 134 stopwords\n",
      "---\n",
      "\n",
      "Removed 242 stopwords\n",
      "---\n",
      "\n",
      "Removed 27 stopwords\n",
      "---\n",
      "\n",
      "Removed 74 stopwords\n",
      "---\n",
      "\n",
      "Removed 88 stopwords\n",
      "---\n",
      "\n",
      "Removed 8 stopwords\n",
      "---\n",
      "\n",
      "Removed 270 stopwords\n",
      "---\n",
      "\n",
      "Removed 123 stopwords\n",
      "---\n",
      "\n",
      "Removed 389 stopwords\n",
      "---\n",
      "\n",
      "Removed 81 stopwords\n",
      "---\n",
      "\n",
      "Removed 187 stopwords\n",
      "---\n",
      "\n",
      "Removed 23 stopwords\n",
      "---\n",
      "\n",
      "Removed 25 stopwords\n",
      "---\n",
      "\n",
      "Removed 112 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 199 stopwords\n",
      "---\n",
      "\n",
      "Removed 82 stopwords\n",
      "---\n",
      "\n",
      "Removed 22 stopwords\n",
      "---\n",
      "\n",
      "Removed 220 stopwords\n",
      "---\n",
      "\n",
      "Removed 56 stopwords\n",
      "---\n",
      "\n",
      "Removed 20 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 10 stopwords\n",
      "---\n",
      "\n",
      "Removed 512 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 24 stopwords\n",
      "---\n",
      "\n",
      "Removed 926 stopwords\n",
      "---\n",
      "\n",
      "Removed 42 stopwords\n",
      "---\n",
      "\n",
      "Removed 115 stopwords\n",
      "---\n",
      "\n",
      "Removed 6 stopwords\n",
      "---\n",
      "\n",
      "Removed 30 stopwords\n",
      "---\n",
      "\n",
      "Removed 751 stopwords\n",
      "---\n",
      "\n",
      "Removed 55 stopwords\n",
      "---\n",
      "\n",
      "Removed 115 stopwords\n",
      "---\n",
      "\n",
      "Removed 61 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 50 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 157 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 1030 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 136 stopwords\n",
      "---\n",
      "\n",
      "Removed 16 stopwords\n",
      "---\n",
      "\n",
      "Removed 14 stopwords\n",
      "---\n",
      "\n",
      "Removed 61 stopwords\n",
      "---\n",
      "\n",
      "Removed 72 stopwords\n",
      "---\n",
      "\n",
      "Removed 52 stopwords\n",
      "---\n",
      "\n",
      "Removed 24 stopwords\n",
      "---\n",
      "\n",
      "Removed 13 stopwords\n",
      "---\n",
      "\n",
      "Removed 55 stopwords\n",
      "---\n",
      "\n",
      "Removed 82 stopwords\n",
      "---\n",
      "\n",
      "Removed 78 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 32 stopwords\n",
      "---\n",
      "\n",
      "Removed 185 stopwords\n",
      "---\n",
      "\n",
      "Removed 48 stopwords\n",
      "---\n",
      "\n",
      "Removed 150 stopwords\n",
      "---\n",
      "\n",
      "Removed 385 stopwords\n",
      "---\n",
      "\n",
      "Removed 522 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 64 stopwords\n",
      "---\n",
      "\n",
      "Removed 113 stopwords\n",
      "---\n",
      "\n",
      "Removed 110 stopwords\n",
      "---\n",
      "\n",
      "Removed 285 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 29 stopwords\n",
      "---\n",
      "\n",
      "Removed 4 stopwords\n",
      "---\n",
      "\n",
      "Removed 92 stopwords\n",
      "---\n",
      "\n",
      "Removed 211 stopwords\n",
      "---\n",
      "\n",
      "Removed 172 stopwords\n",
      "---\n",
      "\n",
      "Removed 80 stopwords\n",
      "---\n",
      "\n",
      "Removed 32 stopwords\n",
      "---\n",
      "\n",
      "Removed 455 stopwords\n",
      "---\n",
      "\n",
      "Removed 119 stopwords\n",
      "---\n",
      "\n",
      "Removed 129 stopwords\n",
      "---\n",
      "\n",
      "Removed 158 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n",
      "\n",
      "Removed 6 stopwords\n",
      "---\n",
      "\n",
      "Removed 118 stopwords\n",
      "---\n",
      "\n",
      "Removed 100 stopwords\n",
      "---\n",
      "\n",
      "Removed 98 stopwords\n",
      "---\n",
      "\n",
      "Removed 418 stopwords\n",
      "---\n",
      "\n",
      "Removed 37 stopwords\n",
      "---\n",
      "\n",
      "Removed 52 stopwords\n",
      "---\n",
      "\n",
      "Removed 143 stopwords\n",
      "---\n",
      "\n",
      "Removed 45 stopwords\n",
      "---\n",
      "\n",
      "Removed 206 stopwords\n",
      "---\n",
      "\n",
      "Removed 168 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 502 stopwords\n",
      "---\n",
      "\n",
      "Removed 18 stopwords\n",
      "---\n",
      "\n",
      "Removed 9 stopwords\n",
      "---\n",
      "\n",
      "Removed 145 stopwords\n",
      "---\n",
      "\n",
      "Removed 55 stopwords\n",
      "---\n",
      "\n",
      "Removed 248 stopwords\n",
      "---\n",
      "\n",
      "Removed 32 stopwords\n",
      "---\n",
      "\n",
      "Removed 122 stopwords\n",
      "---\n",
      "\n",
      "Removed 39 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 173 stopwords\n",
      "---\n",
      "\n",
      "Removed 142 stopwords\n",
      "---\n",
      "\n",
      "Removed 101 stopwords\n",
      "---\n",
      "\n",
      "Removed 356 stopwords\n",
      "---\n",
      "\n",
      "Removed 6 stopwords\n",
      "---\n",
      "\n",
      "Removed 49 stopwords\n",
      "---\n",
      "\n",
      "Removed 1 stopwords\n",
      "---\n",
      "\n",
      "Removed 31 stopwords\n",
      "---\n",
      "\n",
      "Removed 14 stopwords\n",
      "---\n",
      "\n",
      "Removed 25 stopwords\n",
      "---\n",
      "\n",
      "Removed 339 stopwords\n",
      "---\n",
      "\n",
      "Removed 15 stopwords\n",
      "---\n",
      "\n",
      "Removed 19 stopwords\n",
      "---\n",
      "\n",
      "Removed 7 stopwords\n",
      "---\n",
      "\n",
      "Removed 42 stopwords\n",
      "---\n",
      "\n",
      "Removed 385 stopwords\n",
      "---\n",
      "\n",
      "Removed 171 stopwords\n",
      "---\n",
      "\n",
      "Removed 417 stopwords\n",
      "---\n",
      "\n",
      "Removed 198 stopwords\n",
      "---\n",
      "\n",
      "Removed 184 stopwords\n",
      "---\n",
      "\n",
      "Removed 108 stopwords\n",
      "---\n",
      "\n",
      "Removed 59 stopwords\n",
      "---\n",
      "\n",
      "Removed 212 stopwords\n",
      "---\n",
      "\n",
      "Removed 68 stopwords\n",
      "---\n",
      "\n",
      "Removed 122 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 50 stopwords\n",
      "---\n",
      "\n",
      "Removed 241 stopwords\n",
      "---\n",
      "\n",
      "Removed 164 stopwords\n",
      "---\n",
      "\n",
      "Removed 16 stopwords\n",
      "---\n",
      "\n",
      "Removed 15 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 13 stopwords\n",
      "---\n",
      "\n",
      "Removed 1 stopwords\n",
      "---\n",
      "\n",
      "Removed 40 stopwords\n",
      "---\n",
      "\n",
      "Removed 9 stopwords\n",
      "---\n",
      "\n",
      "Removed 11 stopwords\n",
      "---\n",
      "\n",
      "Removed 96 stopwords\n",
      "---\n",
      "\n",
      "Removed 504 stopwords\n",
      "---\n",
      "\n",
      "Removed 15 stopwords\n",
      "---\n",
      "\n",
      "Removed 207 stopwords\n",
      "---\n",
      "\n",
      "Removed 876 stopwords\n",
      "---\n",
      "\n",
      "Removed 31 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 60 stopwords\n",
      "---\n",
      "\n",
      "Removed 78 stopwords\n",
      "---\n",
      "\n",
      "Removed 23 stopwords\n",
      "---\n",
      "\n",
      "Removed 56 stopwords\n",
      "---\n",
      "\n",
      "Removed 292 stopwords\n",
      "---\n",
      "\n",
      "Removed 66 stopwords\n",
      "---\n",
      "\n",
      "Removed 1 stopwords\n",
      "---\n",
      "\n",
      "Removed 74 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "df = wrangle.get_search_csv()\n",
    "df = wrangle.prep_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[['language', 'lemmatized']]\n",
    "\n",
    "# for i in df.index:\n",
    "#     df.loc[i, 'word_count'] = len([word for word in df.loc[i, 'lemmatized'].split()])\n",
    "# df.word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Explore various models and feature combinations.\n",
    "Choose **three** models to validate. Choose **one** to test. \n",
    "Artifact: `model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Preparation\n",
    "- Create function to vectorize, scale, and split data\n",
    "- Create word_count feature --> backport to wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Prediction and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorize_split(df):\n",
    "\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        \n",
    "    ---\n",
    "    Parameters:\n",
    "        \n",
    "    ---\n",
    "    Returns:\n",
    "        X_train, y_train, X_validate, y_validate, X_test, y_test: data subsets\n",
    "    \"\"\"\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    df['lemmatized'] = tfidf.fit_transform(df.lemmatized).todense()\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit_transform(df[['word_count']])\n",
    "\n",
    "    train_validate, test = train_test_split(df, test_size=.3, random_state=514, stratify=df['language'])\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=514, stratify=train_validate['language'])\n",
    "\n",
    "    # split data into Big X, small y sets \n",
    "    X_train = train.drop(columns=['language'])\n",
    "    y_train = train.language\n",
    "\n",
    "    X_validate = validate.drop(columns=['language'])\n",
    "    y_validate = validate.language\n",
    "\n",
    "    X_test = test.drop(columns=['language'])\n",
    "    y_test = test.language\n",
    "\n",
    "    return train, X_train, y_train, X_validate, y_validate, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_train, y_train, X_validate, y_validate, X_test, y_test = vectorize_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python              0.292135\n",
       "Other               0.247191\n",
       "R                   0.168539\n",
       "JavaScript          0.112360\n",
       "Jupyter Notebook    0.101124\n",
       "HTML                0.078652\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formulate baseline prediction ->base prediction is python\n",
    "train.language.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, X_df, y_df):\n",
    "    \"\"\"\n",
    "    purpose: function executes performs computations to produce evaulation metrics for a given model\n",
    "\n",
    "    inputs: \n",
    "        model: a model that has been previous fit to spec\n",
    "        X_df: a dataframe featuring the X subset of data for evaluation\n",
    "        y_df: a dataframe featuring the model target variable\n",
    "\n",
    "    Returns: a rounded pandas Series that can be adding to an evaulation metric comparison chart\n",
    "    \"\"\"\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_df)\n",
    "\n",
    "    # Estimate Probability \n",
    "    y_pred_proba = model.predict_proba(X_df)\n",
    "\n",
    "    #create confusion matrix\n",
    "    confusion = confusion_matrix(y_df, y_pred)\n",
    "\n",
    "    #assign results of confusion matrix to variables\n",
    "    true_negative = confusion[0,0]\n",
    "    false_positive = confusion[0,1]\n",
    "    false_negative = confusion[1,0]\n",
    "    true_positive = confusion[1,1]\n",
    "\n",
    "    #accuracy\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "\n",
    "    #true positive rate / recall\n",
    "    recall = true_positive / (true_positive +false_negative)\n",
    "\n",
    "    #false positive rate\n",
    "    false_positive_rate = false_positive / (true_negative + false_positive)\n",
    "\n",
    "    #true negative rate\n",
    "    true_negative_rate = true_negative / (true_negative + false_positive)\n",
    "\n",
    "    #false negative rate\n",
    "    false_negative_rate = false_negative / (false_negative + true_positive)\n",
    "\n",
    "    #precision\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "    #f1-score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    #support\n",
    "    support_positive = true_positive + false_negative\n",
    "    support_negative = false_positive + true_negative\n",
    "\n",
    "    metrics = pd.Series([accuracy, true_positive, false_positive, true_negative, false_negative,\\\n",
    "                        recall, false_positive_rate, true_negative_rate, false_negative_rate, \\\n",
    "                        precision, f1_score, support_positive, support_negative])\n",
    "                        \n",
    "    return metrics.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_chart():\n",
    "    \"\"\"\n",
    "    purpose: to create a dataframe with an index reflecting compuation metrics for future models\n",
    "\n",
    "    returns: a pandas dataframe with appropriately set index\n",
    "    \"\"\"\n",
    "    statistics = ['Accuracy/Score',\n",
    "    'True Positives' , 'False Positives', 'True Negatives', 'False Negatives', \\\n",
    "    'TPR/Recall', 'False Positive Rate', 'True Negative Rate', 'False Negative Rate', \\\n",
    "    'Precision', 'F1-Score', 'Support Positive', 'Support Negative']\n",
    "\n",
    "\n",
    "    return pd.DataFrame({}, index=statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy for \"language\" prediction:  29.2%\n"
     ]
    }
   ],
   "source": [
    "# formulate baseline accuracy\n",
    "baseline_accuracy = (y_train == 'Python').mean()\n",
    "\n",
    "print(f'Baseline Accuracy for \\\"language\\\" prediction: {(baseline_accuracy * 100): .3}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_description_chart(y):\n",
    "\n",
    "    # formulate baseline accuracy\n",
    "    baseline_accuracy = (y == 'Python').mean()\n",
    "\n",
    "    descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "                                'Accuracy(Score)': baseline_accuracy,\n",
    "                                'Type': 'Basic Baseline',\n",
    "                                'Features Used': 'Baseline Prediction',\n",
    "                                'Parameters': 'n/a'\n",
    "                                }, index=[0])\n",
    "    \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)            Type        Features Used Parameters\n",
       "0  Baseline         0.292135  Basic Baseline  Baseline Prediction        n/a\n",
       "1  Baseline         0.292135  Basic Baseline  Baseline Prediction        n/a"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([model_descriptions, pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0]) ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_chart = model.create_comp_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_set = ['word_count', 'lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [train, X_train, y_train, X_validate, y_validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dtc(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product(np.arange(3,7,1)))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'DTC_'+f'{idx}'\n",
    "        dtc = DecisionTreeClassifier(max_depth=item[0],\\\n",
    "                                            random_state=514)\n",
    "        \n",
    "        dtc.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(dtc, X_train[features], y_train).values\n",
    "\n",
    "        score = dtc.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Decision Tree Classifier',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}'},\n",
    "                                    index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart =  model_dtc(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_3</td>\n",
       "      <td>0.696600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.640400</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.483100</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)                      Type  \\\n",
       "4     DTC_3         0.696600  Decision Tree Classifier   \n",
       "3     DTC_2         0.640400  Decision Tree Classifier   \n",
       "2     DTC_1         0.550600  Decision Tree Classifier   \n",
       "1     DTC_0         0.483100  Decision Tree Classifier   \n",
       "0  Baseline         0.292135            Basic Baseline   \n",
       "\n",
       "                  Features Used Parameters  \n",
       "4  ['word_count', 'lemmatized']   Depth: 6  \n",
       "3  ['word_count', 'lemmatized']   Depth: 5  \n",
       "2  ['word_count', 'lemmatized']   Depth: 4  \n",
       "1  ['word_count', 'lemmatized']   Depth: 3  \n",
       "0           Baseline Prediction        n/a  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.sort_values(by='Accuracy(Score)', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model\tAccuracy(Score)\tType\tFeatures Used\tParameters\n",
    "8\tRF_2\t0.8936\tRandom Forest\t['word_count', 'lemmatized']\tDepth: 20, Leaves: 1\n",
    "11\tRF_5\t0.8936\tRandom Forest\t['word_count', 'lemmatized']\tDepth: 25, Leaves: 1\n",
    "5\tDTC_4\t0.7766\tDecision Tree Classifier\t['word_count', 'lemmatized']\tDepth: 9\n",
    "4\tDTC_3\t0.7660\tDecision Tree Classifier\t['word_count', 'lemmatized']\tDepth: 8\n",
    "3\tDTC_2\t0.6915\tDecision Tree Classifier\t['word_count', 'lemmatized']\tDepth: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTC_0</th>\n",
       "      <th>DTC_1</th>\n",
       "      <th>DTC_2</th>\n",
       "      <th>DTC_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positives</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positives</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negatives</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negatives</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR/Recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative Rate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Positive</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Negative</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DTC_0  DTC_1  DTC_2  DTC_3\n",
       "Accuracy/Score         1.0    1.0    1.0    1.0\n",
       "True Positives         3.0    6.0    7.0    7.0\n",
       "False Positives        0.0    0.0    0.0    0.0\n",
       "True Negatives         0.0    0.0    4.0    5.0\n",
       "False Negatives        0.0    0.0    0.0    0.0\n",
       "TPR/Recall             1.0    1.0    1.0    1.0\n",
       "False Positive Rate    0.0    0.0    0.0    0.0\n",
       "True Negative Rate     0.0    0.0    1.0    1.0\n",
       "False Negative Rate    0.0    0.0    0.0    0.0\n",
       "Precision              1.0    1.0    1.0    1.0\n",
       "F1-Score               1.0    1.0    1.0    1.0\n",
       "Support Positive       3.0    6.0    7.0    7.0\n",
       "Support Negative       0.0    0.0    4.0    5.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product([3,7], [3,2,1]))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'RF_'+f'{idx}'\n",
    "        rf = RandomForestClassifier(max_depth=item[0],\\\n",
    "                                            min_samples_leaf=item[1],\n",
    "                                            random_state=514)\n",
    "        \n",
    "        rf.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(rf, X_train[features], y_train).values\n",
    "\n",
    "        score = rf.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Random Forest',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}, Leaves: {item[1]}'},\n",
    "                                    index=[0])\n",
    "       \n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart = model_rf(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.483100</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.640400</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_3</td>\n",
       "      <td>0.696600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF_0</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_1</td>\n",
       "      <td>0.449400</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_2</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_3</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_4</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.786500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy(Score)                      Type  \\\n",
       "0   Baseline         0.292135            Basic Baseline   \n",
       "1      DTC_0         0.483100  Decision Tree Classifier   \n",
       "2      DTC_1         0.550600  Decision Tree Classifier   \n",
       "3      DTC_2         0.640400  Decision Tree Classifier   \n",
       "4      DTC_3         0.696600  Decision Tree Classifier   \n",
       "5       RF_0         0.427000             Random Forest   \n",
       "6       RF_1         0.449400             Random Forest   \n",
       "7       RF_2         0.505600             Random Forest   \n",
       "8       RF_3         0.550600             Random Forest   \n",
       "9       RF_4         0.573000             Random Forest   \n",
       "10      RF_5         0.786500             Random Forest   \n",
       "\n",
       "                   Features Used           Parameters  \n",
       "0            Baseline Prediction                  n/a  \n",
       "1   ['word_count', 'lemmatized']             Depth: 3  \n",
       "2   ['word_count', 'lemmatized']             Depth: 4  \n",
       "3   ['word_count', 'lemmatized']             Depth: 5  \n",
       "4   ['word_count', 'lemmatized']             Depth: 6  \n",
       "5   ['word_count', 'lemmatized']  Depth: 3, Leaves: 3  \n",
       "6   ['word_count', 'lemmatized']  Depth: 3, Leaves: 2  \n",
       "7   ['word_count', 'lemmatized']  Depth: 3, Leaves: 1  \n",
       "8   ['word_count', 'lemmatized']  Depth: 7, Leaves: 3  \n",
       "9   ['word_count', 'lemmatized']  Depth: 7, Leaves: 2  \n",
       "10  ['word_count', 'lemmatized']  Depth: 7, Leaves: 1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways - Random Forest\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors\n",
    "def model_knn(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    k_range = range(3, 7)\n",
    "    scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train[features], y_train)\n",
    "        scores.append(knn.score(X_train[features], y_train))\n",
    "\n",
    "        model_id = 'Knn_'+f'{k}'\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(knn, X_train[features], y_train).values\n",
    "\n",
    "        score = knn.score(X_train[features], y_train).round(5)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Knn',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'K-Neighbors: {k}'},\n",
    "            index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.scatter(k_range, scores)\n",
    "    plt.xticks([0,5,10,15,20])\n",
    "    plt.show()\n",
    "    np.mean(scores)\n",
    "\n",
    "    \n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/sinao/codeup-data-science/nlp_project/model.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions, comparison_chart = model_knn(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.786500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_3</td>\n",
       "      <td>0.696600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.640400</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_4</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_3</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Knn_4</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Knn_5</td>\n",
       "      <td>0.516850</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_2</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Knn_3</td>\n",
       "      <td>0.494380</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Knn_6</td>\n",
       "      <td>0.483150</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.483100</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_1</td>\n",
       "      <td>0.449400</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF_0</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy(Score)                      Type  \\\n",
       "10      RF_5         0.786500             Random Forest   \n",
       "4      DTC_3         0.696600  Decision Tree Classifier   \n",
       "3      DTC_2         0.640400  Decision Tree Classifier   \n",
       "9       RF_4         0.573000             Random Forest   \n",
       "2      DTC_1         0.550600  Decision Tree Classifier   \n",
       "8       RF_3         0.550600             Random Forest   \n",
       "12     Knn_4         0.528090                       Knn   \n",
       "13     Knn_5         0.516850                       Knn   \n",
       "7       RF_2         0.505600             Random Forest   \n",
       "11     Knn_3         0.494380                       Knn   \n",
       "14     Knn_6         0.483150                       Knn   \n",
       "1      DTC_0         0.483100  Decision Tree Classifier   \n",
       "6       RF_1         0.449400             Random Forest   \n",
       "5       RF_0         0.427000             Random Forest   \n",
       "0   Baseline         0.292135            Basic Baseline   \n",
       "\n",
       "                   Features Used           Parameters  \n",
       "10  ['word_count', 'lemmatized']  Depth: 7, Leaves: 1  \n",
       "4   ['word_count', 'lemmatized']             Depth: 6  \n",
       "3   ['word_count', 'lemmatized']             Depth: 5  \n",
       "9   ['word_count', 'lemmatized']  Depth: 7, Leaves: 2  \n",
       "2   ['word_count', 'lemmatized']             Depth: 4  \n",
       "8   ['word_count', 'lemmatized']  Depth: 7, Leaves: 3  \n",
       "12  ['word_count', 'lemmatized']       K-Neighbors: 4  \n",
       "13  ['word_count', 'lemmatized']       K-Neighbors: 5  \n",
       "7   ['word_count', 'lemmatized']  Depth: 3, Leaves: 1  \n",
       "11  ['word_count', 'lemmatized']       K-Neighbors: 3  \n",
       "14  ['word_count', 'lemmatized']       K-Neighbors: 6  \n",
       "1   ['word_count', 'lemmatized']             Depth: 3  \n",
       "6   ['word_count', 'lemmatized']  Depth: 3, Leaves: 2  \n",
       "5   ['word_count', 'lemmatized']  Depth: 3, Leaves: 3  \n",
       "0            Baseline Prediction                  n/a  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.sort_values(by='Accuracy(Score)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lr(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    cees = [.1,.5,1]\n",
    "    solver = ['newton-cg', 'lbfgs']\n",
    "    weights = [None, 'balanced']\n",
    "\n",
    "    selectors = list(product(cees, solver, weights))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'LR_'+f'{idx}'\n",
    "        lr = LogisticRegression(C=item[0],\\\n",
    "                                solver=item[1],\n",
    "                                class_weight=item[2],\n",
    "                                max_iter=400,\n",
    "                                random_state=514)\n",
    "        \n",
    "        lr.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(lr, X_train[features], y_train).values\n",
    "\n",
    "        score = lr.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Logistic Regression',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'C: {item[0]}, Solver: {item[1]}, Class Weight: {item[2]}'},\n",
    "            index=[0])\n",
    "        \n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/sinao/codeup-data-science/nlp_project/model.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart = model_lr(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description and Comparison Charts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Basic Baseline              0.292135\n",
       "Decision Tree Classifier    0.592675\n",
       "Knn                         0.505618\n",
       "Logistic Regression         0.213500\n",
       "Random Forest               0.548683\n",
       "Name: Accuracy(Score), dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.groupby('Type')['Accuracy(Score)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.483100</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.640400</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_3</td>\n",
       "      <td>0.696600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF_0</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_1</td>\n",
       "      <td>0.449400</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_2</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 3, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_3</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_4</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.786500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Knn_3</td>\n",
       "      <td>0.494380</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Knn_4</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Knn_5</td>\n",
       "      <td>0.516850</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Knn_6</td>\n",
       "      <td>0.483150</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR_0</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR_1</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR_2</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LR_3</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR_4</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.5, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy(Score)                      Type  \\\n",
       "0   Baseline         0.292135            Basic Baseline   \n",
       "1      DTC_0         0.483100  Decision Tree Classifier   \n",
       "2      DTC_1         0.550600  Decision Tree Classifier   \n",
       "3      DTC_2         0.640400  Decision Tree Classifier   \n",
       "4      DTC_3         0.696600  Decision Tree Classifier   \n",
       "5       RF_0         0.427000             Random Forest   \n",
       "6       RF_1         0.449400             Random Forest   \n",
       "7       RF_2         0.505600             Random Forest   \n",
       "8       RF_3         0.550600             Random Forest   \n",
       "9       RF_4         0.573000             Random Forest   \n",
       "10      RF_5         0.786500             Random Forest   \n",
       "11     Knn_3         0.494380                       Knn   \n",
       "12     Knn_4         0.528090                       Knn   \n",
       "13     Knn_5         0.516850                       Knn   \n",
       "14     Knn_6         0.483150                       Knn   \n",
       "15      LR_0         0.303400       Logistic Regression   \n",
       "16      LR_1         0.123600       Logistic Regression   \n",
       "17      LR_2         0.303400       Logistic Regression   \n",
       "18      LR_3         0.123600       Logistic Regression   \n",
       "19      LR_4         0.303400       Logistic Regression   \n",
       "\n",
       "                   Features Used  \\\n",
       "0            Baseline Prediction   \n",
       "1   ['word_count', 'lemmatized']   \n",
       "2   ['word_count', 'lemmatized']   \n",
       "3   ['word_count', 'lemmatized']   \n",
       "4   ['word_count', 'lemmatized']   \n",
       "5   ['word_count', 'lemmatized']   \n",
       "6   ['word_count', 'lemmatized']   \n",
       "7   ['word_count', 'lemmatized']   \n",
       "8   ['word_count', 'lemmatized']   \n",
       "9   ['word_count', 'lemmatized']   \n",
       "10  ['word_count', 'lemmatized']   \n",
       "11  ['word_count', 'lemmatized']   \n",
       "12  ['word_count', 'lemmatized']   \n",
       "13  ['word_count', 'lemmatized']   \n",
       "14  ['word_count', 'lemmatized']   \n",
       "15  ['word_count', 'lemmatized']   \n",
       "16  ['word_count', 'lemmatized']   \n",
       "17  ['word_count', 'lemmatized']   \n",
       "18  ['word_count', 'lemmatized']   \n",
       "19  ['word_count', 'lemmatized']   \n",
       "\n",
       "                                           Parameters  \n",
       "0                                                 n/a  \n",
       "1                                            Depth: 3  \n",
       "2                                            Depth: 4  \n",
       "3                                            Depth: 5  \n",
       "4                                            Depth: 6  \n",
       "5                                 Depth: 3, Leaves: 3  \n",
       "6                                 Depth: 3, Leaves: 2  \n",
       "7                                 Depth: 3, Leaves: 1  \n",
       "8                                 Depth: 7, Leaves: 3  \n",
       "9                                 Depth: 7, Leaves: 2  \n",
       "10                                Depth: 7, Leaves: 1  \n",
       "11                                     K-Neighbors: 3  \n",
       "12                                     K-Neighbors: 4  \n",
       "13                                     K-Neighbors: 5  \n",
       "14                                     K-Neighbors: 6  \n",
       "15      C: 0.1, Solver: newton-cg, Class Weight: None  \n",
       "16  C: 0.1, Solver: newton-cg, Class Weight: balanced  \n",
       "17          C: 0.1, Solver: lbfgs, Class Weight: None  \n",
       "18      C: 0.1, Solver: lbfgs, Class Weight: balanced  \n",
       "19      C: 0.5, Solver: newton-cg, Class Weight: None  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_3</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_4</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_3</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy(Score)                      Type  \\\n",
       "10   RF_5           0.7865             Random Forest   \n",
       "4   DTC_3           0.6966  Decision Tree Classifier   \n",
       "3   DTC_2           0.6404  Decision Tree Classifier   \n",
       "9    RF_4           0.5730             Random Forest   \n",
       "8    RF_3           0.5506             Random Forest   \n",
       "\n",
       "                   Features Used           Parameters  \n",
       "10  ['word_count', 'lemmatized']  Depth: 7, Leaves: 1  \n",
       "4   ['word_count', 'lemmatized']             Depth: 6  \n",
       "3   ['word_count', 'lemmatized']             Depth: 5  \n",
       "9   ['word_count', 'lemmatized']  Depth: 7, Leaves: 2  \n",
       "8   ['word_count', 'lemmatized']  Depth: 7, Leaves: 3  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model descriptions\n",
    "model_descriptions.sort_values('Accuracy(Score)', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF_0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_11</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_9</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_5</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_1</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_4</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_4</th>\n",
       "      <td>0.8750</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_5</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_6</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_8</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_10</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "RF_0           0.0000             0.0              0.0             0.0   \n",
       "RF_1           0.0000             0.0              0.0             0.0   \n",
       "LR_11          0.4000             2.0              2.0             4.0   \n",
       "LR_7           0.4000             2.0              2.0             4.0   \n",
       "LR_3           0.4000             2.0              2.0             4.0   \n",
       "LR_9           0.4375             2.0              2.0             5.0   \n",
       "LR_5           0.4375             2.0              2.0             5.0   \n",
       "LR_1           0.4375             2.0              2.0             5.0   \n",
       "RF_4           0.8000             4.0              0.0             0.0   \n",
       "Knn_4          0.8750             5.0              0.0             2.0   \n",
       "RF_2           1.0000             2.0              0.0             0.0   \n",
       "RF_3           1.0000             4.0              0.0             0.0   \n",
       "Knn_5          1.0000             6.0              0.0             0.0   \n",
       "DTC_1          1.0000             6.0              0.0             0.0   \n",
       "LR_0           1.0000             1.0              0.0             0.0   \n",
       "DTC_0          1.0000             3.0              0.0             0.0   \n",
       "DTC_3          1.0000             7.0              0.0             5.0   \n",
       "LR_6           1.0000             1.0              0.0             0.0   \n",
       "LR_8           1.0000             1.0              0.0             0.0   \n",
       "LR_2           1.0000             1.0              0.0             0.0   \n",
       "Knn_3          1.0000             7.0              0.0             4.0   \n",
       "DTC_2          1.0000             7.0              0.0             4.0   \n",
       "RF_5           1.0000             7.0              0.0             5.0   \n",
       "LR_4           1.0000             1.0              0.0             0.0   \n",
       "LR_10          1.0000             1.0              0.0             0.0   \n",
       "\n",
       "       False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "RF_0               0.0      0.0000               0.0000              0.0000   \n",
       "RF_1               0.0      0.0000               0.0000              0.0000   \n",
       "LR_11              7.0      0.2222               0.3333              0.6667   \n",
       "LR_7               7.0      0.2222               0.3333              0.6667   \n",
       "LR_3               7.0      0.2222               0.3333              0.6667   \n",
       "LR_9               7.0      0.2222               0.2857              0.7143   \n",
       "LR_5               7.0      0.2222               0.2857              0.7143   \n",
       "LR_1               7.0      0.2222               0.2857              0.7143   \n",
       "RF_4               1.0      0.8000               0.0000              0.0000   \n",
       "Knn_4              1.0      0.8333               0.0000              1.0000   \n",
       "RF_2               0.0      1.0000               0.0000              0.0000   \n",
       "RF_3               0.0      1.0000               0.0000              0.0000   \n",
       "Knn_5              0.0      1.0000               0.0000              0.0000   \n",
       "DTC_1              0.0      1.0000               0.0000              0.0000   \n",
       "LR_0               0.0      1.0000               0.0000              0.0000   \n",
       "DTC_0              0.0      1.0000               0.0000              0.0000   \n",
       "DTC_3              0.0      1.0000               0.0000              1.0000   \n",
       "LR_6               0.0      1.0000               0.0000              0.0000   \n",
       "LR_8               0.0      1.0000               0.0000              0.0000   \n",
       "LR_2               0.0      1.0000               0.0000              0.0000   \n",
       "Knn_3              0.0      1.0000               0.0000              1.0000   \n",
       "DTC_2              0.0      1.0000               0.0000              1.0000   \n",
       "RF_5               0.0      1.0000               0.0000              1.0000   \n",
       "LR_4               0.0      1.0000               0.0000              0.0000   \n",
       "LR_10              0.0      1.0000               0.0000              0.0000   \n",
       "\n",
       "       False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "RF_0                0.0000        0.0    0.0000               0.0   \n",
       "RF_1                0.0000        0.0    0.0000               0.0   \n",
       "LR_11               0.7778        0.5    0.3077               9.0   \n",
       "LR_7                0.7778        0.5    0.3077               9.0   \n",
       "LR_3                0.7778        0.5    0.3077               9.0   \n",
       "LR_9                0.7778        0.5    0.3077               9.0   \n",
       "LR_5                0.7778        0.5    0.3077               9.0   \n",
       "LR_1                0.7778        0.5    0.3077               9.0   \n",
       "RF_4                0.2000        1.0    0.8889               5.0   \n",
       "Knn_4               0.1667        1.0    0.9091               6.0   \n",
       "RF_2                0.0000        1.0    1.0000               2.0   \n",
       "RF_3                0.0000        1.0    1.0000               4.0   \n",
       "Knn_5               0.0000        1.0    1.0000               6.0   \n",
       "DTC_1               0.0000        1.0    1.0000               6.0   \n",
       "LR_0                0.0000        1.0    1.0000               1.0   \n",
       "DTC_0               0.0000        1.0    1.0000               3.0   \n",
       "DTC_3               0.0000        1.0    1.0000               7.0   \n",
       "LR_6                0.0000        1.0    1.0000               1.0   \n",
       "LR_8                0.0000        1.0    1.0000               1.0   \n",
       "LR_2                0.0000        1.0    1.0000               1.0   \n",
       "Knn_3               0.0000        1.0    1.0000               7.0   \n",
       "DTC_2               0.0000        1.0    1.0000               7.0   \n",
       "RF_5                0.0000        1.0    1.0000               7.0   \n",
       "LR_4                0.0000        1.0    1.0000               1.0   \n",
       "LR_10               0.0000        1.0    1.0000               1.0   \n",
       "\n",
       "       Support Negative  \n",
       "RF_0                0.0  \n",
       "RF_1                0.0  \n",
       "LR_11               6.0  \n",
       "LR_7                6.0  \n",
       "LR_3                6.0  \n",
       "LR_9                7.0  \n",
       "LR_5                7.0  \n",
       "LR_1                7.0  \n",
       "RF_4                0.0  \n",
       "Knn_4               2.0  \n",
       "RF_2                0.0  \n",
       "RF_3                0.0  \n",
       "Knn_5               0.0  \n",
       "DTC_1               0.0  \n",
       "LR_0                0.0  \n",
       "DTC_0               0.0  \n",
       "DTC_3               5.0  \n",
       "LR_6                0.0  \n",
       "LR_8                0.0  \n",
       "LR_2                0.0  \n",
       "Knn_3               4.0  \n",
       "DTC_2               4.0  \n",
       "RF_5                5.0  \n",
       "LR_4                0.0  \n",
       "LR_10               0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_chart.T.sort_values(by='True Negatives', ascending=False).head(25).sort_values(by=['Accuracy/Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_4</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_4</th>\n",
       "      <td>0.8750</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_6</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_5</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_6</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_8</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_10</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_11</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_1</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_5</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_9</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_3</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_7</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "DTC_0          1.0000             3.0              0.0             0.0   \n",
       "RF_4           0.8000             4.0              0.0             0.0   \n",
       "Knn_4          0.8750             5.0              0.0             2.0   \n",
       "DTC_2          1.0000             7.0              0.0             4.0   \n",
       "DTC_3          1.0000             7.0              0.0             5.0   \n",
       "RF_2           1.0000             2.0              0.0             0.0   \n",
       "RF_5           1.0000             7.0              0.0             5.0   \n",
       "Knn_6          1.0000             6.0              0.0             0.0   \n",
       "Knn_5          1.0000             6.0              0.0             0.0   \n",
       "RF_3           1.0000             4.0              0.0             0.0   \n",
       "LR_0           1.0000             1.0              0.0             0.0   \n",
       "LR_2           1.0000             1.0              0.0             0.0   \n",
       "LR_4           1.0000             1.0              0.0             0.0   \n",
       "LR_6           1.0000             1.0              0.0             0.0   \n",
       "LR_8           1.0000             1.0              0.0             0.0   \n",
       "LR_10          1.0000             1.0              0.0             0.0   \n",
       "Knn_3          1.0000             7.0              0.0             4.0   \n",
       "DTC_1          1.0000             6.0              0.0             0.0   \n",
       "RF_1           0.0000             0.0              0.0             0.0   \n",
       "LR_11          0.4000             2.0              2.0             4.0   \n",
       "LR_1           0.4375             2.0              2.0             5.0   \n",
       "LR_5           0.4375             2.0              2.0             5.0   \n",
       "LR_9           0.4375             2.0              2.0             5.0   \n",
       "LR_3           0.4000             2.0              2.0             4.0   \n",
       "LR_7           0.4000             2.0              2.0             4.0   \n",
       "\n",
       "       False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "DTC_0              0.0      1.0000               0.0000              0.0000   \n",
       "RF_4               1.0      0.8000               0.0000              0.0000   \n",
       "Knn_4              1.0      0.8333               0.0000              1.0000   \n",
       "DTC_2              0.0      1.0000               0.0000              1.0000   \n",
       "DTC_3              0.0      1.0000               0.0000              1.0000   \n",
       "RF_2               0.0      1.0000               0.0000              0.0000   \n",
       "RF_5               0.0      1.0000               0.0000              1.0000   \n",
       "Knn_6              0.0      1.0000               0.0000              0.0000   \n",
       "Knn_5              0.0      1.0000               0.0000              0.0000   \n",
       "RF_3               0.0      1.0000               0.0000              0.0000   \n",
       "LR_0               0.0      1.0000               0.0000              0.0000   \n",
       "LR_2               0.0      1.0000               0.0000              0.0000   \n",
       "LR_4               0.0      1.0000               0.0000              0.0000   \n",
       "LR_6               0.0      1.0000               0.0000              0.0000   \n",
       "LR_8               0.0      1.0000               0.0000              0.0000   \n",
       "LR_10              0.0      1.0000               0.0000              0.0000   \n",
       "Knn_3              0.0      1.0000               0.0000              1.0000   \n",
       "DTC_1              0.0      1.0000               0.0000              0.0000   \n",
       "RF_1               0.0      0.0000               0.0000              0.0000   \n",
       "LR_11              7.0      0.2222               0.3333              0.6667   \n",
       "LR_1               7.0      0.2222               0.2857              0.7143   \n",
       "LR_5               7.0      0.2222               0.2857              0.7143   \n",
       "LR_9               7.0      0.2222               0.2857              0.7143   \n",
       "LR_3               7.0      0.2222               0.3333              0.6667   \n",
       "LR_7               7.0      0.2222               0.3333              0.6667   \n",
       "\n",
       "       False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "DTC_0               0.0000        1.0    1.0000               3.0   \n",
       "RF_4                0.2000        1.0    0.8889               5.0   \n",
       "Knn_4               0.1667        1.0    0.9091               6.0   \n",
       "DTC_2               0.0000        1.0    1.0000               7.0   \n",
       "DTC_3               0.0000        1.0    1.0000               7.0   \n",
       "RF_2                0.0000        1.0    1.0000               2.0   \n",
       "RF_5                0.0000        1.0    1.0000               7.0   \n",
       "Knn_6               0.0000        1.0    1.0000               6.0   \n",
       "Knn_5               0.0000        1.0    1.0000               6.0   \n",
       "RF_3                0.0000        1.0    1.0000               4.0   \n",
       "LR_0                0.0000        1.0    1.0000               1.0   \n",
       "LR_2                0.0000        1.0    1.0000               1.0   \n",
       "LR_4                0.0000        1.0    1.0000               1.0   \n",
       "LR_6                0.0000        1.0    1.0000               1.0   \n",
       "LR_8                0.0000        1.0    1.0000               1.0   \n",
       "LR_10               0.0000        1.0    1.0000               1.0   \n",
       "Knn_3               0.0000        1.0    1.0000               7.0   \n",
       "DTC_1               0.0000        1.0    1.0000               6.0   \n",
       "RF_1                0.0000        0.0    0.0000               0.0   \n",
       "LR_11               0.7778        0.5    0.3077               9.0   \n",
       "LR_1                0.7778        0.5    0.3077               9.0   \n",
       "LR_5                0.7778        0.5    0.3077               9.0   \n",
       "LR_9                0.7778        0.5    0.3077               9.0   \n",
       "LR_3                0.7778        0.5    0.3077               9.0   \n",
       "LR_7                0.7778        0.5    0.3077               9.0   \n",
       "\n",
       "       Support Negative  \n",
       "DTC_0               0.0  \n",
       "RF_4                0.0  \n",
       "Knn_4               2.0  \n",
       "DTC_2               4.0  \n",
       "DTC_3               5.0  \n",
       "RF_2                0.0  \n",
       "RF_5                5.0  \n",
       "Knn_6               0.0  \n",
       "Knn_5               0.0  \n",
       "RF_3                0.0  \n",
       "LR_0                0.0  \n",
       "LR_2                0.0  \n",
       "LR_4                0.0  \n",
       "LR_6                0.0  \n",
       "LR_8                0.0  \n",
       "LR_10               0.0  \n",
       "Knn_3               4.0  \n",
       "DTC_1               0.0  \n",
       "RF_1                0.0  \n",
       "LR_11               6.0  \n",
       "LR_1                7.0  \n",
       "LR_5                7.0  \n",
       "LR_9                7.0  \n",
       "LR_3                6.0  \n",
       "LR_7                6.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_chart.T.sort_values(by='Accuracy/Score', ascending=False).head(25).sort_values(by=['False Positives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27 entries, 0 to 26\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Model            27 non-null     object \n",
      " 1   Accuracy(Score)  27 non-null     float64\n",
      " 2   Type             27 non-null     object \n",
      " 3   Features Used    27 non-null     object \n",
      " 4   Parameters       27 non-null     object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "model_descriptions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation Takeaways\n",
    "- Had to abandon gridsearch script for lack of feasability\n",
    "- KNN underperforming with initial set of hyper parameters\n",
    "- KNN and Logistic regression continued to be low perfoming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model\tAccuracy(Score)\tType\tFeatures Used\tParameters\n",
    "10\tRF_5\t0.79790\tRandom Forest\t['word_count', 'lemmatized']\tDepth: 7, Leaves: 1\n",
    "9\tRF_4\t0.61700\tRandom Forest\t['word_count', 'lemmatized']\tDepth: 7, Leaves: 2\n",
    "4\tDTC_3\t0.59570\tDecision Tree Classifier\t['word_count', 'lemmatized']\tDepth: 6\n",
    "3\tDTC_2\t0.55320\tDecision Tree Classifier\t['word_count', 'lemmatized']\tDepth: 5\n",
    "11\tKnn_3\t0.51064\tKnn\t['word_count', 'lemmatized']\tK-Neighbors: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation - Top 5 Models from Train section\n",
    "\n",
    "Model\t| Accuracy(Score)|Type                  |Features Used                  |Parameters             |\n",
    "|---    | ---            |---                   |   -----                       |---                    |\n",
    "|RF_5   |\t0.79790 |Random Forest              |\t['word_count', 'lemmatized']|\tDepth: 20, Leaves: 1\n",
    "|RF_4   |\t0.61700 |Random Forest              |\t['word_count', 'lemmatized']|\tDepth: 25, Leaves: 1\n",
    "|DTC3   |   0.59570 |Decision Tree Classifier   |\t['word_count', 'lemmatized']|\tDepth: 9\n",
    "|DTC_2  |\t0.55320\t|Decision Tree Classifier\t|['word_count', 'lemmatized']\t|Depth: 8\n",
    "|KNN_3  |\t0.51064\t|Decision Tree Classifier\t|['word_count', 'lemmatized']\t|Depth: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dtc(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_validate=subsets[3]\n",
    "    y_validate=subsets[4]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product(np.arange(5,7,1)))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'DTC_'+f'{idx}'\n",
    "        dtc = DecisionTreeClassifier(max_depth=item[0],\\\n",
    "                                            random_state=514)\n",
    "        \n",
    "        dtc.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(dtc, X_validate[features], y_validate).values\n",
    "\n",
    "        score = dtc.score(X_validate[features], y_validate).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Decision Tree Classifier',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}'},\n",
    "                                    index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_rf(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_validate=subsets[3]\n",
    "    y_validate=subsets[4]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product([7], [1,2]))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'RF_'+f'{idx}'\n",
    "        rf = RandomForestClassifier(max_depth=item[0],\\\n",
    "                                            min_samples_leaf=item[1],\n",
    "                                            random_state=514)\n",
    "        \n",
    "        rf.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(rf, X_validate[features], y_validate).values\n",
    "\n",
    "        score = rf.score(X_validate[features], y_validate).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Random Forest',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}, Leaves: {item[1]}'},\n",
    "                                    index=[0])\n",
    "       \n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors\n",
    "def validate_knn(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_validate=subsets[3]\n",
    "    y_validate=subsets[4]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    k_range = range(3, 4)\n",
    "    scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train[features], y_train)\n",
    "        scores.append(knn.score(X_train[features], y_train))\n",
    "\n",
    "        model_id = 'Knn_'+f'{k}'\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(knn, X_validate[features], y_validate).values\n",
    "\n",
    "        score = knn.score(X_validate[features], y_validate).round(5)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Knn',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'K-Neighbors: {k}'},\n",
    "            index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.scatter(k_range, scores)\n",
    "    plt.xticks([0,5,10,15,20])\n",
    "    plt.show()\n",
    "    np.mean(scores)\n",
    "\n",
    "    \n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0])\n",
    "\n",
    "val_comparisons = model.create_comp_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_descriptions, val_comparisons =  validate_dtc(feat_set, validate_descriptions, val_comparisons, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_descriptions, val_comparisons =  validate_rf(feat_set, validate_descriptions, val_comparisons, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validate_descriptions, val_comparisons =  validate_knn(feat_set, validate_descriptions, val_comparisons, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_1</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_0</td>\n",
       "      <td>0.282100</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 7, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Knn_3</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)                      Type  \\\n",
       "1     DTC_0         0.307700  Decision Tree Classifier   \n",
       "4      RF_1         0.307700             Random Forest   \n",
       "0  Baseline         0.292135            Basic Baseline   \n",
       "3      RF_0         0.282100             Random Forest   \n",
       "5     Knn_3         0.256410                       Knn   \n",
       "\n",
       "                  Features Used           Parameters  \n",
       "1  ['word_count', 'lemmatized']             Depth: 5  \n",
       "4  ['word_count', 'lemmatized']  Depth: 7, Leaves: 2  \n",
       "0           Baseline Prediction                  n/a  \n",
       "3  ['word_count', 'lemmatized']  Depth: 7, Leaves: 1  \n",
       "5  ['word_count', 'lemmatized']       K-Neighbors: 3  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_descriptions.sort_values(by='Accuracy(Score)', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTC_0</th>\n",
       "      <th>DTC_1</th>\n",
       "      <th>RF_0</th>\n",
       "      <th>RF_1</th>\n",
       "      <th>Knn_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positives</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positives</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negatives</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negatives</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR/Recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative Rate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Positive</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Negative</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DTC_0  DTC_1  RF_0  RF_1   Knn_3\n",
       "Accuracy/Score         0.0    0.0   0.0   0.0  0.3333\n",
       "True Positives         0.0    0.0   0.0   0.0  1.0000\n",
       "False Positives        1.0    1.0   1.0   1.0  1.0000\n",
       "True Negatives         0.0    0.0   0.0   0.0  0.0000\n",
       "False Negatives        0.0    0.0   0.0   0.0  1.0000\n",
       "TPR/Recall             0.0    0.0   0.0   0.0  0.5000\n",
       "False Positive Rate    1.0    1.0   1.0   1.0  1.0000\n",
       "True Negative Rate     0.0    0.0   0.0   0.0  0.0000\n",
       "False Negative Rate    0.0    0.0   0.0   0.0  0.5000\n",
       "Precision              0.0    0.0   0.0   0.0  0.5000\n",
       "F1-Score               0.0    0.0   0.0   0.0  0.5000\n",
       "Support Positive       0.0    0.0   0.0   0.0  2.0000\n",
       "Support Negative       1.0    1.0   1.0   1.0  1.0000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Takeaways\n",
    "- Massive performance drop from Train set. \n",
    "- Indicative of over fitting. \n",
    "- Adjusting input data for hopeful performance gains.\n",
    "- Validation Performance on Top 5 from Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "- The Top performing model from Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Modeling Takeaways\n",
    "- THings did not go as plan.\n",
    "- Had to abandon gridsearch idea\n",
    "- Logistic Regression never provided much performance gain above baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
