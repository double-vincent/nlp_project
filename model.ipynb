{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#use multinomial naive bayes algorithm after the other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import wrangle, model\n",
    "\n",
    "from importlib import reload\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wrangle' from '/Users/sinao/codeup-data-science/nlp_project/wrangle.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(wrangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 201 stopwords\n",
      "---\n",
      "\n",
      "Removed 49 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n",
      "\n",
      "Removed 218 stopwords\n",
      "---\n",
      "\n",
      "Removed 401 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 50 stopwords\n",
      "---\n",
      "\n",
      "Removed 8 stopwords\n",
      "---\n",
      "\n",
      "Removed 158 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 44 stopwords\n",
      "---\n",
      "\n",
      "Removed 110 stopwords\n",
      "---\n",
      "\n",
      "Removed 500 stopwords\n",
      "---\n",
      "\n",
      "Removed 494 stopwords\n",
      "---\n",
      "\n",
      "Removed 31 stopwords\n",
      "---\n",
      "\n",
      "Removed 427 stopwords\n",
      "---\n",
      "\n",
      "Removed 76 stopwords\n",
      "---\n",
      "\n",
      "Removed 1 stopwords\n",
      "---\n",
      "\n",
      "Removed 175 stopwords\n",
      "---\n",
      "\n",
      "Removed 731 stopwords\n",
      "---\n",
      "\n",
      "Removed 68 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 358 stopwords\n",
      "---\n",
      "\n",
      "Removed 52 stopwords\n",
      "---\n",
      "\n",
      "Removed 15 stopwords\n",
      "---\n",
      "\n",
      "Removed 48 stopwords\n",
      "---\n",
      "\n",
      "Removed 100 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 134 stopwords\n",
      "---\n",
      "\n",
      "Removed 320 stopwords\n",
      "---\n",
      "\n",
      "Removed 27 stopwords\n",
      "---\n",
      "\n",
      "Removed 74 stopwords\n",
      "---\n",
      "\n",
      "Removed 88 stopwords\n",
      "---\n",
      "\n",
      "Removed 8 stopwords\n",
      "---\n",
      "\n",
      "Removed 272 stopwords\n",
      "---\n",
      "\n",
      "Removed 123 stopwords\n",
      "---\n",
      "\n",
      "Removed 389 stopwords\n",
      "---\n",
      "\n",
      "Removed 81 stopwords\n",
      "---\n",
      "\n",
      "Removed 187 stopwords\n",
      "---\n",
      "\n",
      "Removed 23 stopwords\n",
      "---\n",
      "\n",
      "Removed 25 stopwords\n",
      "---\n",
      "\n",
      "Removed 114 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 199 stopwords\n",
      "---\n",
      "\n",
      "Removed 95 stopwords\n",
      "---\n",
      "\n",
      "Removed 22 stopwords\n",
      "---\n",
      "\n",
      "Removed 220 stopwords\n",
      "---\n",
      "\n",
      "Removed 56 stopwords\n",
      "---\n",
      "\n",
      "Removed 20 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 10 stopwords\n",
      "---\n",
      "\n",
      "Removed 512 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 24 stopwords\n",
      "---\n",
      "\n",
      "Removed 926 stopwords\n",
      "---\n",
      "\n",
      "Removed 42 stopwords\n",
      "---\n",
      "\n",
      "Removed 115 stopwords\n",
      "---\n",
      "\n",
      "Removed 6 stopwords\n",
      "---\n",
      "\n",
      "Removed 30 stopwords\n",
      "---\n",
      "\n",
      "Removed 852 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 115 stopwords\n",
      "---\n",
      "\n",
      "Removed 61 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 53 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 157 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 1030 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 136 stopwords\n",
      "---\n",
      "\n",
      "Removed 16 stopwords\n",
      "---\n",
      "\n",
      "Removed 14 stopwords\n",
      "---\n",
      "\n",
      "Removed 61 stopwords\n",
      "---\n",
      "\n",
      "Removed 72 stopwords\n",
      "---\n",
      "\n",
      "Removed 52 stopwords\n",
      "---\n",
      "\n",
      "Removed 24 stopwords\n",
      "---\n",
      "\n",
      "Removed 13 stopwords\n",
      "---\n",
      "\n",
      "Removed 57 stopwords\n",
      "---\n",
      "\n",
      "Removed 84 stopwords\n",
      "---\n",
      "\n",
      "Removed 78 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 32 stopwords\n",
      "---\n",
      "\n",
      "Removed 185 stopwords\n",
      "---\n",
      "\n",
      "Removed 48 stopwords\n",
      "---\n",
      "\n",
      "Removed 150 stopwords\n",
      "---\n",
      "\n",
      "Removed 385 stopwords\n",
      "---\n",
      "\n",
      "Removed 561 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 64 stopwords\n",
      "---\n",
      "\n",
      "Removed 113 stopwords\n",
      "---\n",
      "\n",
      "Removed 110 stopwords\n",
      "---\n",
      "\n",
      "Removed 285 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "df = wrangle.get_search_csv()\n",
    "df = wrangle.prep_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['language', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      p aligncenter img srchttpsuserimagesgithubuser...\n",
       "1      platform12 github license34 github license56 1...\n",
       "2      dunk httpsrawgithubusercontentcomnaoyashigadun...\n",
       "3      p aligncenter img srcstaticimganalysisgif widt...\n",
       "5      nba nodejs client nbacom api endpoint npm inst...\n",
       "                             ...                        \n",
       "102    basketballrecleague purpose project demonstrat...\n",
       "103    nbastartactiveplayersbot python selenium scrip...\n",
       "106    shoot teamshttpsshootforteamscom app designed ...\n",
       "107    pandasbasketball pandasbasketball small module...\n",
       "108    basketball game demo base opengl grapic render...\n",
       "Name: lemmatized, Length: 98, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Explore various models and feature combinations.\n",
    "Choose **three** models to validate. Choose **one** to test. \n",
    "Artifact: `model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Preparation\n",
    "- Create function to vectorize, scale, and split data\n",
    "- Create word_count feature --> backport to wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Prediction and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.loc[i, 'word_count'] = len([word for word in df.loc[i, 'lemmatized'].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      483.0\n",
       "1      478.0\n",
       "2        5.0\n",
       "3      427.0\n",
       "5      571.0\n",
       "       ...  \n",
       "102     78.0\n",
       "103    178.0\n",
       "106    140.0\n",
       "107    474.0\n",
       "108     51.0\n",
       "Name: word_count, Length: 98, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorize_split(df):\n",
    "\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        \n",
    "    ---\n",
    "    Parameters:\n",
    "        \n",
    "    ---\n",
    "    Returns:\n",
    "        X_train, y_train, X_validate, y_validate, X_test, y_test: data subsets\n",
    "    \"\"\"\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    df['lemmatized'] = tfidf.fit_transform(df.lemmatized).todense()\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    df.word_count = scaler.fit_transform(df.word_count)\n",
    "\n",
    "    train_validate, test = train_test_split(df, test_size=.3, random_state=514, stratify=df['language'])\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=514, stratify=train_validate['language'])\n",
    "\n",
    "    # split data into Big X, small y sets \n",
    "    X_train = train.drop(columns=['language'])\n",
    "    y_train = train.language\n",
    "\n",
    "    X_validate = validate.drop(columns=['language'])\n",
    "    y_validate = validate.language\n",
    "\n",
    "    X_test = test.drop(columns=['language'])\n",
    "    y_test = test.language\n",
    "\n",
    "    return train, X_train, y_train, X_validate, y_validate, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[4.830e+02 4.780e+02 5.000e+00 4.270e+02 5.710e+02 9.100e+01 9.500e+01\n 3.000e+01 4.630e+02 8.400e+01 7.900e+01 1.940e+02 6.630e+02 9.140e+02\n 1.030e+02 6.660e+02 1.250e+02 4.500e+01 3.210e+02 1.622e+03 9.100e+01\n 1.230e+02 8.510e+02 1.620e+02 4.800e+01 9.600e+01 2.470e+02 3.510e+02\n 1.000e+00 4.410e+02 8.910e+02 5.900e+01 1.070e+02 1.660e+02 6.300e+01\n 5.300e+02 6.820e+02 6.210e+02 3.380e+02 2.500e+02 2.240e+02 6.500e+01\n 3.770e+02 1.000e+00 4.480e+02 2.890e+02 4.900e+01 4.980e+02 9.200e+01\n 4.300e+01 7.000e+00 1.610e+02 2.500e+01 9.080e+02 2.000e+00 6.300e+01\n 1.292e+03 4.800e+01 1.890e+02 1.500e+02 6.700e+01 4.801e+03 1.260e+02\n 2.440e+02 9.600e+01 6.000e+00 1.000e+00 1.140e+02 4.700e+01 3.380e+02\n 6.900e+01 1.225e+03 5.900e+01 1.430e+02 2.170e+02 1.330e+02 6.900e+01\n 9.500e+01 1.480e+02 1.520e+02 5.700e+01 1.500e+01 1.750e+02 2.120e+02\n 1.560e+02 5.500e+01 7.700e+01 4.570e+02 9.200e+01 4.350e+02 5.640e+02\n 6.410e+02 1.650e+02 7.800e+01 1.780e+02 1.400e+02 4.740e+02 5.100e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sinao/codeup-data-science/nlp_project/model.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y120sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train, X_train, y_train, X_validate, y_validate, X_test, y_test \u001b[39m=\u001b[39m vectorize_split(df)\n",
      "\u001b[1;32m/Users/sinao/codeup-data-science/nlp_project/model.ipynb Cell 15\u001b[0m in \u001b[0;36mvectorize_split\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y120sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlemmatized\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39mfit_transform(df\u001b[39m.\u001b[39mlemmatized)\u001b[39m.\u001b[39mtodense()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y120sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m scaler \u001b[39m=\u001b[39m preprocessing\u001b[39m.\u001b[39mMinMaxScaler()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y120sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m df\u001b[39m.\u001b[39mword_count \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(df\u001b[39m.\u001b[39;49mword_count)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y120sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m train_validate, test \u001b[39m=\u001b[39m train_test_split(df, test_size\u001b[39m=\u001b[39m\u001b[39m.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m514\u001b[39m, stratify\u001b[39m=\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y120sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m train, validate \u001b[39m=\u001b[39m train_test_split(train_validate, test_size\u001b[39m=\u001b[39m\u001b[39m.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m514\u001b[39m, stratify\u001b[39m=\u001b[39mtrain_validate[\u001b[39m'\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:416\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 416\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:453\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m     )\n\u001b[1;32m    452\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 453\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    454\u001b[0m     X,\n\u001b[1;32m    455\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[1;32m    456\u001b[0m     estimator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    457\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    458\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    461\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    462\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    567\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:769\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 769\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    770\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    771\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    772\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    773\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    774\u001b[0m         )\n\u001b[1;32m    776\u001b[0m \u001b[39m# make sure we actually converted to numeric:\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mOUSV\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[4.830e+02 4.780e+02 5.000e+00 4.270e+02 5.710e+02 9.100e+01 9.500e+01\n 3.000e+01 4.630e+02 8.400e+01 7.900e+01 1.940e+02 6.630e+02 9.140e+02\n 1.030e+02 6.660e+02 1.250e+02 4.500e+01 3.210e+02 1.622e+03 9.100e+01\n 1.230e+02 8.510e+02 1.620e+02 4.800e+01 9.600e+01 2.470e+02 3.510e+02\n 1.000e+00 4.410e+02 8.910e+02 5.900e+01 1.070e+02 1.660e+02 6.300e+01\n 5.300e+02 6.820e+02 6.210e+02 3.380e+02 2.500e+02 2.240e+02 6.500e+01\n 3.770e+02 1.000e+00 4.480e+02 2.890e+02 4.900e+01 4.980e+02 9.200e+01\n 4.300e+01 7.000e+00 1.610e+02 2.500e+01 9.080e+02 2.000e+00 6.300e+01\n 1.292e+03 4.800e+01 1.890e+02 1.500e+02 6.700e+01 4.801e+03 1.260e+02\n 2.440e+02 9.600e+01 6.000e+00 1.000e+00 1.140e+02 4.700e+01 3.380e+02\n 6.900e+01 1.225e+03 5.900e+01 1.430e+02 2.170e+02 1.330e+02 6.900e+01\n 9.500e+01 1.480e+02 1.520e+02 5.700e+01 1.500e+01 1.750e+02 2.120e+02\n 1.560e+02 5.500e+01 7.700e+01 4.570e+02 9.200e+01 4.350e+02 5.640e+02\n 6.410e+02 1.650e+02 7.800e+01 1.780e+02 1.400e+02 4.740e+02 5.100e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "train, X_train, y_train, X_validate, y_validate, X_test, y_test = vectorize_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python              0.297872\n",
       "Other               0.255319\n",
       "Jupyter Notebook    0.127660\n",
       "JavaScript          0.127660\n",
       "R                   0.127660\n",
       "HTML                0.063830\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formulate baseline prediction ->base prediction is python\n",
    "train.language.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, X_df, y_df):\n",
    "    \"\"\"\n",
    "    purpose: function executes performs computations to produce evaulation metrics for a given model\n",
    "\n",
    "    inputs: \n",
    "        model: a model that has been previous fit to spec\n",
    "        X_df: a dataframe featuring the X subset of data for evaluation\n",
    "        y_df: a dataframe featuring the model target variable\n",
    "\n",
    "    Returns: a rounded pandas Series that can be adding to an evaulation metric comparison chart\n",
    "    \"\"\"\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_df)\n",
    "\n",
    "    # Estimate Probability \n",
    "    y_pred_proba = model.predict_proba(X_df)\n",
    "\n",
    "    #create confusion matrix\n",
    "    confusion = confusion_matrix(y_df, y_pred)\n",
    "\n",
    "    #assign results of confusion matrix to variables\n",
    "    true_negative = confusion[0,0]\n",
    "    false_positive = confusion[0,1]\n",
    "    false_negative = confusion[1,0]\n",
    "    true_positive = confusion[1,1]\n",
    "\n",
    "    #accuracy\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "\n",
    "    #true positive rate / recall\n",
    "    recall = true_positive / (true_positive +false_negative)\n",
    "\n",
    "    #false positive rate\n",
    "    false_positive_rate = false_positive / (true_negative + false_positive)\n",
    "\n",
    "    #true negative rate\n",
    "    true_negative_rate = true_negative / (true_negative + false_positive)\n",
    "\n",
    "    #false negative rate\n",
    "    false_negative_rate = false_negative / (false_negative + true_positive)\n",
    "\n",
    "    #precision\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "    #f1-score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    #support\n",
    "    support_positive = true_positive + false_negative\n",
    "    support_negative = false_positive + true_negative\n",
    "\n",
    "    metrics = pd.Series([accuracy, true_positive, false_positive, true_negative, false_negative,\\\n",
    "                        recall, false_positive_rate, true_negative_rate, false_negative_rate, \\\n",
    "                        precision, f1_score, support_positive, support_negative])\n",
    "                        \n",
    "    return metrics.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_chart():\n",
    "    \"\"\"\n",
    "    purpose: to create a dataframe with an index reflecting compuation metrics for future models\n",
    "\n",
    "    returns: a pandas dataframe with appropriately set index\n",
    "    \"\"\"\n",
    "    statistics = ['Accuracy/Score',\n",
    "    'True Positives' , 'False Positives', 'True Negatives', 'False Negatives', \\\n",
    "    'TPR/Recall', 'False Positive Rate', 'True Negative Rate', 'False Negative Rate', \\\n",
    "    'Precision', 'F1-Score', 'Support Positive', 'Support Negative']\n",
    "\n",
    "\n",
    "    return pd.DataFrame({}, index=statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy for \"language\" prediction:  29.8%\n"
     ]
    }
   ],
   "source": [
    "# formulate baseline accuracy\n",
    "baseline_accuracy = (y_train == 'Python').mean()\n",
    "\n",
    "print(f'Baseline Accuracy for \\\"language\\\" prediction: {(baseline_accuracy * 100): .3}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_description_chart(y):\n",
    "\n",
    "    # formulate baseline accuracy\n",
    "    baseline_accuracy = (y == 'Python').mean()\n",
    "\n",
    "    descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "                                'Accuracy(Score)': baseline_accuracy,\n",
    "                                'Type': 'Basic Baseline',\n",
    "                                'Features Used': 'Baseline Prediction',\n",
    "                                'Parameters': 'n/a'\n",
    "                                }, index=[0])\n",
    "    \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)            Type        Features Used Parameters\n",
       "0  Baseline         0.297872  Basic Baseline  Baseline Prediction        n/a\n",
       "1  Baseline         0.297872  Basic Baseline  Baseline Prediction        n/a"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([model_descriptions, pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0]) ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_chart = model.create_comp_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_set = ['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [train, X_train, y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dtc(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product(np.arange(20,25,2)))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'DTC_'+f'{idx}'\n",
    "        dtc = DecisionTreeClassifier(max_depth=item[0],\\\n",
    "                                            random_state=514)\n",
    "        \n",
    "        dtc.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(dtc, X_train[features], y_train).values\n",
    "\n",
    "        score = dtc.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Decision Tree Classifier',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}'},\n",
    "                                    index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n"
     ]
    }
   ],
   "source": [
    "model_descriptions, comparison_chart =  model_dtc(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count']</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count']</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count']</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)                      Type        Features Used  \\\n",
       "0  Baseline         0.297872            Basic Baseline  Baseline Prediction   \n",
       "1     DTC_0         0.297900  Decision Tree Classifier       ['word_count']   \n",
       "2     DTC_1         0.297900  Decision Tree Classifier       ['word_count']   \n",
       "3     DTC_2         0.297900  Decision Tree Classifier       ['word_count']   \n",
       "\n",
       "  Parameters  \n",
       "0        n/a  \n",
       "1  Depth: 20  \n",
       "2  Depth: 22  \n",
       "3  Depth: 24  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product([20,25], [3,2,1]))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'RF_'+f'{idx}'\n",
    "        rf = RandomForestClassifier(max_depth=item[0],\\\n",
    "                                            min_samples_leaf=item[1],\n",
    "                                            random_state=514)\n",
    "        \n",
    "        rf.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(rf, X_train[features], y_train).values\n",
    "\n",
    "        score = rf.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Random Forest',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}, Leaves: {item[1]}'},\n",
    "                                    index=[0])\n",
    "       \n",
    "    model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n"
     ]
    }
   ],
   "source": [
    "model_descriptions, comparison_chart = model_rf(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways - Random Forest\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors\n",
    "def model_knn(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    k_range = range(1, 15)\n",
    "    scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train[features], y_train)\n",
    "        scores.append(knn.score(X_train[features], y_train))\n",
    "\n",
    "        model_id = 'Knn_'+f'{k}'\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(knn, X_train[features], y_train).values\n",
    "\n",
    "        score = knn.score(X_train[features], y_train).round(5)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Knn',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'K-Neighbors: {k}'},\n",
    "            index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.scatter(k_range, scores)\n",
    "    plt.xticks([0,5,10,15,20])\n",
    "    plt.show()\n",
    "    np.mean(scores)\n",
    "\n",
    "    \n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:258: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:261: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = true_positive / (true_positive +false_negative)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:264: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_positive_rate = false_positive / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:267: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  true_negative_rate = true_negative / (true_negative + false_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:270: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  false_negative_rate = false_negative / (false_negative + true_positive)\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:273: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = true_positive / (true_positive + false_positive)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions, comparison_chart = model_knn(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 25, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_7</td>\n",
       "      <td>0.96675</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Accuracy(Score)                      Type  \\\n",
       "0  DTC_1          0.96820  Decision Tree Classifier   \n",
       "0  DTC_2          0.96820  Decision Tree Classifier   \n",
       "0   RF_5          0.96820             Random Forest   \n",
       "0  DTC_0          0.96820  Decision Tree Classifier   \n",
       "0  Knn_7          0.96675                       Knn   \n",
       "\n",
       "                                       Features Used            Parameters  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...             Depth: 22  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...             Depth: 24  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...  Depth: 25, Leaves: 1  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...             Depth: 20  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...        K-Neighbors: 7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions.sort_values(by='Accuracy(Score)', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lr(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    cees = [.1,.5,1]\n",
    "    solver = ['newton-cg', 'lbfgs']\n",
    "    weights = [None, 'balanced']\n",
    "\n",
    "    selectors = list(product(cees, solver, weights))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'LR_'+f'{idx}'\n",
    "        lr = LogisticRegression(C=item[0],\\\n",
    "                                solver=item[1],\n",
    "                                class_weight=item[2],\n",
    "                                max_iter=400,\n",
    "                                random_state=514)\n",
    "        \n",
    "        lr.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(lr, X_train[features], y_train).values\n",
    "\n",
    "        score = lr.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        model_descriptions.loc[idx+1] = {'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Logistic Regression',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'C: {item[0]}, Solver: {item[1]}, Class Weight: {item[2]}'\n",
    "        }\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_descriptions, comparison_chart = model_lr(feat_set, model_descriptions, comparison_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description and Comparison Charts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Basic Baseline              0.962882\n",
       "Decision Tree Classifier    0.968200\n",
       "Knn                         0.961197\n",
       "Logistic Regression         0.806528\n",
       "Random Forest               0.968200\n",
       "Name: Accuracy(Score), dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions.groupby('Type')['Accuracy(Score)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 25, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR_8</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR_16</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR_14</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR_4</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LR_10</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_2</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR_12</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_0</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR_6</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_8</td>\n",
       "      <td>0.96675</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_7</td>\n",
       "      <td>0.96675</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_10</td>\n",
       "      <td>0.96671</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_6</td>\n",
       "      <td>0.96671</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_5</td>\n",
       "      <td>0.96668</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_11</td>\n",
       "      <td>0.96664</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_12</td>\n",
       "      <td>0.96664</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Accuracy(Score)                      Type  \\\n",
       "0    DTC_0          0.96820  Decision Tree Classifier   \n",
       "0    DTC_1          0.96820  Decision Tree Classifier   \n",
       "0    DTC_2          0.96820  Decision Tree Classifier   \n",
       "0     RF_5          0.96820             Random Forest   \n",
       "9     LR_8          0.96770       Logistic Regression   \n",
       "17   LR_16          0.96770       Logistic Regression   \n",
       "15   LR_14          0.96770       Logistic Regression   \n",
       "5     LR_4          0.96770       Logistic Regression   \n",
       "11   LR_10          0.96770       Logistic Regression   \n",
       "3     LR_2          0.96770       Logistic Regression   \n",
       "13   LR_12          0.96770       Logistic Regression   \n",
       "1     LR_0          0.96770       Logistic Regression   \n",
       "7     LR_6          0.96770       Logistic Regression   \n",
       "0    Knn_8          0.96675                       Knn   \n",
       "0    Knn_7          0.96675                       Knn   \n",
       "0   Knn_10          0.96671                       Knn   \n",
       "0    Knn_6          0.96671                       Knn   \n",
       "0    Knn_5          0.96668                       Knn   \n",
       "0   Knn_11          0.96664                       Knn   \n",
       "0   Knn_12          0.96664                       Knn   \n",
       "\n",
       "                                        Features Used  \\\n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "9   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "17  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "15  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "5   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "11  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "3   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "13  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "1   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "7   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "\n",
       "                                       Parameters  \n",
       "0                                       Depth: 20  \n",
       "0                                       Depth: 22  \n",
       "0                                       Depth: 24  \n",
       "0                            Depth: 25, Leaves: 1  \n",
       "9       C: 0.5, Solver: lbfgs, Class Weight: None  \n",
       "17          C: 1, Solver: sag, Class Weight: None  \n",
       "15        C: 1, Solver: lbfgs, Class Weight: None  \n",
       "5         C: 0.1, Solver: sag, Class Weight: None  \n",
       "11        C: 0.5, Solver: sag, Class Weight: None  \n",
       "3       C: 0.1, Solver: lbfgs, Class Weight: None  \n",
       "13    C: 1, Solver: newton-cg, Class Weight: None  \n",
       "1   C: 0.1, Solver: newton-cg, Class Weight: None  \n",
       "7   C: 0.5, Solver: newton-cg, Class Weight: None  \n",
       "0                                  K-Neighbors: 8  \n",
       "0                                  K-Neighbors: 7  \n",
       "0                                 K-Neighbors: 10  \n",
       "0                                  K-Neighbors: 6  \n",
       "0                                  K-Neighbors: 5  \n",
       "0                                 K-Neighbors: 11  \n",
       "0                                 K-Neighbors: 12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model descriptions\n",
    "model_descriptions.sort_values('Accuracy(Score)', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_17</th>\n",
       "      <td>0.4936</td>\n",
       "      <td>13491.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>13903.0</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_5</th>\n",
       "      <td>0.6577</td>\n",
       "      <td>18074.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>9320.0</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.3968</td>\n",
       "      <td>0.6032</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_3</th>\n",
       "      <td>0.6577</td>\n",
       "      <td>18074.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>9320.0</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.3968</td>\n",
       "      <td>0.6032</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_1</th>\n",
       "      <td>0.6577</td>\n",
       "      <td>18074.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>9320.0</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.3968</td>\n",
       "      <td>0.6032</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_15</th>\n",
       "      <td>0.6581</td>\n",
       "      <td>18086.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>9308.0</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_13</th>\n",
       "      <td>0.6581</td>\n",
       "      <td>18086.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>9308.0</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_9</th>\n",
       "      <td>0.6582</td>\n",
       "      <td>18089.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>9305.0</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_7</th>\n",
       "      <td>0.6583</td>\n",
       "      <td>18091.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>9303.0</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.3396</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_11</th>\n",
       "      <td>0.7088</td>\n",
       "      <td>19651.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.4877</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.8259</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_2</th>\n",
       "      <td>0.9271</td>\n",
       "      <td>26117.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_1</th>\n",
       "      <td>0.9364</td>\n",
       "      <td>26416.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_4</th>\n",
       "      <td>0.9631</td>\n",
       "      <td>27245.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_3</th>\n",
       "      <td>0.9637</td>\n",
       "      <td>27273.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.8646</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_4</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_6</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_3</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_10</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27390.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_2</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_2</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27390.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "LR_17          0.4936         13491.0            504.0           552.0   \n",
       "LR_5           0.6577         18074.0            419.0           637.0   \n",
       "LR_3           0.6577         18074.0            419.0           637.0   \n",
       "LR_1           0.6577         18074.0            419.0           637.0   \n",
       "LR_15          0.6581         18086.0            418.0           638.0   \n",
       "LR_13          0.6581         18086.0            418.0           638.0   \n",
       "LR_9           0.6582         18089.0            418.0           638.0   \n",
       "LR_7           0.6583         18091.0            418.0           638.0   \n",
       "LR_11          0.7088         19651.0            541.0           515.0   \n",
       "Knn_2          0.9271         26117.0            796.0           260.0   \n",
       "Knn_1          0.9364         26416.0            830.0           226.0   \n",
       "Knn_4          0.9631         27245.0            900.0           156.0   \n",
       "Knn_3          0.9637         27273.0            913.0           143.0   \n",
       "LR_2           0.9677         27394.0            918.0           138.0   \n",
       "RF_4           0.9677         27394.0            918.0           138.0   \n",
       "LR_6           0.9677         27394.0            918.0           138.0   \n",
       "RF_3           0.9677         27394.0            918.0           138.0   \n",
       "LR_4           0.9677         27394.0            918.0           138.0   \n",
       "LR_0           0.9677         27394.0            918.0           138.0   \n",
       "LR_10          0.9677         27394.0            918.0           138.0   \n",
       "RF_5           0.9682         27390.0            900.0           156.0   \n",
       "DTC_2          0.9682         27379.0            889.0           167.0   \n",
       "DTC_1          0.9682         27379.0            889.0           167.0   \n",
       "RF_2           0.9682         27390.0            900.0           156.0   \n",
       "DTC_0          0.9682         27379.0            889.0           167.0   \n",
       "\n",
       "       False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "LR_17          13903.0      0.4925               0.4773              0.5227   \n",
       "LR_5            9320.0      0.6598               0.3968              0.6032   \n",
       "LR_3            9320.0      0.6598               0.3968              0.6032   \n",
       "LR_1            9320.0      0.6598               0.3968              0.6032   \n",
       "LR_15           9308.0      0.6602               0.3958              0.6042   \n",
       "LR_13           9308.0      0.6602               0.3958              0.6042   \n",
       "LR_9            9305.0      0.6603               0.3958              0.6042   \n",
       "LR_7            9303.0      0.6604               0.3958              0.6042   \n",
       "LR_11           7743.0      0.7173               0.5123              0.4877   \n",
       "Knn_2           1277.0      0.9534               0.7538              0.2462   \n",
       "Knn_1            978.0      0.9643               0.7860              0.2140   \n",
       "Knn_4            149.0      0.9946               0.8523              0.1477   \n",
       "Knn_3            121.0      0.9956               0.8646              0.1354   \n",
       "LR_2               0.0      1.0000               0.8693              0.1307   \n",
       "RF_4               0.0      1.0000               0.8693              0.1307   \n",
       "LR_6               0.0      1.0000               0.8693              0.1307   \n",
       "RF_3               0.0      1.0000               0.8693              0.1307   \n",
       "LR_4               0.0      1.0000               0.8693              0.1307   \n",
       "LR_0               0.0      1.0000               0.8693              0.1307   \n",
       "LR_10              0.0      1.0000               0.8693              0.1307   \n",
       "RF_5               4.0      0.9999               0.8523              0.1477   \n",
       "DTC_2             15.0      0.9995               0.8419              0.1581   \n",
       "DTC_1             15.0      0.9995               0.8419              0.1581   \n",
       "RF_2               4.0      0.9999               0.8523              0.1477   \n",
       "DTC_0             15.0      0.9995               0.8419              0.1581   \n",
       "\n",
       "       False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "LR_17               0.5075     0.9640    0.6519           27394.0   \n",
       "LR_5                0.3402     0.9773    0.7878           27394.0   \n",
       "LR_3                0.3402     0.9773    0.7878           27394.0   \n",
       "LR_1                0.3402     0.9773    0.7878           27394.0   \n",
       "LR_15               0.3398     0.9774    0.7881           27394.0   \n",
       "LR_13               0.3398     0.9774    0.7881           27394.0   \n",
       "LR_9                0.3397     0.9774    0.7882           27394.0   \n",
       "LR_7                0.3396     0.9774    0.7882           27394.0   \n",
       "LR_11               0.2827     0.9732    0.8259           27394.0   \n",
       "Knn_2               0.0466     0.9704    0.9618           27394.0   \n",
       "Knn_1               0.0357     0.9695    0.9669           27394.0   \n",
       "Knn_4               0.0054     0.9680    0.9811           27394.0   \n",
       "Knn_3               0.0044     0.9676    0.9814           27394.0   \n",
       "LR_2                0.0000     0.9676    0.9835           27394.0   \n",
       "RF_4                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_6                0.0000     0.9676    0.9835           27394.0   \n",
       "RF_3                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_4                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_0                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_10               0.0000     0.9676    0.9835           27394.0   \n",
       "RF_5                0.0001     0.9682    0.9838           27394.0   \n",
       "DTC_2               0.0005     0.9686    0.9838           27394.0   \n",
       "DTC_1               0.0005     0.9686    0.9838           27394.0   \n",
       "RF_2                0.0001     0.9682    0.9838           27394.0   \n",
       "DTC_0               0.0005     0.9686    0.9838           27394.0   \n",
       "\n",
       "       Support Negative  \n",
       "LR_17            1056.0  \n",
       "LR_5             1056.0  \n",
       "LR_3             1056.0  \n",
       "LR_1             1056.0  \n",
       "LR_15            1056.0  \n",
       "LR_13            1056.0  \n",
       "LR_9             1056.0  \n",
       "LR_7             1056.0  \n",
       "LR_11            1056.0  \n",
       "Knn_2            1056.0  \n",
       "Knn_1            1056.0  \n",
       "Knn_4            1056.0  \n",
       "Knn_3            1056.0  \n",
       "LR_2             1056.0  \n",
       "RF_4             1056.0  \n",
       "LR_6             1056.0  \n",
       "RF_3             1056.0  \n",
       "LR_4             1056.0  \n",
       "LR_0             1056.0  \n",
       "LR_10            1056.0  \n",
       "RF_5             1056.0  \n",
       "DTC_2            1056.0  \n",
       "DTC_1            1056.0  \n",
       "RF_2             1056.0  \n",
       "DTC_0            1056.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_chart.T.sort_values(by='True Negatives', ascending=False).head(25).sort_values(by=['Accuracy/Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_2</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_2</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27390.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27390.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_0</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_1</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_3</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_4</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_14</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_16</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_10</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_8</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_6</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_12</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_6</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27386.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_5</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27387.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_7</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_8</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_10</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_12</th>\n",
       "      <td>0.9666</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_11</th>\n",
       "      <td>0.9666</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "DTC_0           0.9682         27379.0            889.0           167.0   \n",
       "DTC_2           0.9682         27379.0            889.0           167.0   \n",
       "DTC_1           0.9682         27379.0            889.0           167.0   \n",
       "RF_2            0.9682         27390.0            900.0           156.0   \n",
       "RF_5            0.9682         27390.0            900.0           156.0   \n",
       "LR_2            0.9677         27394.0            918.0           138.0   \n",
       "RF_0            0.9677         27394.0            918.0           138.0   \n",
       "RF_1            0.9677         27394.0            918.0           138.0   \n",
       "RF_3            0.9677         27394.0            918.0           138.0   \n",
       "RF_4            0.9677         27394.0            918.0           138.0   \n",
       "LR_14           0.9677         27394.0            918.0           138.0   \n",
       "LR_16           0.9677         27394.0            918.0           138.0   \n",
       "LR_10           0.9677         27394.0            918.0           138.0   \n",
       "LR_8            0.9677         27394.0            918.0           138.0   \n",
       "LR_6            0.9677         27394.0            918.0           138.0   \n",
       "LR_4            0.9677         27394.0            918.0           138.0   \n",
       "LR_0            0.9677         27394.0            918.0           138.0   \n",
       "LR_12           0.9677         27394.0            918.0           138.0   \n",
       "Knn_6           0.9667         27386.0            939.0           117.0   \n",
       "Knn_5           0.9667         27387.0            941.0           115.0   \n",
       "Knn_7           0.9667         27394.0            946.0           110.0   \n",
       "Knn_8           0.9667         27394.0            946.0           110.0   \n",
       "Knn_10          0.9667         27394.0            947.0           109.0   \n",
       "Knn_12          0.9666         27394.0            949.0           107.0   \n",
       "Knn_11          0.9666         27394.0            949.0           107.0   \n",
       "\n",
       "        False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "DTC_0              15.0      0.9995               0.8419              0.1581   \n",
       "DTC_2              15.0      0.9995               0.8419              0.1581   \n",
       "DTC_1              15.0      0.9995               0.8419              0.1581   \n",
       "RF_2                4.0      0.9999               0.8523              0.1477   \n",
       "RF_5                4.0      0.9999               0.8523              0.1477   \n",
       "LR_2                0.0      1.0000               0.8693              0.1307   \n",
       "RF_0                0.0      1.0000               0.8693              0.1307   \n",
       "RF_1                0.0      1.0000               0.8693              0.1307   \n",
       "RF_3                0.0      1.0000               0.8693              0.1307   \n",
       "RF_4                0.0      1.0000               0.8693              0.1307   \n",
       "LR_14               0.0      1.0000               0.8693              0.1307   \n",
       "LR_16               0.0      1.0000               0.8693              0.1307   \n",
       "LR_10               0.0      1.0000               0.8693              0.1307   \n",
       "LR_8                0.0      1.0000               0.8693              0.1307   \n",
       "LR_6                0.0      1.0000               0.8693              0.1307   \n",
       "LR_4                0.0      1.0000               0.8693              0.1307   \n",
       "LR_0                0.0      1.0000               0.8693              0.1307   \n",
       "LR_12               0.0      1.0000               0.8693              0.1307   \n",
       "Knn_6               8.0      0.9997               0.8892              0.1108   \n",
       "Knn_5               7.0      0.9997               0.8911              0.1089   \n",
       "Knn_7               0.0      1.0000               0.8958              0.1042   \n",
       "Knn_8               0.0      1.0000               0.8958              0.1042   \n",
       "Knn_10              0.0      1.0000               0.8968              0.1032   \n",
       "Knn_12              0.0      1.0000               0.8987              0.1013   \n",
       "Knn_11              0.0      1.0000               0.8987              0.1013   \n",
       "\n",
       "        False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "DTC_0                0.0005     0.9686    0.9838           27394.0   \n",
       "DTC_2                0.0005     0.9686    0.9838           27394.0   \n",
       "DTC_1                0.0005     0.9686    0.9838           27394.0   \n",
       "RF_2                 0.0001     0.9682    0.9838           27394.0   \n",
       "RF_5                 0.0001     0.9682    0.9838           27394.0   \n",
       "LR_2                 0.0000     0.9676    0.9835           27394.0   \n",
       "RF_0                 0.0000     0.9676    0.9835           27394.0   \n",
       "RF_1                 0.0000     0.9676    0.9835           27394.0   \n",
       "RF_3                 0.0000     0.9676    0.9835           27394.0   \n",
       "RF_4                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_14                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_16                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_10                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_8                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_6                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_4                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_0                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_12                0.0000     0.9676    0.9835           27394.0   \n",
       "Knn_6                0.0003     0.9668    0.9830           27394.0   \n",
       "Knn_5                0.0003     0.9668    0.9830           27394.0   \n",
       "Knn_7                0.0000     0.9666    0.9830           27394.0   \n",
       "Knn_8                0.0000     0.9666    0.9830           27394.0   \n",
       "Knn_10               0.0000     0.9666    0.9830           27394.0   \n",
       "Knn_12               0.0000     0.9665    0.9830           27394.0   \n",
       "Knn_11               0.0000     0.9665    0.9830           27394.0   \n",
       "\n",
       "        Support Negative  \n",
       "DTC_0             1056.0  \n",
       "DTC_2             1056.0  \n",
       "DTC_1             1056.0  \n",
       "RF_2              1056.0  \n",
       "RF_5              1056.0  \n",
       "LR_2              1056.0  \n",
       "RF_0              1056.0  \n",
       "RF_1              1056.0  \n",
       "RF_3              1056.0  \n",
       "RF_4              1056.0  \n",
       "LR_14             1056.0  \n",
       "LR_16             1056.0  \n",
       "LR_10             1056.0  \n",
       "LR_8              1056.0  \n",
       "LR_6              1056.0  \n",
       "LR_4              1056.0  \n",
       "LR_0              1056.0  \n",
       "LR_12             1056.0  \n",
       "Knn_6             1056.0  \n",
       "Knn_5             1056.0  \n",
       "Knn_7             1056.0  \n",
       "Knn_8             1056.0  \n",
       "Knn_10            1056.0  \n",
       "Knn_12            1056.0  \n",
       "Knn_11            1056.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_chart.T.sort_values(by='Accuracy/Score', ascending=False).head(25).sort_values(by=['False Positives'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation Takeaways\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation Takeaways\n",
    "- Goal:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20 = model_descriptions.sort_values('Accuracy(Score)', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selectors(parameters):\n",
    "    removal_list = ['Depth: ','K-Neighbors: ','Leaves: ','C: ',' Solver: ', ' Class Weight: ']\n",
    "\n",
    "    for word in removal_list:\n",
    "        parameters = parameters.replace(word, \"\")\n",
    "\n",
    "    return parameters.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_on_validation(descriptions, subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_validate= subsets[3]\n",
    "    y_validate = subsets[4]\n",
    "\n",
    "    \n",
    "    validate_metrics = create_comp_chart()\n",
    "    val_descriptions = create_description_chart(y_validate)\n",
    "    \n",
    "    #feat_set = descriptions.iloc[1]['Features Used'].strip('\\[]\\'').split('\\', \\'')\n",
    "    print(descriptions.index)\n",
    "    for idx in descriptions.index:\n",
    "\n",
    "        model_id = descriptions.loc[idx]['Model']\n",
    "        feat_set = descriptions.loc[idx]['Features Used'].strip('\\[]\\'').split('\\', \\'')\n",
    "        selectors = get_selectors(descriptions.loc[idx]['Parameters'])\n",
    "\n",
    "        features = []\n",
    "\n",
    "        for feature in feat_set:\n",
    "            features += [col for col in train.columns if feature in col]\n",
    "\n",
    "        if model_id.startswith('DTC'):\n",
    "            val_model = DecisionTreeClassifier(max_depth=int(selectors[0]),\\\n",
    "                                                random_state=514)\n",
    "        elif model_id.startswith('RF'):\n",
    "            val_model = RandomForestClassifier(max_depth=int(selectors[0]),\\\n",
    "                                            min_samples_leaf=int(selectors[1]),\n",
    "                                            random_state=514)\n",
    "        elif model_id.startswith('Knn'):\n",
    "            val_model = KNeighborsClassifier(n_neighbors = int(selectors[0]))\n",
    "        elif model_id.startswith('LR'):\n",
    "            val_model = LogisticRegression(C=float(selectors[0]),\\\n",
    "                                            solver=selectors[1],\n",
    "                                            class_weight=selectors[2],\n",
    "                                            max_iter=200,\n",
    "                                            random_state=514)  \n",
    "                                    \n",
    "        val_model.fit(X_train[features], y_train)\n",
    "\n",
    "        validate_metrics[model_id] = model.compute_metrics(val_model, X_validate[features], y_validate).values\n",
    "\n",
    "        score = val_model.score(X_validate[features], y_validate).round(4)\n",
    "\n",
    "        val_descriptions.loc[idx+1] = {'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': descriptions.loc[idx]['Type'],\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': descriptions.loc[idx]['Parameters']\n",
    "        }\n",
    "        \n",
    "    val_descriptions.insert(loc=2, column='Sensitivity', value=0)\n",
    "\n",
    "    for idx in val_descriptions.index:\n",
    "        model_id = val_descriptions.loc[idx]['Model']\n",
    "        if model_id != 'Baseline':\n",
    "            val_descriptions.loc[idx, 'Sensitivity'] = validate_metrics.T.loc[model_id]['True Negative Rate']        \n",
    "\n",
    "\n",
    "    return val_descriptions, validate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_descriptions, validate_metrics = score_on_validation(top_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.962933</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LR_2</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Knn_5</td>\n",
       "      <td>0.967100</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Knn_10</td>\n",
       "      <td>0.967100</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR_16</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR_0</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.967900</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 25, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Knn_8</td>\n",
       "      <td>0.967200</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR_4</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy(Score)                      Type  \\\n",
       "0   Baseline         0.962933            Basic Baseline   \n",
       "1      DTC_0         0.966500  Decision Tree Classifier   \n",
       "10      LR_2         0.968300       Logistic Regression   \n",
       "18     Knn_5         0.967100                       Knn   \n",
       "16    Knn_10         0.967100                       Knn   \n",
       "6      LR_16         0.968300       Logistic Regression   \n",
       "12      LR_0         0.968300       Logistic Regression   \n",
       "4       RF_5         0.967900             Random Forest   \n",
       "14     Knn_8         0.967200                       Knn   \n",
       "2      DTC_1         0.966500  Decision Tree Classifier   \n",
       "8       LR_4         0.968300       Logistic Regression   \n",
       "\n",
       "                                        Features Used  \\\n",
       "0                                 Baseline Prediction   \n",
       "1   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "10  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "18  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "16  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "6   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "12  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "4   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "14  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "2   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "8   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "\n",
       "                                       Parameters  \n",
       "0                                             n/a  \n",
       "1                                       Depth: 20  \n",
       "10      C: 0.1, Solver: lbfgs, Class Weight: None  \n",
       "18                                 K-Neighbors: 5  \n",
       "16                                K-Neighbors: 10  \n",
       "6           C: 1, Solver: sag, Class Weight: None  \n",
       "12  C: 0.1, Solver: newton-cg, Class Weight: None  \n",
       "4                            Depth: 25, Leaves: 1  \n",
       "14                                 K-Neighbors: 8  \n",
       "2                                       Depth: 22  \n",
       "8         C: 0.1, Solver: sag, Class Weight: None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>0.9665</td>\n",
       "      <td>11718.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>0.9665</td>\n",
       "      <td>11718.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>0.9679</td>\n",
       "      <td>11737.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_16</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_5</th>\n",
       "      <td>0.9671</td>\n",
       "      <td>11740.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_8</th>\n",
       "      <td>0.9672</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_10</th>\n",
       "      <td>0.9671</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "DTC_0           0.9665         11718.0            384.0            68.0   \n",
       "DTC_1           0.9665         11718.0            384.0            68.0   \n",
       "RF_5            0.9679         11737.0            386.0            66.0   \n",
       "LR_2            0.9683         11742.0            387.0            65.0   \n",
       "LR_16           0.9683         11742.0            387.0            65.0   \n",
       "LR_0            0.9683         11742.0            387.0            65.0   \n",
       "LR_4            0.9683         11742.0            387.0            65.0   \n",
       "Knn_5           0.9671         11740.0            399.0            53.0   \n",
       "Knn_8           0.9672         11742.0            400.0            52.0   \n",
       "Knn_10          0.9671         11742.0            401.0            51.0   \n",
       "\n",
       "        False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "DTC_0              24.0      0.9980               0.8496              0.1504   \n",
       "DTC_1              24.0      0.9980               0.8496              0.1504   \n",
       "RF_5                5.0      0.9996               0.8540              0.1460   \n",
       "LR_2                0.0      1.0000               0.8562              0.1438   \n",
       "LR_16               0.0      1.0000               0.8562              0.1438   \n",
       "LR_0                0.0      1.0000               0.8562              0.1438   \n",
       "LR_4                0.0      1.0000               0.8562              0.1438   \n",
       "Knn_5               2.0      0.9998               0.8827              0.1173   \n",
       "Knn_8               0.0      1.0000               0.8850              0.1150   \n",
       "Knn_10              0.0      1.0000               0.8872              0.1128   \n",
       "\n",
       "        False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "DTC_0                0.0020     0.9683    0.9829           11742.0   \n",
       "DTC_1                0.0020     0.9683    0.9829           11742.0   \n",
       "RF_5                 0.0004     0.9682    0.9836           11742.0   \n",
       "LR_2                 0.0000     0.9681    0.9838           11742.0   \n",
       "LR_16                0.0000     0.9681    0.9838           11742.0   \n",
       "LR_0                 0.0000     0.9681    0.9838           11742.0   \n",
       "LR_4                 0.0000     0.9681    0.9838           11742.0   \n",
       "Knn_5                0.0002     0.9671    0.9832           11742.0   \n",
       "Knn_8                0.0000     0.9671    0.9833           11742.0   \n",
       "Knn_10               0.0000     0.9670    0.9832           11742.0   \n",
       "\n",
       "        Support Negative  \n",
       "DTC_0              452.0  \n",
       "DTC_1              452.0  \n",
       "RF_5               452.0  \n",
       "LR_2               452.0  \n",
       "LR_16              452.0  \n",
       "LR_0               452.0  \n",
       "LR_4               452.0  \n",
       "Knn_5              452.0  \n",
       "Knn_8              452.0  \n",
       "Knn_10             452.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validate_metrics.T.sort_values(by='True Negative Rate', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "> Initial: All three chosen sets perform baseline. Need to re-adjust and re-attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = val_descriptions[val_descriptions.Model == 'DTC_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Accuracy(Score)                      Type  \\\n",
       "1  DTC_0           0.9665  Decision Tree Classifier   \n",
       "\n",
       "                                       Features Used Parameters  \n",
       "1  ['marital_status', 'occupation', 'race', 'educ...  Depth: 20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC_0\n"
     ]
    }
   ],
   "source": [
    "for idx in top_model.index:\n",
    "    print(top_model.loc[idx]['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_on_test(descriptions, subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_test = subsets[5]\n",
    "    y_test = subsets[6]\n",
    "\n",
    "    test_metrics = create_comp_chart()\n",
    "    test_descriptions = create_description_chart(y_test)\n",
    "        \n",
    "    for idx in descriptions.index:\n",
    "        \n",
    "        model_id = descriptions.loc[idx]['Model']\n",
    "        feat_set = descriptions.loc[idx]['Features Used'].strip('\\[]\\'').split('\\', \\'')\n",
    "        selectors = get_selectors(descriptions.loc[idx]['Parameters'])\n",
    "\n",
    "        features = []\n",
    "\n",
    "        for feature in feat_set:\n",
    "            features += [col for col in train.columns if feature in col]\n",
    "\n",
    "        if model_id.startswith('DTC'):\n",
    "            test_model = DecisionTreeClassifier(max_depth=int(selectors[0]),\\\n",
    "                                                random_state=514)\n",
    "        elif model_id.startswith('RF'):\n",
    "            test_model = RandomForestClassifier(max_depth=int(selectors[0]),\\\n",
    "                                            min_samples_leaf=int(selectors[1]),\n",
    "                                            random_state=514)\n",
    "        elif model_id.startswith('Knn'):\n",
    "            test_model = KNeighborsClassifier(n_neighbors = int(selectors[0]))\n",
    "        elif model_id.startswith('LR'):\n",
    "            test_model = LogisticRegression(C=float(selectors[0]),\\\n",
    "                                            solver=selectors[1],\n",
    "                                            class_weight=selectors[2],\n",
    "                                            max_iter=200,\n",
    "                                            random_state=514)  \n",
    "                                    \n",
    "        test_model.fit(X_train[features], y_train)\n",
    "\n",
    "        test_metrics[model_id] = compute_metrics(test_model, X_test[features], y_test).values\n",
    "\n",
    "        score = test_model.score(X_test[features], y_test).round(4)\n",
    "\n",
    "        test_descriptions.loc[idx+1] = {'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': descriptions.loc[idx]['Type'],\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': descriptions.loc[idx]['Parameters']\n",
    "        }\n",
    "\n",
    "    return test_descriptions, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_descriptions, test_metrics = score_on_test(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTC_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positives</th>\n",
       "      <td>9771.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positives</th>\n",
       "      <td>328.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negatives</th>\n",
       "      <td>49.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negatives</th>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR/Recall</th>\n",
       "      <td>0.9986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative Rate</th>\n",
       "      <td>0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.9828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Positive</th>\n",
       "      <td>9785.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Negative</th>\n",
       "      <td>377.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DTC_0\n",
       "Accuracy/Score          0.9663\n",
       "True Positives       9771.0000\n",
       "False Positives       328.0000\n",
       "True Negatives         49.0000\n",
       "False Negatives        14.0000\n",
       "TPR/Recall              0.9986\n",
       "False Positive Rate     0.8700\n",
       "True Negative Rate      0.1300\n",
       "False Negative Rate     0.0014\n",
       "Precision               0.9675\n",
       "F1-Score                0.9828\n",
       "Support Positive     9785.0000\n",
       "Support Negative      377.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_chart():\n",
    "    \"\"\"\n",
    "    purpose: to create a dataframe with an index reflecting compuation metrics for future models\n",
    "\n",
    "    returns: a pandas dataframe with appropriately set index\n",
    "    \"\"\"\n",
    "    statistics = ['Accuracy/Score',\n",
    "    'True Positives' , 'False Positives', 'True Negatives', 'False Negatives', \\\n",
    "    'TPR/Recall', 'False Positive Rate', 'True Negative Rate', 'False Negative Rate', \\\n",
    "    'Precision', 'F1-Score', 'Support Positive', 'Support Negative']\n",
    "\n",
    "\n",
    "    return pd.DataFrame({}, index=statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X, y, feature_groups, subsets):\n",
    "    \n",
    "   #take in features sets and run them through each of the different types\n",
    "   #of models and their variations\n",
    "   train_descriptions = create_description_chart(y)\n",
    "   train_metrics = create_comp_chart()\n",
    "\n",
    "   for features in feature_groups:\n",
    "      \n",
    "      train_descriptions, train_metrics = model_dtc(features, train_descriptions, train_metrics, subsets)\n",
    "      train_descriptions, train_metrics = model_rf(features, train_descriptions, train_metrics, subsets)\n",
    "      #train_descriptions, train_metrics = model_knn(features, train_descriptions, train_metrics, subsets)\n",
    "      train_descriptions, train_metrics = model_lr(features, train_descriptions, train_metrics, subsets)\n",
    "\n",
    "   train_descriptions.insert(loc=2, column='Sensitivity', value=0)\n",
    "\n",
    "   for idx in train_descriptions.index:\n",
    "      model_id = train_descriptions.iloc[idx]['Model']\n",
    "      if model_id != 'Baseline':\n",
    "         train_descriptions.loc[idx, 'Sensitivity'] = train_metrics.T.loc[model_id]['True Negative Rate']\n",
    "         \n",
    "   return train_descriptions, train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_final_report(train, feature_bank):\n",
    "\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = split_X_y(train)\n",
    "\n",
    "    subsets=[train, X_train, y_train, X_validate, y_validate, X_test, y_test]\n",
    "\n",
    "    train_descriptions, train_metrics = train_models(X_train, y_train, feature_bank, subsets)\n",
    "\n",
    "    train_descriptions[train_descriptions.Sensitivity > .20].\\\n",
    "        sort_values('Accuracy(Score)', ascending=False).\\\n",
    "        head(20)\n",
    "\n",
    "    top_4 = train_descriptions[train_descriptions.Sensitivity > .20].\\\n",
    "        sort_values('Accuracy(Score)', ascending=False).\\\n",
    "        head(4)\n",
    "\n",
    "    val_descriptions, validate_metrics = score_on_validation(top_4, subsets)\n",
    "\n",
    "    top_1 = val_descriptions[(val_descriptions.Sensitivity > .20) & (val_descriptions['Accuracy(Score)'] > .66)].\\\n",
    "        sort_values('Sensitivity', ascending=False).\\\n",
    "        head(1)\n",
    "\n",
    "    test_descriptions, test_metrics = score_on_test(top_1, subsets)\n",
    "\n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([12, 8, 10, 14], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <td>0.6684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positives</th>\n",
       "      <td>6554.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positives</th>\n",
       "      <td>139.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negatives</th>\n",
       "      <td>238.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negatives</th>\n",
       "      <td>3231.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR/Recall</th>\n",
       "      <td>0.6698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative Rate</th>\n",
       "      <td>0.6313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.3302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.7955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Positive</th>\n",
       "      <td>9785.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Negative</th>\n",
       "      <td>377.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          LR_7\n",
       "Accuracy/Score          0.6684\n",
       "True Positives       6554.0000\n",
       "False Positives       139.0000\n",
       "True Negatives        238.0000\n",
       "False Negatives      3231.0000\n",
       "TPR/Recall              0.6698\n",
       "False Positive Rate     0.3687\n",
       "True Negative Rate      0.6313\n",
       "False Negative Rate     0.3302\n",
       "Precision               0.9792\n",
       "F1-Score                0.7955\n",
       "Support Positive     9785.0000\n",
       "Support Negative      377.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for_final_report(train, [feat_set])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
