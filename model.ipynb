{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#use multinomial naive bayes algorithm after the other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import acquire, prepare\n",
    "\n",
    "from importlib import reload\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency\n",
    "`Raw Count`: This is simply the count of the number of occurances of each word.  \n",
    "`Frequency`: The number of times each word appears divided by the total number of words.  \n",
    "`Augmented Frequency`: The frequency of each word divided by the maximum frequency. This can help prevent bias towards larger documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_count</th>\n",
       "      <th>frequency</th>\n",
       "      <th>augmented_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lam</th>\n",
       "      <td>3</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_count  frequency  augmented_frequency\n",
       "a               3   0.272727             1.000000\n",
       "little          3   0.272727             1.000000\n",
       "lam             3   0.272727             1.000000\n",
       "mary            1   0.090909             0.333333\n",
       "had             1   0.090909             0.333333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = 'Mary had a little lam, a little lam, a little lam.'\n",
    "\n",
    "document = document.lower()\\\n",
    "                    .replace(',', ' ')\\\n",
    "                    .replace('.', '')\n",
    "words = pd.Series(document.split())\n",
    "\n",
    "#from series extra value counts (raw count of term frequency[TF]).\n",
    "# can then us to calc other measures\n",
    "(pd.DataFrame({'raw_count': words.value_counts()})\n",
    ".assign(frequency=lambda df: df.raw_count / df.raw_count.sum()) # create frequency column\n",
    ".assign(augmented_frequency=lambda df: df.frequency / df.frequency.max())) # create augmented frequency column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency\n",
    "* must have multiple documents \n",
    "* provides ide of how much informationa word provides\n",
    "* based on commonality of word appearance across docs\n",
    "* higher freq == lower IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'IDF for a given word')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#example of relationship between frequency and IDF score\n",
    "n_documents = 20\n",
    "\n",
    "x = np.arange(1, n_documents +1)\n",
    "y = np.log(n_documents / x)\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(x,y, marker='.')\n",
    "\n",
    "plt.xticks(x)\n",
    "plt.xlabel('# of Documents the word appears in')\n",
    "plt.ylabel('IDF')\n",
    "plt.title('IDF for a given word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating IDF for multipel words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"Codeup's data science program was created in response to a \"\n",
      "            'percieved lack of data science talent, and growing demand.',\n",
      " 'description': \"Codeup's data science program teaches hands on skills using \"\n",
      "                'Python and pandas.',\n",
      " 'news': 'Codeup announced last thursday that they just launched a new data '\n",
      "         'science program. It is 18 weeks long.'}\n",
      "'\\nCleaning and lemmatizing...\\n'\n",
      "{'context': \"codeup's data science program wa created in response to a \"\n",
      "            'percieved lack of data science talent and growing demand',\n",
      " 'description': \"codeup's data science program teach hand on skill using \"\n",
      "                'python and panda',\n",
      " 'news': 'codeup announced last thursday that they just launched a new data '\n",
      "         'science program it is 18 week long'}\n"
     ]
    }
   ],
   "source": [
    "#generate 3 example documents\n",
    "documents = {\n",
    "    'news': 'Codeup announced last thursday that they just launched a new data science program. It is 18 weeks long.',\n",
    "    'description': 'Codeup\\'s data science program teaches hands on skills using Python and pandas.',\n",
    "    'conreadme_txt': 'Codeup\\'s data science program was created in response to a percieved lack of data science talent, and growing demand.'\n",
    "}\n",
    "\n",
    "pprint(documents)\n",
    "\n",
    "pprint('\\nCleaning and lemmatizing...\\n')\n",
    "\n",
    "documents = {topic: prepare.lemmatize(prepare.basic_clean(documents[topic])) for topic in documents}\n",
    "\n",
    "pprint(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate IDF for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create func\n",
    "def idf(word):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        \n",
    "    ---\n",
    "    Parameters:\n",
    "        \n",
    "    ---\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    n_occurences = sum([1 for doc in documents.values() if word in doc])\n",
    "    return len(documents) / n_occurences  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teach</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idf\n",
       "word        \n",
       "teach    3.0\n",
       "created  3.0\n",
       "hand     3.0\n",
       "skill    3.0\n",
       "using    3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of unique qwords\n",
    "unique_words = pd.Series(' '.join(documents.values()).split()).unique()\n",
    "\n",
    "#put unique words into a data frame\n",
    "(pd.DataFrame(dict(word=unique_words))\n",
    ".assign(idf=lambda df: df.word.apply(idf))\n",
    ".set_index('word')\n",
    ".sort_values(by='idf', ascending=False)\n",
    ".head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>doc</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hand</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teach</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>panda</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>python</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>using</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>skill</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wa</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>created</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>response</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lack</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>talent</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>growing</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>percieved</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>demand</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>last</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>long</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>week</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thursday</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>announced</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>that</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>they</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>just</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>launched</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>in</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>on</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>program</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>program</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>science</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>program</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codeup</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word          doc    tf_idf\n",
       "5        hand  description  0.250000\n",
       "4       teach  description  0.250000\n",
       "11      panda  description  0.250000\n",
       "9      python  description  0.250000\n",
       "8       using  description  0.250000\n",
       "7       skill  description  0.250000\n",
       "14         wa      context  0.176471\n",
       "13    created      context  0.176471\n",
       "11   response      context  0.176471\n",
       "9          to      context  0.176471\n",
       "8        lack      context  0.176471\n",
       "7          of      context  0.176471\n",
       "6      talent      context  0.176471\n",
       "4     growing      context  0.176471\n",
       "3   percieved      context  0.176471\n",
       "16     demand      context  0.176471\n",
       "16       last         news  0.166667\n",
       "17       long         news  0.166667\n",
       "2        week         news  0.166667\n",
       "3          18         news  0.166667\n",
       "4          is         news  0.166667\n",
       "15   thursday         news  0.166667\n",
       "1   announced         news  0.166667\n",
       "5          it         news  0.166667\n",
       "14       that         news  0.166667\n",
       "13       they         news  0.166667\n",
       "12       just         news  0.166667\n",
       "11   launched         news  0.166667\n",
       "9         new         news  0.166667\n",
       "0    codeup's  description  0.125000\n",
       "10        and  description  0.125000\n",
       "1        data      context  0.117647\n",
       "0     science      context  0.117647\n",
       "2    codeup's      context  0.088235\n",
       "5         and      context  0.088235\n",
       "12         in      context  0.088235\n",
       "6          on  description  0.083333\n",
       "3     program  description  0.083333\n",
       "2     science  description  0.083333\n",
       "1        data  description  0.083333\n",
       "10          a      context  0.058824\n",
       "15    program      context  0.058824\n",
       "10          a         news  0.055556\n",
       "8        data         news  0.055556\n",
       "7     science         news  0.055556\n",
       "6     program         news  0.055556\n",
       "0      codeup         news  0.055556"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = []\n",
    "\n",
    "#calculate tf-idf value for every word across every document\n",
    "\n",
    "#iterate over all documents\n",
    "for doc, readme_txt in documents.items():\n",
    "    #make dataframe that contains the tf for every word in every document\n",
    "    df = (pd.Series(readme_txt.split())\n",
    "            .value_counts()\n",
    "            .reset_index()\n",
    "            .set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
    "            .assign(tf=lambda df: df.raw_count / df.shape[0])\n",
    "            .drop(columns='raw_count')\n",
    "            .assign(doc=doc))\n",
    "    \n",
    "    # append dataframe to list\n",
    "    tfs.append(df)\n",
    "\n",
    "#concatenate all tf values together\n",
    "(pd.concat(tfs)\n",
    "#calculate the idf value for each word\n",
    "    .assign(idf=lambda df: df.word.apply(idf))\n",
    "    .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    "    .drop(columns=['tf', 'idf'])\n",
    "    .sort_values(by='tf_idf', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>18</th>\n",
       "      <th>a</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>codeup's</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word               18         a       and  announced    codeup  codeup's  \\\n",
       "doc                                                                        \n",
       "context      0.000000  0.058824  0.088235   0.000000  0.000000  0.088235   \n",
       "description  0.000000  0.000000  0.125000   0.000000  0.000000  0.125000   \n",
       "news         0.166667  0.055556  0.000000   0.166667  0.055556  0.000000   \n",
       "\n",
       "word          created      data    demand   growing  ...  skill    talent  \\\n",
       "doc                                                  ...                    \n",
       "context      0.176471  0.117647  0.176471  0.176471  ...   0.00  0.176471   \n",
       "description  0.000000  0.083333  0.000000  0.000000  ...   0.25  0.000000   \n",
       "news         0.000000  0.055556  0.000000  0.000000  ...   0.00  0.000000   \n",
       "\n",
       "word         teach      that      they  thursday        to  using        wa  \\\n",
       "doc                                                                           \n",
       "context       0.00  0.000000  0.000000  0.000000  0.176471   0.00  0.176471   \n",
       "description   0.25  0.000000  0.000000  0.000000  0.000000   0.25  0.000000   \n",
       "news          0.00  0.166667  0.166667  0.166667  0.000000   0.00  0.000000   \n",
       "\n",
       "word             week  \n",
       "doc                    \n",
       "context      0.000000  \n",
       "description  0.000000  \n",
       "news         0.166667  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we'll then concatenate all the tf values together\n",
    "(pd.concat(tfs) \n",
    "#calcualte the idf calue for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .pipe(lambda df: pd.crosstab(df.doc, df.word, values=df.tf_idf, aggfunc=lambda x:x))\n",
    " .fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x36 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.readme_txt import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(documents.values())\n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>hand</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.155666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152159</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.304317</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257627</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         18       and  announced    codeup   created      data    demand  \\\n",
       "0  0.263566  0.000000   0.263566  0.155666  0.000000  0.155666  0.000000   \n",
       "1  0.000000  0.253880   0.000000  0.197160  0.000000  0.197160  0.000000   \n",
       "2  0.000000  0.195932   0.000000  0.152159  0.257627  0.304317  0.257627   \n",
       "\n",
       "    growing      hand        in  ...     skill    talent     teach      that  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.263566   \n",
       "1  0.000000  0.333821  0.000000  ...  0.333821  0.000000  0.333821  0.000000   \n",
       "2  0.257627  0.000000  0.257627  ...  0.000000  0.257627  0.000000  0.000000   \n",
       "\n",
       "       they  thursday        to     using        wa      week  \n",
       "0  0.263566  0.263566  0.000000  0.000000  0.000000  0.263566  \n",
       "1  0.000000  0.000000  0.000000  0.333821  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.257627  0.000000  0.257627  0.000000  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "id                                                         \n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ###\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.readme_txt)\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "train, validate, test, train_scaled, validate_scaled, test_scaled = wrangle.split_scale(df, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28450 entries, 26127 to 19091\n",
      "Columns: 171 entries, household_num to occupation_11.0\n",
      "dtypes: float64(7), int64(9), uint8(155)\n",
      "memory usage: 7.9 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Explore various models and feature combinations.\n",
    "Choose **three** models to validate. Choose **one** to test. \n",
    "Artifact: `model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Preparation\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Prediction and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.962882\n",
       "0    0.037118\n",
       "Name: employed, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# formulate baseline prediction\n",
    "train.language.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_y(df):\n",
    "    # split data into Big X, small y sets \n",
    "    X_train = train.drop(columns=['language'])\n",
    "    y_train = train.language\n",
    "\n",
    "    X_validate = validate.drop(columns=['language'])\n",
    "    y_validate = validate.language\n",
    "\n",
    "    X_test = test.drop(columns=['language'])\n",
    "    y_test = test.language\n",
    "\n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, X_df, y_df):\n",
    "    \"\"\"\n",
    "    purpose: function executes performs computations to produce evaulation metrics for a given model\n",
    "\n",
    "    inputs: \n",
    "        model: a model that has been previous fit to spec\n",
    "        X_df: a dataframe featuring the X subset of data for evaluation\n",
    "        y_df: a dataframe featuring the model target variable\n",
    "\n",
    "    Returns: a rounded pandas Series that can be adding to an evaulation metric comparison chart\n",
    "    \"\"\"\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_df)\n",
    "\n",
    "    # Estimate Probability \n",
    "    y_pred_proba = model.predict_proba(X_df)\n",
    "\n",
    "    #create confusion matrix\n",
    "    confusion = confusion_matrix(y_df, y_pred)\n",
    "\n",
    "    #assign results of confusion matrix to variables\n",
    "    true_negative = confusion[0,0]\n",
    "    false_positive = confusion[0,1]\n",
    "    false_negative = confusion[1,0]\n",
    "    true_positive = confusion[1,1]\n",
    "\n",
    "    #accuracy\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "\n",
    "    #true positive rate / recall\n",
    "    recall = true_positive / (true_positive +false_negative)\n",
    "\n",
    "    #false positive rate\n",
    "    false_positive_rate = false_positive / (true_negative + false_positive)\n",
    "\n",
    "    #true negative rate\n",
    "    true_negative_rate = true_negative / (true_negative + false_positive)\n",
    "\n",
    "    #false negative rate\n",
    "    false_negative_rate = false_negative / (false_negative + true_positive)\n",
    "\n",
    "    #precision\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "    #f1-score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    #support\n",
    "    support_positive = true_positive + false_negative\n",
    "    support_negative = false_positive + true_negative\n",
    "\n",
    "    metrics = pd.Series([accuracy, true_positive, false_positive, true_negative, false_negative,\\\n",
    "                        recall, false_positive_rate, true_negative_rate, false_negative_rate, \\\n",
    "                        precision, f1_score, support_positive, support_negative])\n",
    "                        \n",
    "    return metrics.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_chart():\n",
    "    \"\"\"\n",
    "    purpose: to create a dataframe with an index reflecting compuation metrics for future models\n",
    "\n",
    "    returns: a pandas dataframe with appropriately set index\n",
    "    \"\"\"\n",
    "    statistics = ['Accuracy/Score',\n",
    "    'True Positives' , 'False Positives', 'True Negatives', 'False Negatives', \\\n",
    "    'TPR/Recall', 'False Positive Rate', 'True Negative Rate', 'False Negative Rate', \\\n",
    "    'Precision', 'F1-Score', 'Support Positive', 'Support Negative']\n",
    "\n",
    "\n",
    "    return pd.DataFrame({}, index=statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into Big X, small y sets \n",
    "X_train = train.drop(columns=['language'])\n",
    "y_train = train.language\n",
    "\n",
    "X_validate = validate.drop(columns=['language'])\n",
    "y_validate = validate.language\n",
    "\n",
    "X_test = test.drop(columns=['language'])\n",
    "y_test = test.language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy for \"unemployed\" prediction on Telco dataset:  96.3%\n"
     ]
    }
   ],
   "source": [
    "# formulate baseline accuracy\n",
    "baseline_accuracy = (y_train == 1).mean()\n",
    "\n",
    "print(f'Baseline Accuracy for \\\"language\\\" prediction: {(baseline_accuracy * 100): .3}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_description_chart(y):\n",
    "\n",
    "    # formulate baseline accuracy\n",
    "    baseline_accuracy = (y == 1).mean()\n",
    "\n",
    "    descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "                                'Accuracy(Score)': baseline_accuracy,\n",
    "                                'Type': 'Basic Baseline',\n",
    "                                'Features Used': 'Baseline Prediction',\n",
    "                                'Parameters': 'n/a'\n",
    "                                }, index=[0])\n",
    "    \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.962882</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.962882</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)            Type        Features Used Parameters\n",
       "0  Baseline         0.962882  Basic Baseline  Baseline Prediction        n/a\n",
       "1  Baseline         0.962882  Basic Baseline  Baseline Prediction        n/a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([model_descriptions, pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0]) ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_chart = model.create_comp_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_set = ['marital_status', 'occupation', 'race', 'education', 'citizenship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [train, X_train, y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dtc(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product(np.arange(20,25,2)))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'DTC_'+f'{idx}'\n",
    "        dtc = DecisionTreeClassifier(max_depth=item[0],\\\n",
    "                                            random_state=514)\n",
    "        \n",
    "        dtc.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(dtc, X_train[features], y_train).values\n",
    "\n",
    "        score = dtc.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Decision Tree Classifier',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}'},\n",
    "                                    index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart =  model_dtc(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.962882</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 25, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Knn_1</td>\n",
       "      <td>0.936450</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Knn_2</td>\n",
       "      <td>0.927140</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Knn_3</td>\n",
       "      <td>0.963660</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Knn_4</td>\n",
       "      <td>0.963130</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Knn_5</td>\n",
       "      <td>0.966680</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Knn_6</td>\n",
       "      <td>0.966710</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Knn_7</td>\n",
       "      <td>0.966750</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Knn_8</td>\n",
       "      <td>0.966750</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Knn_9</td>\n",
       "      <td>0.966640</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Knn_10</td>\n",
       "      <td>0.966710</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Knn_11</td>\n",
       "      <td>0.966640</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Knn_12</td>\n",
       "      <td>0.966640</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Knn_13</td>\n",
       "      <td>0.966430</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Knn_14</td>\n",
       "      <td>0.966430</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR_0</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LR_1</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LR_2</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LR_3</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LR_4</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LR_5</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: sag, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LR_6</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LR_7</td>\n",
       "      <td>0.658300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: newton-cg, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LR_8</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LR_9</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: lbfgs, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LR_10</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LR_11</td>\n",
       "      <td>0.708800</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: sag, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LR_12</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LR_13</td>\n",
       "      <td>0.658100</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: newton-cg, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LR_14</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LR_15</td>\n",
       "      <td>0.658100</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: lbfgs, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LR_16</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LR_17</td>\n",
       "      <td>0.493600</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: sag, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy(Score)                      Type  \\\n",
       "0   Baseline         0.962882            Basic Baseline   \n",
       "1      DTC_0         0.968200  Decision Tree Classifier   \n",
       "2      DTC_1         0.968200  Decision Tree Classifier   \n",
       "3      DTC_2         0.968200  Decision Tree Classifier   \n",
       "4       RF_5         0.968200             Random Forest   \n",
       "5      Knn_1         0.936450                       Knn   \n",
       "6      Knn_2         0.927140                       Knn   \n",
       "7      Knn_3         0.963660                       Knn   \n",
       "8      Knn_4         0.963130                       Knn   \n",
       "9      Knn_5         0.966680                       Knn   \n",
       "10     Knn_6         0.966710                       Knn   \n",
       "11     Knn_7         0.966750                       Knn   \n",
       "12     Knn_8         0.966750                       Knn   \n",
       "13     Knn_9         0.966640                       Knn   \n",
       "14    Knn_10         0.966710                       Knn   \n",
       "15    Knn_11         0.966640                       Knn   \n",
       "16    Knn_12         0.966640                       Knn   \n",
       "17    Knn_13         0.966430                       Knn   \n",
       "18    Knn_14         0.966430                       Knn   \n",
       "19      LR_0         0.967700       Logistic Regression   \n",
       "20      LR_1         0.657700       Logistic Regression   \n",
       "21      LR_2         0.967700       Logistic Regression   \n",
       "22      LR_3         0.657700       Logistic Regression   \n",
       "23      LR_4         0.967700       Logistic Regression   \n",
       "24      LR_5         0.657700       Logistic Regression   \n",
       "25      LR_6         0.967700       Logistic Regression   \n",
       "26      LR_7         0.658300       Logistic Regression   \n",
       "27      LR_8         0.967700       Logistic Regression   \n",
       "28      LR_9         0.658200       Logistic Regression   \n",
       "29     LR_10         0.967700       Logistic Regression   \n",
       "30     LR_11         0.708800       Logistic Regression   \n",
       "31     LR_12         0.967700       Logistic Regression   \n",
       "32     LR_13         0.658100       Logistic Regression   \n",
       "33     LR_14         0.967700       Logistic Regression   \n",
       "34     LR_15         0.658100       Logistic Regression   \n",
       "35     LR_16         0.967700       Logistic Regression   \n",
       "36     LR_17         0.493600       Logistic Regression   \n",
       "37     DTC_0         0.968200  Decision Tree Classifier   \n",
       "38     DTC_1         0.968200  Decision Tree Classifier   \n",
       "39     DTC_2         0.968200  Decision Tree Classifier   \n",
       "40     DTC_0         0.968200  Decision Tree Classifier   \n",
       "41     DTC_1         0.968200  Decision Tree Classifier   \n",
       "42     DTC_2         0.968200  Decision Tree Classifier   \n",
       "\n",
       "                                        Features Used  \\\n",
       "0                                 Baseline Prediction   \n",
       "1   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "2   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "3   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "4   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "5   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "6   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "7   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "8   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "9   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "10  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "11  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "12  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "13  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "14  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "15  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "16  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "17  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "18  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "19  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "20  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "21  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "22  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "23  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "24  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "25  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "26  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "27  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "28  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "29  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "30  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "31  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "32  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "33  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "34  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "35  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "36  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "37  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "38  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "39  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "40  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "41  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "42  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "\n",
       "                                           Parameters  \n",
       "0                                                 n/a  \n",
       "1                                           Depth: 20  \n",
       "2                                           Depth: 22  \n",
       "3                                           Depth: 24  \n",
       "4                                Depth: 25, Leaves: 1  \n",
       "5                                      K-Neighbors: 1  \n",
       "6                                      K-Neighbors: 2  \n",
       "7                                      K-Neighbors: 3  \n",
       "8                                      K-Neighbors: 4  \n",
       "9                                      K-Neighbors: 5  \n",
       "10                                     K-Neighbors: 6  \n",
       "11                                     K-Neighbors: 7  \n",
       "12                                     K-Neighbors: 8  \n",
       "13                                     K-Neighbors: 9  \n",
       "14                                    K-Neighbors: 10  \n",
       "15                                    K-Neighbors: 11  \n",
       "16                                    K-Neighbors: 12  \n",
       "17                                    K-Neighbors: 13  \n",
       "18                                    K-Neighbors: 14  \n",
       "19      C: 0.1, Solver: newton-cg, Class Weight: None  \n",
       "20  C: 0.1, Solver: newton-cg, Class Weight: balanced  \n",
       "21          C: 0.1, Solver: lbfgs, Class Weight: None  \n",
       "22      C: 0.1, Solver: lbfgs, Class Weight: balanced  \n",
       "23            C: 0.1, Solver: sag, Class Weight: None  \n",
       "24        C: 0.1, Solver: sag, Class Weight: balanced  \n",
       "25      C: 0.5, Solver: newton-cg, Class Weight: None  \n",
       "26  C: 0.5, Solver: newton-cg, Class Weight: balanced  \n",
       "27          C: 0.5, Solver: lbfgs, Class Weight: None  \n",
       "28      C: 0.5, Solver: lbfgs, Class Weight: balanced  \n",
       "29            C: 0.5, Solver: sag, Class Weight: None  \n",
       "30        C: 0.5, Solver: sag, Class Weight: balanced  \n",
       "31        C: 1, Solver: newton-cg, Class Weight: None  \n",
       "32    C: 1, Solver: newton-cg, Class Weight: balanced  \n",
       "33            C: 1, Solver: lbfgs, Class Weight: None  \n",
       "34        C: 1, Solver: lbfgs, Class Weight: balanced  \n",
       "35              C: 1, Solver: sag, Class Weight: None  \n",
       "36          C: 1, Solver: sag, Class Weight: balanced  \n",
       "37                                          Depth: 20  \n",
       "38                                          Depth: 22  \n",
       "39                                          Depth: 24  \n",
       "40                                          Depth: 20  \n",
       "41                                          Depth: 22  \n",
       "42                                          Depth: 24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product([20,25], [3,2,1]))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'RF_'+f'{idx}'\n",
    "        rf = RandomForestClassifier(max_depth=item[0],\\\n",
    "                                            min_samples_leaf=item[1],\n",
    "                                            random_state=514)\n",
    "        \n",
    "        rf.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(rf, X_train[features], y_train).values\n",
    "\n",
    "        score = rf.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Random Forest',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}, Leaves: {item[1]}'},\n",
    "                                    index=[0])\n",
    "       \n",
    "    model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart = model_rf(feat_set, model_descriptions, comparison_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways - Random Forest\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors\n",
    "def model_knn(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    k_range = range(1, 15)\n",
    "    scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train[features], y_train)\n",
    "        scores.append(knn.score(X_train[features], y_train))\n",
    "\n",
    "        model_id = 'Knn_'+f'{k}'\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(knn, X_train[features], y_train).values\n",
    "\n",
    "        score = knn.score(X_train[features], y_train).round(5)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Knn',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'K-Neighbors: {k}'},\n",
    "            index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.scatter(k_range, scores)\n",
    "    plt.xticks([0,5,10,15,20])\n",
    "    plt.show()\n",
    "    np.mean(scores)\n",
    "\n",
    "    \n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions, comparison_chart = model_knn(feat_set, model_descriptions, comparison_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 25, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_7</td>\n",
       "      <td>0.96675</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Accuracy(Score)                      Type  \\\n",
       "0  DTC_1          0.96820  Decision Tree Classifier   \n",
       "0  DTC_2          0.96820  Decision Tree Classifier   \n",
       "0   RF_5          0.96820             Random Forest   \n",
       "0  DTC_0          0.96820  Decision Tree Classifier   \n",
       "0  Knn_7          0.96675                       Knn   \n",
       "\n",
       "                                       Features Used            Parameters  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...             Depth: 22  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...             Depth: 24  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...  Depth: 25, Leaves: 1  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...             Depth: 20  \n",
       "0  ['marital_status', 'occupation', 'race', 'educ...        K-Neighbors: 7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions.sort_values(by='Accuracy(Score)', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lr(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    cees = [.1,.5,1]\n",
    "    solver = ['newton-cg', 'lbfgs']\n",
    "    weights = [None, 'balanced']\n",
    "\n",
    "    selectors = list(product(cees, solver, weights))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'LR_'+f'{idx}'\n",
    "        lr = LogisticRegression(C=item[0],\\\n",
    "                                solver=item[1],\n",
    "                                class_weight=item[2],\n",
    "                                max_iter=400,\n",
    "                                random_state=514)\n",
    "        \n",
    "        lr.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(lr, X_train[features], y_train).values\n",
    "\n",
    "        score = lr.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        model_descriptions.loc[idx+1] = {'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Logistic Regression',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'C: {item[0]}, Solver: {item[1]}, Class Weight: {item[2]}'\n",
    "        }\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_descriptions, comparison_chart = model_lr(feat_set, model_descriptions, comparison_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description and Comparison Charts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Basic Baseline              0.962882\n",
       "Decision Tree Classifier    0.968200\n",
       "Knn                         0.961197\n",
       "Logistic Regression         0.806528\n",
       "Random Forest               0.968200\n",
       "Name: Accuracy(Score), dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions.groupby('Type')['Accuracy(Score)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.96820</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 25, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR_8</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR_16</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR_14</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR_4</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LR_10</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_2</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR_12</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_0</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR_6</td>\n",
       "      <td>0.96770</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.5, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_8</td>\n",
       "      <td>0.96675</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_7</td>\n",
       "      <td>0.96675</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_10</td>\n",
       "      <td>0.96671</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_6</td>\n",
       "      <td>0.96671</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_5</td>\n",
       "      <td>0.96668</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_11</td>\n",
       "      <td>0.96664</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knn_12</td>\n",
       "      <td>0.96664</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Accuracy(Score)                      Type  \\\n",
       "0    DTC_0          0.96820  Decision Tree Classifier   \n",
       "0    DTC_1          0.96820  Decision Tree Classifier   \n",
       "0    DTC_2          0.96820  Decision Tree Classifier   \n",
       "0     RF_5          0.96820             Random Forest   \n",
       "9     LR_8          0.96770       Logistic Regression   \n",
       "17   LR_16          0.96770       Logistic Regression   \n",
       "15   LR_14          0.96770       Logistic Regression   \n",
       "5     LR_4          0.96770       Logistic Regression   \n",
       "11   LR_10          0.96770       Logistic Regression   \n",
       "3     LR_2          0.96770       Logistic Regression   \n",
       "13   LR_12          0.96770       Logistic Regression   \n",
       "1     LR_0          0.96770       Logistic Regression   \n",
       "7     LR_6          0.96770       Logistic Regression   \n",
       "0    Knn_8          0.96675                       Knn   \n",
       "0    Knn_7          0.96675                       Knn   \n",
       "0   Knn_10          0.96671                       Knn   \n",
       "0    Knn_6          0.96671                       Knn   \n",
       "0    Knn_5          0.96668                       Knn   \n",
       "0   Knn_11          0.96664                       Knn   \n",
       "0   Knn_12          0.96664                       Knn   \n",
       "\n",
       "                                        Features Used  \\\n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "9   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "17  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "15  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "5   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "11  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "3   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "13  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "1   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "7   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "0   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "\n",
       "                                       Parameters  \n",
       "0                                       Depth: 20  \n",
       "0                                       Depth: 22  \n",
       "0                                       Depth: 24  \n",
       "0                            Depth: 25, Leaves: 1  \n",
       "9       C: 0.5, Solver: lbfgs, Class Weight: None  \n",
       "17          C: 1, Solver: sag, Class Weight: None  \n",
       "15        C: 1, Solver: lbfgs, Class Weight: None  \n",
       "5         C: 0.1, Solver: sag, Class Weight: None  \n",
       "11        C: 0.5, Solver: sag, Class Weight: None  \n",
       "3       C: 0.1, Solver: lbfgs, Class Weight: None  \n",
       "13    C: 1, Solver: newton-cg, Class Weight: None  \n",
       "1   C: 0.1, Solver: newton-cg, Class Weight: None  \n",
       "7   C: 0.5, Solver: newton-cg, Class Weight: None  \n",
       "0                                  K-Neighbors: 8  \n",
       "0                                  K-Neighbors: 7  \n",
       "0                                 K-Neighbors: 10  \n",
       "0                                  K-Neighbors: 6  \n",
       "0                                  K-Neighbors: 5  \n",
       "0                                 K-Neighbors: 11  \n",
       "0                                 K-Neighbors: 12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model descriptions\n",
    "model_descriptions.sort_values('Accuracy(Score)', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_17</th>\n",
       "      <td>0.4936</td>\n",
       "      <td>13491.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>13903.0</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_5</th>\n",
       "      <td>0.6577</td>\n",
       "      <td>18074.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>9320.0</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.3968</td>\n",
       "      <td>0.6032</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_3</th>\n",
       "      <td>0.6577</td>\n",
       "      <td>18074.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>9320.0</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.3968</td>\n",
       "      <td>0.6032</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_1</th>\n",
       "      <td>0.6577</td>\n",
       "      <td>18074.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>9320.0</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.3968</td>\n",
       "      <td>0.6032</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_15</th>\n",
       "      <td>0.6581</td>\n",
       "      <td>18086.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>9308.0</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_13</th>\n",
       "      <td>0.6581</td>\n",
       "      <td>18086.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>9308.0</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_9</th>\n",
       "      <td>0.6582</td>\n",
       "      <td>18089.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>9305.0</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_7</th>\n",
       "      <td>0.6583</td>\n",
       "      <td>18091.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>9303.0</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.3396</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_11</th>\n",
       "      <td>0.7088</td>\n",
       "      <td>19651.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.4877</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.8259</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_2</th>\n",
       "      <td>0.9271</td>\n",
       "      <td>26117.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_1</th>\n",
       "      <td>0.9364</td>\n",
       "      <td>26416.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_4</th>\n",
       "      <td>0.9631</td>\n",
       "      <td>27245.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_3</th>\n",
       "      <td>0.9637</td>\n",
       "      <td>27273.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.8646</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_4</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_6</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_3</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_10</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27390.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_2</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_2</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27390.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "LR_17          0.4936         13491.0            504.0           552.0   \n",
       "LR_5           0.6577         18074.0            419.0           637.0   \n",
       "LR_3           0.6577         18074.0            419.0           637.0   \n",
       "LR_1           0.6577         18074.0            419.0           637.0   \n",
       "LR_15          0.6581         18086.0            418.0           638.0   \n",
       "LR_13          0.6581         18086.0            418.0           638.0   \n",
       "LR_9           0.6582         18089.0            418.0           638.0   \n",
       "LR_7           0.6583         18091.0            418.0           638.0   \n",
       "LR_11          0.7088         19651.0            541.0           515.0   \n",
       "Knn_2          0.9271         26117.0            796.0           260.0   \n",
       "Knn_1          0.9364         26416.0            830.0           226.0   \n",
       "Knn_4          0.9631         27245.0            900.0           156.0   \n",
       "Knn_3          0.9637         27273.0            913.0           143.0   \n",
       "LR_2           0.9677         27394.0            918.0           138.0   \n",
       "RF_4           0.9677         27394.0            918.0           138.0   \n",
       "LR_6           0.9677         27394.0            918.0           138.0   \n",
       "RF_3           0.9677         27394.0            918.0           138.0   \n",
       "LR_4           0.9677         27394.0            918.0           138.0   \n",
       "LR_0           0.9677         27394.0            918.0           138.0   \n",
       "LR_10          0.9677         27394.0            918.0           138.0   \n",
       "RF_5           0.9682         27390.0            900.0           156.0   \n",
       "DTC_2          0.9682         27379.0            889.0           167.0   \n",
       "DTC_1          0.9682         27379.0            889.0           167.0   \n",
       "RF_2           0.9682         27390.0            900.0           156.0   \n",
       "DTC_0          0.9682         27379.0            889.0           167.0   \n",
       "\n",
       "       False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "LR_17          13903.0      0.4925               0.4773              0.5227   \n",
       "LR_5            9320.0      0.6598               0.3968              0.6032   \n",
       "LR_3            9320.0      0.6598               0.3968              0.6032   \n",
       "LR_1            9320.0      0.6598               0.3968              0.6032   \n",
       "LR_15           9308.0      0.6602               0.3958              0.6042   \n",
       "LR_13           9308.0      0.6602               0.3958              0.6042   \n",
       "LR_9            9305.0      0.6603               0.3958              0.6042   \n",
       "LR_7            9303.0      0.6604               0.3958              0.6042   \n",
       "LR_11           7743.0      0.7173               0.5123              0.4877   \n",
       "Knn_2           1277.0      0.9534               0.7538              0.2462   \n",
       "Knn_1            978.0      0.9643               0.7860              0.2140   \n",
       "Knn_4            149.0      0.9946               0.8523              0.1477   \n",
       "Knn_3            121.0      0.9956               0.8646              0.1354   \n",
       "LR_2               0.0      1.0000               0.8693              0.1307   \n",
       "RF_4               0.0      1.0000               0.8693              0.1307   \n",
       "LR_6               0.0      1.0000               0.8693              0.1307   \n",
       "RF_3               0.0      1.0000               0.8693              0.1307   \n",
       "LR_4               0.0      1.0000               0.8693              0.1307   \n",
       "LR_0               0.0      1.0000               0.8693              0.1307   \n",
       "LR_10              0.0      1.0000               0.8693              0.1307   \n",
       "RF_5               4.0      0.9999               0.8523              0.1477   \n",
       "DTC_2             15.0      0.9995               0.8419              0.1581   \n",
       "DTC_1             15.0      0.9995               0.8419              0.1581   \n",
       "RF_2               4.0      0.9999               0.8523              0.1477   \n",
       "DTC_0             15.0      0.9995               0.8419              0.1581   \n",
       "\n",
       "       False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "LR_17               0.5075     0.9640    0.6519           27394.0   \n",
       "LR_5                0.3402     0.9773    0.7878           27394.0   \n",
       "LR_3                0.3402     0.9773    0.7878           27394.0   \n",
       "LR_1                0.3402     0.9773    0.7878           27394.0   \n",
       "LR_15               0.3398     0.9774    0.7881           27394.0   \n",
       "LR_13               0.3398     0.9774    0.7881           27394.0   \n",
       "LR_9                0.3397     0.9774    0.7882           27394.0   \n",
       "LR_7                0.3396     0.9774    0.7882           27394.0   \n",
       "LR_11               0.2827     0.9732    0.8259           27394.0   \n",
       "Knn_2               0.0466     0.9704    0.9618           27394.0   \n",
       "Knn_1               0.0357     0.9695    0.9669           27394.0   \n",
       "Knn_4               0.0054     0.9680    0.9811           27394.0   \n",
       "Knn_3               0.0044     0.9676    0.9814           27394.0   \n",
       "LR_2                0.0000     0.9676    0.9835           27394.0   \n",
       "RF_4                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_6                0.0000     0.9676    0.9835           27394.0   \n",
       "RF_3                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_4                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_0                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_10               0.0000     0.9676    0.9835           27394.0   \n",
       "RF_5                0.0001     0.9682    0.9838           27394.0   \n",
       "DTC_2               0.0005     0.9686    0.9838           27394.0   \n",
       "DTC_1               0.0005     0.9686    0.9838           27394.0   \n",
       "RF_2                0.0001     0.9682    0.9838           27394.0   \n",
       "DTC_0               0.0005     0.9686    0.9838           27394.0   \n",
       "\n",
       "       Support Negative  \n",
       "LR_17            1056.0  \n",
       "LR_5             1056.0  \n",
       "LR_3             1056.0  \n",
       "LR_1             1056.0  \n",
       "LR_15            1056.0  \n",
       "LR_13            1056.0  \n",
       "LR_9             1056.0  \n",
       "LR_7             1056.0  \n",
       "LR_11            1056.0  \n",
       "Knn_2            1056.0  \n",
       "Knn_1            1056.0  \n",
       "Knn_4            1056.0  \n",
       "Knn_3            1056.0  \n",
       "LR_2             1056.0  \n",
       "RF_4             1056.0  \n",
       "LR_6             1056.0  \n",
       "RF_3             1056.0  \n",
       "LR_4             1056.0  \n",
       "LR_0             1056.0  \n",
       "LR_10            1056.0  \n",
       "RF_5             1056.0  \n",
       "DTC_2            1056.0  \n",
       "DTC_1            1056.0  \n",
       "RF_2             1056.0  \n",
       "DTC_0            1056.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_chart.T.sort_values(by='True Negatives', ascending=False).head(25).sort_values(by=['Accuracy/Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_2</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27379.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_2</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27390.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>0.9682</td>\n",
       "      <td>27390.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_0</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_1</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_3</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_4</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_14</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_16</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_10</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_8</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_6</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_12</th>\n",
       "      <td>0.9677</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_6</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27386.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_5</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27387.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_7</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_8</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_10</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_12</th>\n",
       "      <td>0.9666</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_11</th>\n",
       "      <td>0.9666</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>27394.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "DTC_0           0.9682         27379.0            889.0           167.0   \n",
       "DTC_2           0.9682         27379.0            889.0           167.0   \n",
       "DTC_1           0.9682         27379.0            889.0           167.0   \n",
       "RF_2            0.9682         27390.0            900.0           156.0   \n",
       "RF_5            0.9682         27390.0            900.0           156.0   \n",
       "LR_2            0.9677         27394.0            918.0           138.0   \n",
       "RF_0            0.9677         27394.0            918.0           138.0   \n",
       "RF_1            0.9677         27394.0            918.0           138.0   \n",
       "RF_3            0.9677         27394.0            918.0           138.0   \n",
       "RF_4            0.9677         27394.0            918.0           138.0   \n",
       "LR_14           0.9677         27394.0            918.0           138.0   \n",
       "LR_16           0.9677         27394.0            918.0           138.0   \n",
       "LR_10           0.9677         27394.0            918.0           138.0   \n",
       "LR_8            0.9677         27394.0            918.0           138.0   \n",
       "LR_6            0.9677         27394.0            918.0           138.0   \n",
       "LR_4            0.9677         27394.0            918.0           138.0   \n",
       "LR_0            0.9677         27394.0            918.0           138.0   \n",
       "LR_12           0.9677         27394.0            918.0           138.0   \n",
       "Knn_6           0.9667         27386.0            939.0           117.0   \n",
       "Knn_5           0.9667         27387.0            941.0           115.0   \n",
       "Knn_7           0.9667         27394.0            946.0           110.0   \n",
       "Knn_8           0.9667         27394.0            946.0           110.0   \n",
       "Knn_10          0.9667         27394.0            947.0           109.0   \n",
       "Knn_12          0.9666         27394.0            949.0           107.0   \n",
       "Knn_11          0.9666         27394.0            949.0           107.0   \n",
       "\n",
       "        False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "DTC_0              15.0      0.9995               0.8419              0.1581   \n",
       "DTC_2              15.0      0.9995               0.8419              0.1581   \n",
       "DTC_1              15.0      0.9995               0.8419              0.1581   \n",
       "RF_2                4.0      0.9999               0.8523              0.1477   \n",
       "RF_5                4.0      0.9999               0.8523              0.1477   \n",
       "LR_2                0.0      1.0000               0.8693              0.1307   \n",
       "RF_0                0.0      1.0000               0.8693              0.1307   \n",
       "RF_1                0.0      1.0000               0.8693              0.1307   \n",
       "RF_3                0.0      1.0000               0.8693              0.1307   \n",
       "RF_4                0.0      1.0000               0.8693              0.1307   \n",
       "LR_14               0.0      1.0000               0.8693              0.1307   \n",
       "LR_16               0.0      1.0000               0.8693              0.1307   \n",
       "LR_10               0.0      1.0000               0.8693              0.1307   \n",
       "LR_8                0.0      1.0000               0.8693              0.1307   \n",
       "LR_6                0.0      1.0000               0.8693              0.1307   \n",
       "LR_4                0.0      1.0000               0.8693              0.1307   \n",
       "LR_0                0.0      1.0000               0.8693              0.1307   \n",
       "LR_12               0.0      1.0000               0.8693              0.1307   \n",
       "Knn_6               8.0      0.9997               0.8892              0.1108   \n",
       "Knn_5               7.0      0.9997               0.8911              0.1089   \n",
       "Knn_7               0.0      1.0000               0.8958              0.1042   \n",
       "Knn_8               0.0      1.0000               0.8958              0.1042   \n",
       "Knn_10              0.0      1.0000               0.8968              0.1032   \n",
       "Knn_12              0.0      1.0000               0.8987              0.1013   \n",
       "Knn_11              0.0      1.0000               0.8987              0.1013   \n",
       "\n",
       "        False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "DTC_0                0.0005     0.9686    0.9838           27394.0   \n",
       "DTC_2                0.0005     0.9686    0.9838           27394.0   \n",
       "DTC_1                0.0005     0.9686    0.9838           27394.0   \n",
       "RF_2                 0.0001     0.9682    0.9838           27394.0   \n",
       "RF_5                 0.0001     0.9682    0.9838           27394.0   \n",
       "LR_2                 0.0000     0.9676    0.9835           27394.0   \n",
       "RF_0                 0.0000     0.9676    0.9835           27394.0   \n",
       "RF_1                 0.0000     0.9676    0.9835           27394.0   \n",
       "RF_3                 0.0000     0.9676    0.9835           27394.0   \n",
       "RF_4                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_14                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_16                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_10                0.0000     0.9676    0.9835           27394.0   \n",
       "LR_8                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_6                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_4                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_0                 0.0000     0.9676    0.9835           27394.0   \n",
       "LR_12                0.0000     0.9676    0.9835           27394.0   \n",
       "Knn_6                0.0003     0.9668    0.9830           27394.0   \n",
       "Knn_5                0.0003     0.9668    0.9830           27394.0   \n",
       "Knn_7                0.0000     0.9666    0.9830           27394.0   \n",
       "Knn_8                0.0000     0.9666    0.9830           27394.0   \n",
       "Knn_10               0.0000     0.9666    0.9830           27394.0   \n",
       "Knn_12               0.0000     0.9665    0.9830           27394.0   \n",
       "Knn_11               0.0000     0.9665    0.9830           27394.0   \n",
       "\n",
       "        Support Negative  \n",
       "DTC_0             1056.0  \n",
       "DTC_2             1056.0  \n",
       "DTC_1             1056.0  \n",
       "RF_2              1056.0  \n",
       "RF_5              1056.0  \n",
       "LR_2              1056.0  \n",
       "RF_0              1056.0  \n",
       "RF_1              1056.0  \n",
       "RF_3              1056.0  \n",
       "RF_4              1056.0  \n",
       "LR_14             1056.0  \n",
       "LR_16             1056.0  \n",
       "LR_10             1056.0  \n",
       "LR_8              1056.0  \n",
       "LR_6              1056.0  \n",
       "LR_4              1056.0  \n",
       "LR_0              1056.0  \n",
       "LR_12             1056.0  \n",
       "Knn_6             1056.0  \n",
       "Knn_5             1056.0  \n",
       "Knn_7             1056.0  \n",
       "Knn_8             1056.0  \n",
       "Knn_10            1056.0  \n",
       "Knn_12            1056.0  \n",
       "Knn_11            1056.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_chart.T.sort_values(by='Accuracy/Score', ascending=False).head(25).sort_values(by=['False Positives'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation Takeaways\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation Takeaways\n",
    "- Goal:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20 = model_descriptions.sort_values('Accuracy(Score)', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selectors(parameters):\n",
    "    removal_list = ['Depth: ','K-Neighbors: ','Leaves: ','C: ',' Solver: ', ' Class Weight: ']\n",
    "\n",
    "    for word in removal_list:\n",
    "        parameters = parameters.replace(word, \"\")\n",
    "\n",
    "    return parameters.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_on_validation(descriptions, subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_validate= subsets[3]\n",
    "    y_validate = subsets[4]\n",
    "\n",
    "    \n",
    "    validate_metrics = create_comp_chart()\n",
    "    val_descriptions = create_description_chart(y_validate)\n",
    "    \n",
    "    #feat_set = descriptions.iloc[1]['Features Used'].strip('\\[]\\'').split('\\', \\'')\n",
    "    print(descriptions.index)\n",
    "    for idx in descriptions.index:\n",
    "\n",
    "        model_id = descriptions.loc[idx]['Model']\n",
    "        feat_set = descriptions.loc[idx]['Features Used'].strip('\\[]\\'').split('\\', \\'')\n",
    "        selectors = get_selectors(descriptions.loc[idx]['Parameters'])\n",
    "\n",
    "        features = []\n",
    "\n",
    "        for feature in feat_set:\n",
    "            features += [col for col in train.columns if feature in col]\n",
    "\n",
    "        if model_id.startswith('DTC'):\n",
    "            val_model = DecisionTreeClassifier(max_depth=int(selectors[0]),\\\n",
    "                                                random_state=514)\n",
    "        elif model_id.startswith('RF'):\n",
    "            val_model = RandomForestClassifier(max_depth=int(selectors[0]),\\\n",
    "                                            min_samples_leaf=int(selectors[1]),\n",
    "                                            random_state=514)\n",
    "        elif model_id.startswith('Knn'):\n",
    "            val_model = KNeighborsClassifier(n_neighbors = int(selectors[0]))\n",
    "        elif model_id.startswith('LR'):\n",
    "            val_model = LogisticRegression(C=float(selectors[0]),\\\n",
    "                                            solver=selectors[1],\n",
    "                                            class_weight=selectors[2],\n",
    "                                            max_iter=200,\n",
    "                                            random_state=514)  \n",
    "                                    \n",
    "        val_model.fit(X_train[features], y_train)\n",
    "\n",
    "        validate_metrics[model_id] = model.compute_metrics(val_model, X_validate[features], y_validate).values\n",
    "\n",
    "        score = val_model.score(X_validate[features], y_validate).round(4)\n",
    "\n",
    "        val_descriptions.loc[idx+1] = {'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': descriptions.loc[idx]['Type'],\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': descriptions.loc[idx]['Parameters']\n",
    "        }\n",
    "        \n",
    "    val_descriptions.insert(loc=2, column='Sensitivity', value=0)\n",
    "\n",
    "    for idx in val_descriptions.index:\n",
    "        model_id = val_descriptions.loc[idx]['Model']\n",
    "        if model_id != 'Baseline':\n",
    "            val_descriptions.loc[idx, 'Sensitivity'] = validate_metrics.T.loc[model_id]['True Negative Rate']        \n",
    "\n",
    "\n",
    "    return val_descriptions, validate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_descriptions, validate_metrics = score_on_validation(top_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.962933</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LR_2</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Knn_5</td>\n",
       "      <td>0.967100</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Knn_10</td>\n",
       "      <td>0.967100</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR_16</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR_0</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.967900</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 25, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Knn_8</td>\n",
       "      <td>0.967200</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>K-Neighbors: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR_4</td>\n",
       "      <td>0.968300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>C: 0.1, Solver: sag, Class Weight: None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy(Score)                      Type  \\\n",
       "0   Baseline         0.962933            Basic Baseline   \n",
       "1      DTC_0         0.966500  Decision Tree Classifier   \n",
       "10      LR_2         0.968300       Logistic Regression   \n",
       "18     Knn_5         0.967100                       Knn   \n",
       "16    Knn_10         0.967100                       Knn   \n",
       "6      LR_16         0.968300       Logistic Regression   \n",
       "12      LR_0         0.968300       Logistic Regression   \n",
       "4       RF_5         0.967900             Random Forest   \n",
       "14     Knn_8         0.967200                       Knn   \n",
       "2      DTC_1         0.966500  Decision Tree Classifier   \n",
       "8       LR_4         0.968300       Logistic Regression   \n",
       "\n",
       "                                        Features Used  \\\n",
       "0                                 Baseline Prediction   \n",
       "1   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "10  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "18  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "16  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "6   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "12  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "4   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "14  ['marital_status', 'occupation', 'race', 'educ...   \n",
       "2   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "8   ['marital_status', 'occupation', 'race', 'educ...   \n",
       "\n",
       "                                       Parameters  \n",
       "0                                             n/a  \n",
       "1                                       Depth: 20  \n",
       "10      C: 0.1, Solver: lbfgs, Class Weight: None  \n",
       "18                                 K-Neighbors: 5  \n",
       "16                                K-Neighbors: 10  \n",
       "6           C: 1, Solver: sag, Class Weight: None  \n",
       "12  C: 0.1, Solver: newton-cg, Class Weight: None  \n",
       "4                            Depth: 25, Leaves: 1  \n",
       "14                                 K-Neighbors: 8  \n",
       "2                                       Depth: 22  \n",
       "8         C: 0.1, Solver: sag, Class Weight: None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>0.9665</td>\n",
       "      <td>11718.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>0.9665</td>\n",
       "      <td>11718.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>0.9679</td>\n",
       "      <td>11737.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_16</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_5</th>\n",
       "      <td>0.9671</td>\n",
       "      <td>11740.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_8</th>\n",
       "      <td>0.9672</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_10</th>\n",
       "      <td>0.9671</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "DTC_0           0.9665         11718.0            384.0            68.0   \n",
       "DTC_1           0.9665         11718.0            384.0            68.0   \n",
       "RF_5            0.9679         11737.0            386.0            66.0   \n",
       "LR_2            0.9683         11742.0            387.0            65.0   \n",
       "LR_16           0.9683         11742.0            387.0            65.0   \n",
       "LR_0            0.9683         11742.0            387.0            65.0   \n",
       "LR_4            0.9683         11742.0            387.0            65.0   \n",
       "Knn_5           0.9671         11740.0            399.0            53.0   \n",
       "Knn_8           0.9672         11742.0            400.0            52.0   \n",
       "Knn_10          0.9671         11742.0            401.0            51.0   \n",
       "\n",
       "        False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "DTC_0              24.0      0.9980               0.8496              0.1504   \n",
       "DTC_1              24.0      0.9980               0.8496              0.1504   \n",
       "RF_5                5.0      0.9996               0.8540              0.1460   \n",
       "LR_2                0.0      1.0000               0.8562              0.1438   \n",
       "LR_16               0.0      1.0000               0.8562              0.1438   \n",
       "LR_0                0.0      1.0000               0.8562              0.1438   \n",
       "LR_4                0.0      1.0000               0.8562              0.1438   \n",
       "Knn_5               2.0      0.9998               0.8827              0.1173   \n",
       "Knn_8               0.0      1.0000               0.8850              0.1150   \n",
       "Knn_10              0.0      1.0000               0.8872              0.1128   \n",
       "\n",
       "        False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "DTC_0                0.0020     0.9683    0.9829           11742.0   \n",
       "DTC_1                0.0020     0.9683    0.9829           11742.0   \n",
       "RF_5                 0.0004     0.9682    0.9836           11742.0   \n",
       "LR_2                 0.0000     0.9681    0.9838           11742.0   \n",
       "LR_16                0.0000     0.9681    0.9838           11742.0   \n",
       "LR_0                 0.0000     0.9681    0.9838           11742.0   \n",
       "LR_4                 0.0000     0.9681    0.9838           11742.0   \n",
       "Knn_5                0.0002     0.9671    0.9832           11742.0   \n",
       "Knn_8                0.0000     0.9671    0.9833           11742.0   \n",
       "Knn_10               0.0000     0.9670    0.9832           11742.0   \n",
       "\n",
       "        Support Negative  \n",
       "DTC_0              452.0  \n",
       "DTC_1              452.0  \n",
       "RF_5               452.0  \n",
       "LR_2               452.0  \n",
       "LR_16              452.0  \n",
       "LR_0               452.0  \n",
       "LR_4               452.0  \n",
       "Knn_5              452.0  \n",
       "Knn_8              452.0  \n",
       "Knn_10             452.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validate_metrics.T.sort_values(by='True Negative Rate', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "> Initial: All three chosen sets perform baseline. Need to re-adjust and re-attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = val_descriptions[val_descriptions.Model == 'DTC_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Accuracy(Score)                      Type  \\\n",
       "1  DTC_0           0.9665  Decision Tree Classifier   \n",
       "\n",
       "                                       Features Used Parameters  \n",
       "1  ['marital_status', 'occupation', 'race', 'educ...  Depth: 20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC_0\n"
     ]
    }
   ],
   "source": [
    "for idx in top_model.index:\n",
    "    print(top_model.loc[idx]['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_on_test(descriptions, subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_test = subsets[5]\n",
    "    y_test = subsets[6]\n",
    "\n",
    "    test_metrics = create_comp_chart()\n",
    "    test_descriptions = create_description_chart(y_test)\n",
    "        \n",
    "    for idx in descriptions.index:\n",
    "        \n",
    "        model_id = descriptions.loc[idx]['Model']\n",
    "        feat_set = descriptions.loc[idx]['Features Used'].strip('\\[]\\'').split('\\', \\'')\n",
    "        selectors = get_selectors(descriptions.loc[idx]['Parameters'])\n",
    "\n",
    "        features = []\n",
    "\n",
    "        for feature in feat_set:\n",
    "            features += [col for col in train.columns if feature in col]\n",
    "\n",
    "        if model_id.startswith('DTC'):\n",
    "            test_model = DecisionTreeClassifier(max_depth=int(selectors[0]),\\\n",
    "                                                random_state=514)\n",
    "        elif model_id.startswith('RF'):\n",
    "            test_model = RandomForestClassifier(max_depth=int(selectors[0]),\\\n",
    "                                            min_samples_leaf=int(selectors[1]),\n",
    "                                            random_state=514)\n",
    "        elif model_id.startswith('Knn'):\n",
    "            test_model = KNeighborsClassifier(n_neighbors = int(selectors[0]))\n",
    "        elif model_id.startswith('LR'):\n",
    "            test_model = LogisticRegression(C=float(selectors[0]),\\\n",
    "                                            solver=selectors[1],\n",
    "                                            class_weight=selectors[2],\n",
    "                                            max_iter=200,\n",
    "                                            random_state=514)  \n",
    "                                    \n",
    "        test_model.fit(X_train[features], y_train)\n",
    "\n",
    "        test_metrics[model_id] = compute_metrics(test_model, X_test[features], y_test).values\n",
    "\n",
    "        score = test_model.score(X_test[features], y_test).round(4)\n",
    "\n",
    "        test_descriptions.loc[idx+1] = {'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': descriptions.loc[idx]['Type'],\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': descriptions.loc[idx]['Parameters']\n",
    "        }\n",
    "\n",
    "    return test_descriptions, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_descriptions, test_metrics = score_on_test(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTC_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positives</th>\n",
       "      <td>9771.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positives</th>\n",
       "      <td>328.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negatives</th>\n",
       "      <td>49.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negatives</th>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR/Recall</th>\n",
       "      <td>0.9986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative Rate</th>\n",
       "      <td>0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.9828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Positive</th>\n",
       "      <td>9785.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Negative</th>\n",
       "      <td>377.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DTC_0\n",
       "Accuracy/Score          0.9663\n",
       "True Positives       9771.0000\n",
       "False Positives       328.0000\n",
       "True Negatives         49.0000\n",
       "False Negatives        14.0000\n",
       "TPR/Recall              0.9986\n",
       "False Positive Rate     0.8700\n",
       "True Negative Rate      0.1300\n",
       "False Negative Rate     0.0014\n",
       "Precision               0.9675\n",
       "F1-Score                0.9828\n",
       "Support Positive     9785.0000\n",
       "Support Negative      377.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_chart():\n",
    "    \"\"\"\n",
    "    purpose: to create a dataframe with an index reflecting compuation metrics for future models\n",
    "\n",
    "    returns: a pandas dataframe with appropriately set index\n",
    "    \"\"\"\n",
    "    statistics = ['Accuracy/Score',\n",
    "    'True Positives' , 'False Positives', 'True Negatives', 'False Negatives', \\\n",
    "    'TPR/Recall', 'False Positive Rate', 'True Negative Rate', 'False Negative Rate', \\\n",
    "    'Precision', 'F1-Score', 'Support Positive', 'Support Negative']\n",
    "\n",
    "\n",
    "    return pd.DataFrame({}, index=statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X, y, feature_groups, subsets):\n",
    "    \n",
    "   #take in features sets and run them through each of the different types\n",
    "   #of models and their variations\n",
    "   train_descriptions = create_description_chart(y)\n",
    "   train_metrics = create_comp_chart()\n",
    "\n",
    "   for features in feature_groups:\n",
    "      \n",
    "      train_descriptions, train_metrics = model_dtc(features, train_descriptions, train_metrics, subsets)\n",
    "      train_descriptions, train_metrics = model_rf(features, train_descriptions, train_metrics, subsets)\n",
    "      #train_descriptions, train_metrics = model_knn(features, train_descriptions, train_metrics, subsets)\n",
    "      train_descriptions, train_metrics = model_lr(features, train_descriptions, train_metrics, subsets)\n",
    "\n",
    "   train_descriptions.insert(loc=2, column='Sensitivity', value=0)\n",
    "\n",
    "   for idx in train_descriptions.index:\n",
    "      model_id = train_descriptions.iloc[idx]['Model']\n",
    "      if model_id != 'Baseline':\n",
    "         train_descriptions.loc[idx, 'Sensitivity'] = train_metrics.T.loc[model_id]['True Negative Rate']\n",
    "         \n",
    "   return train_descriptions, train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_final_report(train, feature_bank):\n",
    "\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = split_X_y(train)\n",
    "\n",
    "    subsets=[train, X_train, y_train, X_validate, y_validate, X_test, y_test]\n",
    "\n",
    "    train_descriptions, train_metrics = train_models(X_train, y_train, feature_bank, subsets)\n",
    "\n",
    "    train_descriptions[train_descriptions.Sensitivity > .20].\\\n",
    "        sort_values('Accuracy(Score)', ascending=False).\\\n",
    "        head(20)\n",
    "\n",
    "    top_4 = train_descriptions[train_descriptions.Sensitivity > .20].\\\n",
    "        sort_values('Accuracy(Score)', ascending=False).\\\n",
    "        head(4)\n",
    "\n",
    "    val_descriptions, validate_metrics = score_on_validation(top_4, subsets)\n",
    "\n",
    "    top_1 = val_descriptions[(val_descriptions.Sensitivity > .20) & (val_descriptions['Accuracy(Score)'] > .66)].\\\n",
    "        sort_values('Sensitivity', ascending=False).\\\n",
    "        head(1)\n",
    "\n",
    "    test_descriptions, test_metrics = score_on_test(top_1, subsets)\n",
    "\n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([12, 8, 10, 14], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <td>0.6684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positives</th>\n",
       "      <td>6554.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positives</th>\n",
       "      <td>139.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negatives</th>\n",
       "      <td>238.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negatives</th>\n",
       "      <td>3231.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR/Recall</th>\n",
       "      <td>0.6698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative Rate</th>\n",
       "      <td>0.6313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.3302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.7955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Positive</th>\n",
       "      <td>9785.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Negative</th>\n",
       "      <td>377.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          LR_7\n",
       "Accuracy/Score          0.6684\n",
       "True Positives       6554.0000\n",
       "False Positives       139.0000\n",
       "True Negatives        238.0000\n",
       "False Negatives      3231.0000\n",
       "TPR/Recall              0.6698\n",
       "False Positive Rate     0.3687\n",
       "True Negative Rate      0.6313\n",
       "False Negative Rate     0.3302\n",
       "Precision               0.9792\n",
       "F1-Score                0.7955\n",
       "Support Positive     9785.0000\n",
       "Support Negative      377.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for_final_report(train, [feat_set])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
