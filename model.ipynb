{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#use multinomial naive bayes algorithm after the other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import wrangle, model\n",
    "\n",
    "from importlib import reload\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wrangle' from '/Users/sinao/codeup-data-science/nlp_project/wrangle.py'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(wrangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle.get_search_csv()\n",
    "df = wrangle.prep_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVE AFTER HE ADDS THIS GETS MOVED INTO PPREPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language = df.language.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language_bigrams'] = df.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created class in order to facilitate bigram and trigram creation\n",
    "class code_language:\n",
    "  def __init__(self, words, label:str):\n",
    "    self.words = words\n",
    "    self.label = label\n",
    "    self.unique_to_language = set()\n",
    "\n",
    "  def whole_words(self): \n",
    "    return pd.Series(self.words.split())\n",
    "\n",
    "  def word_counts(self):\n",
    "    return pd.Series(self.words.split()).value_counts()\n",
    "\n",
    "  def unique_words(self):\n",
    "    return set(pd.Series(self.whole_words().unique()))\n",
    "\n",
    "  def bigrams(self):\n",
    "    return pd.Series(list(nltk.bigrams(self.words.split())))\n",
    "\n",
    "  def trigrams(self):\n",
    "    return pd.Series(list(nltk.ngrams(self.words.split(), 3)))\n",
    "\n",
    "  def readme_count(self):\n",
    "    return df[df.language == self.label].word_count.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this initilizes the class objects. \n",
    "html = code_language(words=' '.join(df[df.language == 'html'].lemmatized), label='html')\n",
    "javascript = code_language(words=' '.join(df[df.language == 'javascript'].lemmatized), label='javascript')\n",
    "r_ = code_language(words=' '.join(df[df.language == 'r'].lemmatized), label='r')\n",
    "other_ = code_language(words=' '.join(df[df.language == 'other'].lemmatized), label='other')\n",
    "python_ = code_language(words=' '.join(df[df.language == 'python'].lemmatized), label='python')\n",
    "all_ = code_language(words=' '.join(df.lemmatized), label='all languages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_placement(language):\n",
    "\n",
    "    if language == 'html':\n",
    "        language = html.bigrams()\n",
    "    elif language == 'javascript':\n",
    "        language = javascript.bigrams()\n",
    "    elif language == 'r':\n",
    "        language = r_.bigrams()\n",
    "    elif language == 'python':\n",
    "        language = python_.bigrams()\n",
    "    else:\n",
    "        language = other_.bigrams()\n",
    "    return ', '.join(str(e) for e in language.str.join(sep=' ').to_list())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language_bigrams = df.language_bigrams.apply(bigram_placement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      install usage, usage game, game check, check s...\n",
       "2      readmemd dunk, dunk dunk, dunk dribbble, dribb...\n",
       "3      getting started, started get, get copy, copy p...\n",
       "5      install usage, usage game, game check, check s...\n",
       "7      getting started, started get, get copy, copy p...\n",
       "                             ...                        \n",
       "185    getting started, started get, get copy, copy p...\n",
       "186    getting started, started get, get copy, copy p...\n",
       "188    readmemd dunk, dunk dunk, dunk dribbble, dribb...\n",
       "189    getting started, started get, get copy, copy p...\n",
       "190    ncaahoopr installation, installation function,...\n",
       "Name: language_bigrams, Length: 179, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## Fit Vectorizer\n",
    "# Setup\n",
    "Explore various models and feature combinations.\n",
    "Choose **three** models to validate. Choose **one** to test. \n",
    "Artifact: `model.py`\n",
    "### Modeling Preparation\n",
    "- Create function to vectorize, scale, and split data\n",
    "- Create word_count feature --> backport to wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_set = ['word_count', 'lemmatized', 'language_bigrams']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Prediction and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorize_split(df):\n",
    "\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        \n",
    "    ---\n",
    "    Parameters:\n",
    "        \n",
    "    ---\n",
    "    Returns:\n",
    "        X_train, y_train, X_validate, y_validate, X_test, y_test: data subsets\n",
    "    \"\"\"\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    df['lemmatized'] = tfidf.fit_transform(df.lemmatized).todense()\n",
    "    df['language_bigrams']= tfidf.fit_transform(df.language_bigrams).todense()\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit_transform(df[['word_count']])\n",
    "\n",
    "    train_validate, test = train_test_split(df, test_size=.3, random_state=514, stratify=df['language'])\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=514, stratify=train_validate['language'])\n",
    "\n",
    "     # split data into Big X, small y sets \n",
    "    X_train = train.drop(columns=['language'])\n",
    "    y_train = train.language\n",
    "\n",
    "    X_validate = validate.drop(columns=['language'])\n",
    "    y_validate = validate.language\n",
    "\n",
    "    X_test = test.drop(columns=['language'])\n",
    "    y_test = test.language\n",
    "\n",
    "    return train, X_train, y_train, X_validate, y_validate, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_train, y_train, X_validate, y_validate, X_test, y_test = vectorize_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "python        0.402299\n",
       "other         0.252874\n",
       "r             0.160920\n",
       "javascript    0.114943\n",
       "html          0.068966\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formulate baseline prediction ->base prediction is python\n",
    "train.language.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, X_df, y_df):\n",
    "    \"\"\"\n",
    "    purpose: function executes performs computations to produce evaulation metrics for a given model\n",
    "\n",
    "    inputs: \n",
    "        model: a model that has been previous fit to spec\n",
    "        X_df: a dataframe featuring the X subset of data for evaluation\n",
    "        y_df: a dataframe featuring the model target variable\n",
    "\n",
    "    Returns: a rounded pandas Series that can be adding to an evaulation metric comparison chart\n",
    "    \"\"\"\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_df)\n",
    "\n",
    "    # Estimate Probability \n",
    "    y_pred_proba = model.predict_proba(X_df)\n",
    "\n",
    "    #create confusion matrix\n",
    "    confusion = confusion_matrix(y_df, y_pred)\n",
    "\n",
    "    #assign results of confusion matrix to variables\n",
    "    true_negative = confusion[0,0]\n",
    "    false_positive = confusion[0,1]\n",
    "    false_negative = confusion[1,0]\n",
    "    true_positive = confusion[1,1]\n",
    "\n",
    "    #accuracy\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "\n",
    "    #true positive rate / recall\n",
    "    recall = true_positive / (true_positive +false_negative)\n",
    "\n",
    "    #false positive rate\n",
    "    false_positive_rate = false_positive / (true_negative + false_positive)\n",
    "\n",
    "    #true negative rate\n",
    "    true_negative_rate = true_negative / (true_negative + false_positive)\n",
    "\n",
    "    #false negative rate\n",
    "    false_negative_rate = false_negative / (false_negative + true_positive)\n",
    "\n",
    "    #precision\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "    #f1-score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    #support\n",
    "    support_positive = true_positive + false_negative\n",
    "    support_negative = false_positive + true_negative\n",
    "\n",
    "    metrics = pd.Series([accuracy, true_positive, false_positive, true_negative, false_negative,\\\n",
    "                        recall, false_positive_rate, true_negative_rate, false_negative_rate, \\\n",
    "                        precision, f1_score, support_positive, support_negative])\n",
    "                        \n",
    "    return metrics.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_chart():\n",
    "    \"\"\"\n",
    "    purpose: to create a dataframe with an index reflecting compuation metrics for future models\n",
    "\n",
    "    returns: a pandas dataframe with appropriately set index\n",
    "    \"\"\"\n",
    "    statistics = ['Accuracy/Score',\n",
    "    'True Positives' , 'False Positives', 'True Negatives', 'False Negatives', \\\n",
    "    'TPR/Recall', 'False Positive Rate', 'True Negative Rate', 'False Negative Rate', \\\n",
    "    'Precision', 'F1-Score', 'Support Positive', 'Support Negative']\n",
    "\n",
    "\n",
    "    return pd.DataFrame({}, index=statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy for \"language\" prediction:  40.2%\n"
     ]
    }
   ],
   "source": [
    "# formulate baseline accuracy\n",
    "baseline_accuracy = (y_train == 'python').mean()\n",
    "\n",
    "print(f'Baseline Accuracy for \\\"language\\\" prediction: {(baseline_accuracy * 100): .3}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_description_chart(y):\n",
    "\n",
    "    # formulate baseline accuracy\n",
    "    baseline_accuracy = (y == 'python').mean()\n",
    "\n",
    "    descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "                                'Accuracy(Score)': baseline_accuracy,\n",
    "                                'Type': 'Basic Baseline',\n",
    "                                'Features Used': 'Baseline Prediction',\n",
    "                                'Parameters': 'n/a'\n",
    "                                }, index=[0])\n",
    "    \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)            Type        Features Used Parameters\n",
       "0  Baseline         0.402299  Basic Baseline  Baseline Prediction        n/a\n",
       "1  Baseline         0.402299  Basic Baseline  Baseline Prediction        n/a"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([model_descriptions, pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0]) ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_chart = model.create_comp_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [train, X_train, y_train, X_validate, y_validate, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dtc(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product(np.arange(5,10,1)))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'DTC_'+f'{idx}'\n",
    "        dtc = DecisionTreeClassifier(max_depth=item[0],\\\n",
    "                                            random_state=514)\n",
    "        \n",
    "        dtc.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(dtc, X_train[features], y_train).values\n",
    "\n",
    "        score = dtc.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Decision Tree Classifier',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}'},\n",
    "                                    index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart =  model_dtc(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTC_4</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_3</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Accuracy(Score)                      Type  \\\n",
       "5  DTC_4           0.9655  Decision Tree Classifier   \n",
       "3  DTC_2           0.9425  Decision Tree Classifier   \n",
       "4  DTC_3           0.9425  Decision Tree Classifier   \n",
       "2  DTC_1           0.9195  Decision Tree Classifier   \n",
       "1  DTC_0           0.8966  Decision Tree Classifier   \n",
       "\n",
       "                                      Features Used Parameters  \n",
       "5  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 9  \n",
       "3  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 7  \n",
       "4  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 8  \n",
       "2  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 6  \n",
       "1  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 5  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.sort_values(by='Accuracy(Score)', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product([5,10,7], [3,2,1]))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'RF_'+f'{idx}'\n",
    "        rf = RandomForestClassifier(max_depth=item[0],\\\n",
    "                                            min_samples_leaf=item[1],\n",
    "                                            random_state=514)\n",
    "        \n",
    "        rf.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(rf, X_train[features], y_train).values\n",
    "\n",
    "        score = rf.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Random Forest',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}, Leaves: {item[1]}'},\n",
    "                                    index=[0])\n",
    "       \n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart = model_rf(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.896600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_3</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTC_4</td>\n",
       "      <td>0.965500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_0</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_1</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_2</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_3</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF_4</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF_6</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF_7</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF_8</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy(Score)                      Type  \\\n",
       "0   Baseline         0.402299            Basic Baseline   \n",
       "1      DTC_0         0.896600  Decision Tree Classifier   \n",
       "2      DTC_1         0.919500  Decision Tree Classifier   \n",
       "3      DTC_2         0.942500  Decision Tree Classifier   \n",
       "4      DTC_3         0.942500  Decision Tree Classifier   \n",
       "5      DTC_4         0.965500  Decision Tree Classifier   \n",
       "6       RF_0         0.919500             Random Forest   \n",
       "7       RF_1         0.931000             Random Forest   \n",
       "8       RF_2         0.954000             Random Forest   \n",
       "9       RF_3         0.919500             Random Forest   \n",
       "10      RF_4         0.942500             Random Forest   \n",
       "11      RF_5         1.000000             Random Forest   \n",
       "12      RF_6         0.919500             Random Forest   \n",
       "13      RF_7         0.942500             Random Forest   \n",
       "14      RF_8         0.988500             Random Forest   \n",
       "\n",
       "                                       Features Used            Parameters  \n",
       "0                                Baseline Prediction                   n/a  \n",
       "1   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 5  \n",
       "2   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 6  \n",
       "3   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 7  \n",
       "4   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 8  \n",
       "5   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 9  \n",
       "6   ['word_count', 'lemmatized', 'language_bigrams']   Depth: 5, Leaves: 3  \n",
       "7   ['word_count', 'lemmatized', 'language_bigrams']   Depth: 5, Leaves: 2  \n",
       "8   ['word_count', 'lemmatized', 'language_bigrams']   Depth: 5, Leaves: 1  \n",
       "9   ['word_count', 'lemmatized', 'language_bigrams']  Depth: 10, Leaves: 3  \n",
       "10  ['word_count', 'lemmatized', 'language_bigrams']  Depth: 10, Leaves: 2  \n",
       "11  ['word_count', 'lemmatized', 'language_bigrams']  Depth: 10, Leaves: 1  \n",
       "12  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 7, Leaves: 3  \n",
       "13  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 7, Leaves: 2  \n",
       "14  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 7, Leaves: 1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways - Random Forest\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors\n",
    "def model_knn(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    k_range = range(3, 7)\n",
    "    scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train[features], y_train)\n",
    "        scores.append(knn.score(X_train[features], y_train))\n",
    "\n",
    "        model_id = 'Knn_'+f'{k}'\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(knn, X_train[features], y_train).values\n",
    "\n",
    "        score = knn.score(X_train[features], y_train).round(5)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Knn',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'K-Neighbors: {k}'},\n",
    "            index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.scatter(k_range, scores)\n",
    "    plt.xticks([0,5,10,15,20])\n",
    "    plt.show()\n",
    "    np.mean(scores)\n",
    "\n",
    "    \n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/sinao/codeup-data-science/nlp_project/model.py'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions, comparison_chart = model_knn(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF_8</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTC_4</td>\n",
       "      <td>0.965500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_2</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF_4</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_3</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF_7</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_1</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF_6</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_3</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_0</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.896600</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Knn_3</td>\n",
       "      <td>0.563220</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>K-Neighbors: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Knn_4</td>\n",
       "      <td>0.563220</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>K-Neighbors: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Knn_5</td>\n",
       "      <td>0.505750</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>K-Neighbors: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Knn_6</td>\n",
       "      <td>0.505750</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>K-Neighbors: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy(Score)                      Type  \\\n",
       "11      RF_5         1.000000             Random Forest   \n",
       "14      RF_8         0.988500             Random Forest   \n",
       "5      DTC_4         0.965500  Decision Tree Classifier   \n",
       "8       RF_2         0.954000             Random Forest   \n",
       "10      RF_4         0.942500             Random Forest   \n",
       "3      DTC_2         0.942500  Decision Tree Classifier   \n",
       "4      DTC_3         0.942500  Decision Tree Classifier   \n",
       "13      RF_7         0.942500             Random Forest   \n",
       "7       RF_1         0.931000             Random Forest   \n",
       "12      RF_6         0.919500             Random Forest   \n",
       "9       RF_3         0.919500             Random Forest   \n",
       "6       RF_0         0.919500             Random Forest   \n",
       "2      DTC_1         0.919500  Decision Tree Classifier   \n",
       "1      DTC_0         0.896600  Decision Tree Classifier   \n",
       "15     Knn_3         0.563220                       Knn   \n",
       "16     Knn_4         0.563220                       Knn   \n",
       "17     Knn_5         0.505750                       Knn   \n",
       "18     Knn_6         0.505750                       Knn   \n",
       "0   Baseline         0.402299            Basic Baseline   \n",
       "\n",
       "                                       Features Used            Parameters  \n",
       "11  ['word_count', 'lemmatized', 'language_bigrams']  Depth: 10, Leaves: 1  \n",
       "14  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 7, Leaves: 1  \n",
       "5   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 9  \n",
       "8   ['word_count', 'lemmatized', 'language_bigrams']   Depth: 5, Leaves: 1  \n",
       "10  ['word_count', 'lemmatized', 'language_bigrams']  Depth: 10, Leaves: 2  \n",
       "3   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 7  \n",
       "4   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 8  \n",
       "13  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 7, Leaves: 2  \n",
       "7   ['word_count', 'lemmatized', 'language_bigrams']   Depth: 5, Leaves: 2  \n",
       "12  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 7, Leaves: 3  \n",
       "9   ['word_count', 'lemmatized', 'language_bigrams']  Depth: 10, Leaves: 3  \n",
       "6   ['word_count', 'lemmatized', 'language_bigrams']   Depth: 5, Leaves: 3  \n",
       "2   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 6  \n",
       "1   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 5  \n",
       "15  ['word_count', 'lemmatized', 'language_bigrams']        K-Neighbors: 3  \n",
       "16  ['word_count', 'lemmatized', 'language_bigrams']        K-Neighbors: 4  \n",
       "17  ['word_count', 'lemmatized', 'language_bigrams']        K-Neighbors: 5  \n",
       "18  ['word_count', 'lemmatized', 'language_bigrams']        K-Neighbors: 6  \n",
       "0                                Baseline Prediction                   n/a  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.sort_values(by='Accuracy(Score)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lr(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    cees = [.1,.5,1]\n",
    "    solver = ['newton-cg', 'lbfgs']\n",
    "    weights = [None, 'balanced']\n",
    "\n",
    "    selectors = list(product(cees, solver, weights))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'LR_'+f'{idx}'\n",
    "        lr = LogisticRegression(C=item[0],\\\n",
    "                                solver=item[1],\n",
    "                                class_weight=item[2],\n",
    "                                max_iter=400,\n",
    "                                random_state=514)\n",
    "        \n",
    "        lr.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(lr, X_train[features], y_train).values\n",
    "\n",
    "        score = lr.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Logistic Regression',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'C: {item[0]}, Solver: {item[1]}, Class Weight: {item[2]}'},\n",
    "            index=[0])\n",
    "        \n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/sinao/codeup-data-science/nlp_project/model.py'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart = model_lr(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description and Comparison Charts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Basic Baseline              0.402299\n",
       "Decision Tree Classifier    0.933320\n",
       "Knn                         0.534485\n",
       "Logistic Regression         0.341975\n",
       "Random Forest               0.946333\n",
       "Name: Accuracy(Score), dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.groupby('Type')['Accuracy(Score)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF_8</td>\n",
       "      <td>0.98850</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTC_4</td>\n",
       "      <td>0.96550</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_2</td>\n",
       "      <td>0.95400</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.94250</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_3</td>\n",
       "      <td>0.94250</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF_4</td>\n",
       "      <td>0.94250</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF_7</td>\n",
       "      <td>0.94250</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_1</td>\n",
       "      <td>0.93100</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF_6</td>\n",
       "      <td>0.91950</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.91950</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_0</td>\n",
       "      <td>0.91950</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_3</td>\n",
       "      <td>0.91950</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.89660</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Knn_4</td>\n",
       "      <td>0.56322</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>K-Neighbors: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Knn_3</td>\n",
       "      <td>0.56322</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>K-Neighbors: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Knn_5</td>\n",
       "      <td>0.50575</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>K-Neighbors: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Knn_6</td>\n",
       "      <td>0.50575</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>K-Neighbors: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LR_6</td>\n",
       "      <td>0.41380</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>C: 0.5, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR_0</td>\n",
       "      <td>0.41380</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy(Score)                      Type  \\\n",
       "11   RF_5          1.00000             Random Forest   \n",
       "14   RF_8          0.98850             Random Forest   \n",
       "5   DTC_4          0.96550  Decision Tree Classifier   \n",
       "8    RF_2          0.95400             Random Forest   \n",
       "3   DTC_2          0.94250  Decision Tree Classifier   \n",
       "4   DTC_3          0.94250  Decision Tree Classifier   \n",
       "10   RF_4          0.94250             Random Forest   \n",
       "13   RF_7          0.94250             Random Forest   \n",
       "7    RF_1          0.93100             Random Forest   \n",
       "12   RF_6          0.91950             Random Forest   \n",
       "2   DTC_1          0.91950  Decision Tree Classifier   \n",
       "6    RF_0          0.91950             Random Forest   \n",
       "9    RF_3          0.91950             Random Forest   \n",
       "1   DTC_0          0.89660  Decision Tree Classifier   \n",
       "16  Knn_4          0.56322                       Knn   \n",
       "15  Knn_3          0.56322                       Knn   \n",
       "17  Knn_5          0.50575                       Knn   \n",
       "18  Knn_6          0.50575                       Knn   \n",
       "25   LR_6          0.41380       Logistic Regression   \n",
       "19   LR_0          0.41380       Logistic Regression   \n",
       "\n",
       "                                       Features Used  \\\n",
       "11  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "14  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "5   ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "8   ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "3   ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "4   ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "10  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "13  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "7   ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "12  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "2   ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "6   ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "9   ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "1   ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "16  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "15  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "17  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "18  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "25  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "19  ['word_count', 'lemmatized', 'language_bigrams']   \n",
       "\n",
       "                                       Parameters  \n",
       "11                           Depth: 10, Leaves: 1  \n",
       "14                            Depth: 7, Leaves: 1  \n",
       "5                                        Depth: 9  \n",
       "8                             Depth: 5, Leaves: 1  \n",
       "3                                        Depth: 7  \n",
       "4                                        Depth: 8  \n",
       "10                           Depth: 10, Leaves: 2  \n",
       "13                            Depth: 7, Leaves: 2  \n",
       "7                             Depth: 5, Leaves: 2  \n",
       "12                            Depth: 7, Leaves: 3  \n",
       "2                                        Depth: 6  \n",
       "6                             Depth: 5, Leaves: 3  \n",
       "9                            Depth: 10, Leaves: 3  \n",
       "1                                        Depth: 5  \n",
       "16                                 K-Neighbors: 4  \n",
       "15                                 K-Neighbors: 3  \n",
       "17                                 K-Neighbors: 5  \n",
       "18                                 K-Neighbors: 6  \n",
       "25      C: 0.5, Solver: lbfgs, Class Weight: None  \n",
       "19  C: 0.1, Solver: newton-cg, Class Weight: None  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.sort_values(by='Accuracy(Score)',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 10, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF_8</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTC_4</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_2</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy(Score)                      Type  \\\n",
       "11   RF_5           1.0000             Random Forest   \n",
       "14   RF_8           0.9885             Random Forest   \n",
       "5   DTC_4           0.9655  Decision Tree Classifier   \n",
       "8    RF_2           0.9540             Random Forest   \n",
       "3   DTC_2           0.9425  Decision Tree Classifier   \n",
       "\n",
       "                                       Features Used            Parameters  \n",
       "11  ['word_count', 'lemmatized', 'language_bigrams']  Depth: 10, Leaves: 1  \n",
       "14  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 7, Leaves: 1  \n",
       "5   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 9  \n",
       "8   ['word_count', 'lemmatized', 'language_bigrams']   Depth: 5, Leaves: 1  \n",
       "3   ['word_count', 'lemmatized', 'language_bigrams']              Depth: 7  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model descriptions\n",
    "model_descriptions.sort_values('Accuracy(Score)', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31 entries, 0 to 30\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Model            31 non-null     object \n",
      " 1   Accuracy(Score)  31 non-null     float64\n",
      " 2   Type             31 non-null     object \n",
      " 3   Features Used    31 non-null     object \n",
      " 4   Parameters       31 non-null     object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "model_descriptions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation Takeaways\n",
    "- Had to abandon gridsearch script for lack of feasability\n",
    "- KNN underperforming with initial set of hyper parameters\n",
    "- KNN and Logistic regression continued to be low perfoming\n",
    "- First two rounds of batch model testing did not provide performance above 30%\n",
    "- 3rd round of testing incorporating bigrams showed dramatic improved.\n",
    "    - DTC and RF type models hovering above 85%\n",
    "- 4th round showed large possibility of overfitting on RF models so we reduced depth to below 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation - Top 5 Models from Train section\n",
    "\n",
    "Model\t| Accuracy(Score)   |Type                       |Features Used                           |Parameters             |\n",
    "|---    | ---               |---                        |   -----                                |---                    |\n",
    "|RF_6   |\t0.91950         |Random Forest              |word_count, lemmatized, language_bigrams|Depth: 7, Leaves: 3\n",
    "|RF_0   |\t0.91950         |Random Forest              |word_count, lemmatized, language_bigrams|Depth: 5, Leaves: 3\n",
    "|DTC_1  |   0.91950         |Decision Tree Classifier   |word_count, lemmatized, language_bigrams|Depth: 6\n",
    "|DTC_0  |\t0.89066\t        |Decision Tree Classifier\t|word_count, lemmatized, language_bigrams|Depth: 5\n",
    "|KNN_4  |\t0.56322\t        |K-Nearest Neighbors\t    |word_count, lemmatized, language_bigrams|K-Neighbors: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dtc(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_validate=subsets[3]\n",
    "    y_validate=subsets[4]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product(np.arange(5,7,1)))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'DTC_'+f'{idx}'\n",
    "        dtc = DecisionTreeClassifier(max_depth=item[0],\\\n",
    "                                            random_state=514)\n",
    "        \n",
    "        dtc.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(dtc, X_validate[features], y_validate).values\n",
    "\n",
    "        score = dtc.score(X_validate[features], y_validate).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Decision Tree Classifier',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}'},\n",
    "                                    index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_rf(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_validate=subsets[3]\n",
    "    y_validate=subsets[4]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product([5,7], [3]))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'RF_'+f'{idx}'\n",
    "        rf = RandomForestClassifier(max_depth=item[0],\\\n",
    "                                            min_samples_leaf=item[1],\n",
    "                                            random_state=514)\n",
    "        \n",
    "        rf.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(rf, X_validate[features], y_validate).values\n",
    "\n",
    "        score = rf.score(X_validate[features], y_validate).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Random Forest',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}, Leaves: {item[1]}'},\n",
    "                                    index=[0])\n",
    "       \n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors\n",
    "def validate_knn(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_validate=subsets[3]\n",
    "    y_validate=subsets[4]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    k_range = range(4, 5)\n",
    "    scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train[features], y_train)\n",
    "        scores.append(knn.score(X_train[features], y_train))\n",
    "\n",
    "        model_id = 'Knn_'+f'{k}'\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(knn, X_validate[features], y_validate).values\n",
    "\n",
    "        score = knn.score(X_validate[features], y_validate).round(5)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Knn',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'K-Neighbors: {k}'},\n",
    "            index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.scatter(k_range, scores)\n",
    "    plt.xticks([0,5,10,15,20])\n",
    "    plt.show()\n",
    "    np.mean(scores)\n",
    "\n",
    "    \n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0])\n",
    "\n",
    "val_comparisons = model.create_comp_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_descriptions, val_comparisons =  validate_dtc(feat_set, validate_descriptions, val_comparisons, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_descriptions, val_comparisons =  validate_rf(feat_set, validate_descriptions, val_comparisons, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validate_descriptions, val_comparisons =  validate_knn(feat_set, validate_descriptions, val_comparisons, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.868400</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.842100</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_0</td>\n",
       "      <td>0.763200</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_1</td>\n",
       "      <td>0.763200</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 7, Leaves: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)                      Type  \\\n",
       "1     DTC_0         0.868400  Decision Tree Classifier   \n",
       "2     DTC_1         0.842100  Decision Tree Classifier   \n",
       "3      RF_0         0.763200             Random Forest   \n",
       "4      RF_1         0.763200             Random Forest   \n",
       "0  Baseline         0.402299            Basic Baseline   \n",
       "\n",
       "                                      Features Used           Parameters  \n",
       "1  ['word_count', 'lemmatized', 'language_bigrams']             Depth: 5  \n",
       "2  ['word_count', 'lemmatized', 'language_bigrams']             Depth: 6  \n",
       "3  ['word_count', 'lemmatized', 'language_bigrams']  Depth: 5, Leaves: 3  \n",
       "4  ['word_count', 'lemmatized', 'language_bigrams']  Depth: 7, Leaves: 3  \n",
       "0                               Baseline Prediction                  n/a  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_descriptions.sort_values(by='Accuracy(Score)', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Takeaways\n",
    "- Massive performance drop from Train set. \n",
    "- Indicative of over fitting. Made numerous adjustements to control for this. \n",
    "- Logistic Regression never made it to validation \n",
    "- Adjusting input data for hopeful performance gains.\n",
    "- Validation Performance on Top 5 from Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "- The Top performing model from Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_description = pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dtc(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_test=subsets[5]\n",
    "    y_test=subsets[6]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product(np.arange(5,6,1)))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'DTC_'+f'{idx}'\n",
    "        dtc = DecisionTreeClassifier(max_depth=item[0],\\\n",
    "                                            random_state=514)\n",
    "        \n",
    "        dtc.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(dtc, X_test[features], y_test).values\n",
    "\n",
    "        score = dtc.score(X_test[features], y_test).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Decision Tree Classifier',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}'},\n",
    "                                    index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comparisons = model.create_comp_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_description, test_comparisons = test_dtc(feat_set, test_description, test_comparisons, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.777800</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized', 'language_bigrams']</td>\n",
       "      <td>Depth: 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)                      Type  \\\n",
       "0  Baseline         0.402299            Basic Baseline   \n",
       "1     DTC_0         0.777800  Decision Tree Classifier   \n",
       "\n",
       "                                      Features Used Parameters  \n",
       "0                               Baseline Prediction        n/a  \n",
       "1  ['word_count', 'lemmatized', 'language_bigrams']   Depth: 5  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Modeling Takeaways\n",
    "- Things did not go as plan.\n",
    "- Had to abandon gridsearch idea\n",
    "- Logistic Regression never provided much performance gain above baseline\n",
    "- DTC models consistenly peformed well\n",
    "- Final Modele had 37% performamce gain above baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
