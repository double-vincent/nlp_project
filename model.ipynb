{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#use multinomial naive bayes algorithm after the other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import wrangle, model\n",
    "\n",
    "from importlib import reload\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wrangle' from '/Users/sinao/codeup-data-science/nlp_project/wrangle.py'>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(wrangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 201 stopwords\n",
      "---\n",
      "\n",
      "Removed 49 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n",
      "\n",
      "Removed 218 stopwords\n",
      "---\n",
      "\n",
      "Removed 401 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 50 stopwords\n",
      "---\n",
      "\n",
      "Removed 8 stopwords\n",
      "---\n",
      "\n",
      "Removed 158 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 44 stopwords\n",
      "---\n",
      "\n",
      "Removed 110 stopwords\n",
      "---\n",
      "\n",
      "Removed 500 stopwords\n",
      "---\n",
      "\n",
      "Removed 494 stopwords\n",
      "---\n",
      "\n",
      "Removed 31 stopwords\n",
      "---\n",
      "\n",
      "Removed 427 stopwords\n",
      "---\n",
      "\n",
      "Removed 76 stopwords\n",
      "---\n",
      "\n",
      "Removed 1 stopwords\n",
      "---\n",
      "\n",
      "Removed 175 stopwords\n",
      "---\n",
      "\n",
      "Removed 731 stopwords\n",
      "---\n",
      "\n",
      "Removed 68 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 358 stopwords\n",
      "---\n",
      "\n",
      "Removed 52 stopwords\n",
      "---\n",
      "\n",
      "Removed 15 stopwords\n",
      "---\n",
      "\n",
      "Removed 48 stopwords\n",
      "---\n",
      "\n",
      "Removed 100 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 134 stopwords\n",
      "---\n",
      "\n",
      "Removed 320 stopwords\n",
      "---\n",
      "\n",
      "Removed 27 stopwords\n",
      "---\n",
      "\n",
      "Removed 74 stopwords\n",
      "---\n",
      "\n",
      "Removed 88 stopwords\n",
      "---\n",
      "\n",
      "Removed 8 stopwords\n",
      "---\n",
      "\n",
      "Removed 272 stopwords\n",
      "---\n",
      "\n",
      "Removed 123 stopwords\n",
      "---\n",
      "\n",
      "Removed 389 stopwords\n",
      "---\n",
      "\n",
      "Removed 81 stopwords\n",
      "---\n",
      "\n",
      "Removed 187 stopwords\n",
      "---\n",
      "\n",
      "Removed 23 stopwords\n",
      "---\n",
      "\n",
      "Removed 25 stopwords\n",
      "---\n",
      "\n",
      "Removed 114 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 199 stopwords\n",
      "---\n",
      "\n",
      "Removed 95 stopwords\n",
      "---\n",
      "\n",
      "Removed 22 stopwords\n",
      "---\n",
      "\n",
      "Removed 220 stopwords\n",
      "---\n",
      "\n",
      "Removed 56 stopwords\n",
      "---\n",
      "\n",
      "Removed 20 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 10 stopwords\n",
      "---\n",
      "\n",
      "Removed 512 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 24 stopwords\n",
      "---\n",
      "\n",
      "Removed 926 stopwords\n",
      "---\n",
      "\n",
      "Removed 42 stopwords\n",
      "---\n",
      "\n",
      "Removed 115 stopwords\n",
      "---\n",
      "\n",
      "Removed 6 stopwords\n",
      "---\n",
      "\n",
      "Removed 30 stopwords\n",
      "---\n",
      "\n",
      "Removed 852 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 115 stopwords\n",
      "---\n",
      "\n",
      "Removed 61 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 53 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 157 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 1030 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 136 stopwords\n",
      "---\n",
      "\n",
      "Removed 16 stopwords\n",
      "---\n",
      "\n",
      "Removed 14 stopwords\n",
      "---\n",
      "\n",
      "Removed 61 stopwords\n",
      "---\n",
      "\n",
      "Removed 72 stopwords\n",
      "---\n",
      "\n",
      "Removed 52 stopwords\n",
      "---\n",
      "\n",
      "Removed 24 stopwords\n",
      "---\n",
      "\n",
      "Removed 13 stopwords\n",
      "---\n",
      "\n",
      "Removed 57 stopwords\n",
      "---\n",
      "\n",
      "Removed 84 stopwords\n",
      "---\n",
      "\n",
      "Removed 78 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 32 stopwords\n",
      "---\n",
      "\n",
      "Removed 185 stopwords\n",
      "---\n",
      "\n",
      "Removed 48 stopwords\n",
      "---\n",
      "\n",
      "Removed 150 stopwords\n",
      "---\n",
      "\n",
      "Removed 385 stopwords\n",
      "---\n",
      "\n",
      "Removed 561 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 64 stopwords\n",
      "---\n",
      "\n",
      "Removed 113 stopwords\n",
      "---\n",
      "\n",
      "Removed 110 stopwords\n",
      "---\n",
      "\n",
      "Removed 285 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "df = wrangle.get_search_csv()\n",
    "df = wrangle.prep_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['language', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      p aligncenter img srchttpsuserimagesgithubuser...\n",
       "1      platform12 github license34 github license56 1...\n",
       "2      dunk httpsrawgithubusercontentcomnaoyashigadun...\n",
       "3      p aligncenter img srcstaticimganalysisgif widt...\n",
       "5      nba nodejs client nbacom api endpoint npm inst...\n",
       "                             ...                        \n",
       "102    basketballrecleague purpose project demonstrat...\n",
       "103    nbastartactiveplayersbot python selenium scrip...\n",
       "106    shoot teamshttpsshootforteamscom app designed ...\n",
       "107    pandasbasketball pandasbasketball small module...\n",
       "108    basketball game demo base opengl grapic render...\n",
       "Name: lemmatized, Length: 98, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Explore various models and feature combinations.\n",
    "Choose **three** models to validate. Choose **one** to test. \n",
    "Artifact: `model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Preparation\n",
    "- Create function to vectorize, scale, and split data\n",
    "- Create word_count feature --> backport to wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Prediction and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.loc[i, 'word_count'] = len([word for word in df.loc[i, 'lemmatized'].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      483.0\n",
       "1      478.0\n",
       "2        5.0\n",
       "3      427.0\n",
       "5      571.0\n",
       "       ...  \n",
       "102     78.0\n",
       "103    178.0\n",
       "106    140.0\n",
       "107    474.0\n",
       "108     51.0\n",
       "Name: word_count, Length: 98, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorize_split(df):\n",
    "\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        \n",
    "    ---\n",
    "    Parameters:\n",
    "        \n",
    "    ---\n",
    "    Returns:\n",
    "        X_train, y_train, X_validate, y_validate, X_test, y_test: data subsets\n",
    "    \"\"\"\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    df['lemmatized'] = tfidf.fit_transform(df.lemmatized).todense()\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit_transform(df[['word_count']])\n",
    "\n",
    "    train_validate, test = train_test_split(df, test_size=.3, random_state=514, stratify=df['language'])\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=514, stratify=train_validate['language'])\n",
    "\n",
    "    # split data into Big X, small y sets \n",
    "    X_train = train.drop(columns=['language'])\n",
    "    y_train = train.language\n",
    "\n",
    "    X_validate = validate.drop(columns=['language'])\n",
    "    y_validate = validate.language\n",
    "\n",
    "    X_test = test.drop(columns=['language'])\n",
    "    y_test = test.language\n",
    "\n",
    "    return train, X_train, y_train, X_validate, y_validate, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_train, y_train, X_validate, y_validate, X_test, y_test = vectorize_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python              0.297872\n",
       "Other               0.255319\n",
       "Jupyter Notebook    0.127660\n",
       "JavaScript          0.127660\n",
       "R                   0.127660\n",
       "HTML                0.063830\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formulate baseline prediction ->base prediction is python\n",
    "train.language.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, X_df, y_df):\n",
    "    \"\"\"\n",
    "    purpose: function executes performs computations to produce evaulation metrics for a given model\n",
    "\n",
    "    inputs: \n",
    "        model: a model that has been previous fit to spec\n",
    "        X_df: a dataframe featuring the X subset of data for evaluation\n",
    "        y_df: a dataframe featuring the model target variable\n",
    "\n",
    "    Returns: a rounded pandas Series that can be adding to an evaulation metric comparison chart\n",
    "    \"\"\"\n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_df)\n",
    "\n",
    "    # Estimate Probability \n",
    "    y_pred_proba = model.predict_proba(X_df)\n",
    "\n",
    "    #create confusion matrix\n",
    "    confusion = confusion_matrix(y_df, y_pred)\n",
    "\n",
    "    #assign results of confusion matrix to variables\n",
    "    true_negative = confusion[0,0]\n",
    "    false_positive = confusion[0,1]\n",
    "    false_negative = confusion[1,0]\n",
    "    true_positive = confusion[1,1]\n",
    "\n",
    "    #accuracy\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "\n",
    "    #true positive rate / recall\n",
    "    recall = true_positive / (true_positive +false_negative)\n",
    "\n",
    "    #false positive rate\n",
    "    false_positive_rate = false_positive / (true_negative + false_positive)\n",
    "\n",
    "    #true negative rate\n",
    "    true_negative_rate = true_negative / (true_negative + false_positive)\n",
    "\n",
    "    #false negative rate\n",
    "    false_negative_rate = false_negative / (false_negative + true_positive)\n",
    "\n",
    "    #precision\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "    #f1-score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    #support\n",
    "    support_positive = true_positive + false_negative\n",
    "    support_negative = false_positive + true_negative\n",
    "\n",
    "    metrics = pd.Series([accuracy, true_positive, false_positive, true_negative, false_negative,\\\n",
    "                        recall, false_positive_rate, true_negative_rate, false_negative_rate, \\\n",
    "                        precision, f1_score, support_positive, support_negative])\n",
    "                        \n",
    "    return metrics.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_chart():\n",
    "    \"\"\"\n",
    "    purpose: to create a dataframe with an index reflecting compuation metrics for future models\n",
    "\n",
    "    returns: a pandas dataframe with appropriately set index\n",
    "    \"\"\"\n",
    "    statistics = ['Accuracy/Score',\n",
    "    'True Positives' , 'False Positives', 'True Negatives', 'False Negatives', \\\n",
    "    'TPR/Recall', 'False Positive Rate', 'True Negative Rate', 'False Negative Rate', \\\n",
    "    'Precision', 'F1-Score', 'Support Positive', 'Support Negative']\n",
    "\n",
    "\n",
    "    return pd.DataFrame({}, index=statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy for \"language\" prediction:  29.8%\n"
     ]
    }
   ],
   "source": [
    "# formulate baseline accuracy\n",
    "baseline_accuracy = (y_train == 'Python').mean()\n",
    "\n",
    "print(f'Baseline Accuracy for \\\"language\\\" prediction: {(baseline_accuracy * 100): .3}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_description_chart(y):\n",
    "\n",
    "    # formulate baseline accuracy\n",
    "    baseline_accuracy = (y == 'Python').mean()\n",
    "\n",
    "    descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "                                'Accuracy(Score)': baseline_accuracy,\n",
    "                                'Type': 'Basic Baseline',\n",
    "                                'Features Used': 'Baseline Prediction',\n",
    "                                'Parameters': 'n/a'\n",
    "                                }, index=[0])\n",
    "    \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions = pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)            Type        Features Used Parameters\n",
       "0  Baseline         0.297872  Basic Baseline  Baseline Prediction        n/a\n",
       "1  Baseline         0.297872  Basic Baseline  Baseline Prediction        n/a"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([model_descriptions, pd.DataFrame({'Model': 'Baseline', \\\n",
    "    'Accuracy(Score)': baseline_accuracy,\n",
    "    'Type': 'Basic Baseline',\n",
    "    'Features Used': 'Baseline Prediction',\n",
    "    'Parameters': 'n/a'\n",
    "    }, index=[0]) ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_chart = model.create_comp_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_set = ['word_count', 'lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [train, X_train, y_train, X_validate, y_validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dtc(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product(np.arange(20,25,2)))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'DTC_'+f'{idx}'\n",
    "        dtc = DecisionTreeClassifier(max_depth=item[0],\\\n",
    "                                            random_state=514)\n",
    "        \n",
    "        dtc.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(dtc, X_train[features], y_train).values\n",
    "\n",
    "        score = dtc.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Decision Tree Classifier',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}'},\n",
    "                                    index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart =  model_dtc(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.957400</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.957400</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.957400</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy(Score)                      Type  \\\n",
       "0  Baseline         0.297872            Basic Baseline   \n",
       "1     DTC_0         0.957400  Decision Tree Classifier   \n",
       "2     DTC_1         0.957400  Decision Tree Classifier   \n",
       "3     DTC_2         0.957400  Decision Tree Classifier   \n",
       "\n",
       "                  Features Used Parameters  \n",
       "0           Baseline Prediction        n/a  \n",
       "1  ['word_count', 'lemmatized']  Depth: 20  \n",
       "2  ['word_count', 'lemmatized']  Depth: 22  \n",
       "3  ['word_count', 'lemmatized']  Depth: 24  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    selectors = list(product([20,25], [3,2,1]))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'RF_'+f'{idx}'\n",
    "        rf = RandomForestClassifier(max_depth=item[0],\\\n",
    "                                            min_samples_leaf=item[1],\n",
    "                                            random_state=514)\n",
    "        \n",
    "        rf.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(rf, X_train[features], y_train).values\n",
    "\n",
    "        score = rf.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "                                    'Accuracy(Score)': score,\n",
    "                                    'Type': 'Random Forest',\n",
    "                                    'Features Used': f'{feat_set}',\n",
    "                                    'Parameters': f'Depth: {item[0]}, Leaves: {item[1]}'},\n",
    "                                    index=[0])\n",
    "       \n",
    "    model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart = model_rf(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways - Random Forest\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors\n",
    "def model_knn(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    k_range = range(1, 15)\n",
    "    scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train[features], y_train)\n",
    "        scores.append(knn.score(X_train[features], y_train))\n",
    "\n",
    "        model_id = 'Knn_'+f'{k}'\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(knn, X_train[features], y_train).values\n",
    "\n",
    "        score = knn.score(X_train[features], y_train).round(5)\n",
    "\n",
    "        description = pd.DataFrame({'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Knn',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'K-Neighbors: {k}'},\n",
    "            index=[0])\n",
    "\n",
    "        model_descriptions = pd.concat([model_descriptions, description], ignore_index=True)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.scatter(k_range, scores)\n",
    "    plt.xticks([0,5,10,15,20])\n",
    "    plt.show()\n",
    "    np.mean(scores)\n",
    "\n",
    "    \n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_descriptions, comparison_chart = model_knn(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Knn_1</td>\n",
       "      <td>0.95745</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_1</td>\n",
       "      <td>0.95740</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_2</td>\n",
       "      <td>0.95740</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_5</td>\n",
       "      <td>0.95740</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 25, Leaves: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.95740</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Accuracy(Score)                      Type  \\\n",
       "5  Knn_1          0.95745                       Knn   \n",
       "2  DTC_1          0.95740  Decision Tree Classifier   \n",
       "3  DTC_2          0.95740  Decision Tree Classifier   \n",
       "4   RF_5          0.95740             Random Forest   \n",
       "1  DTC_0          0.95740  Decision Tree Classifier   \n",
       "\n",
       "                  Features Used            Parameters  \n",
       "5  ['word_count', 'lemmatized']        K-Neighbors: 1  \n",
       "2  ['word_count', 'lemmatized']             Depth: 22  \n",
       "3  ['word_count', 'lemmatized']             Depth: 24  \n",
       "4  ['word_count', 'lemmatized']  Depth: 25, Leaves: 1  \n",
       "1  ['word_count', 'lemmatized']             Depth: 20  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.sort_values(by='Accuracy(Score)', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lr(feat_set,\\\n",
    "        model_descriptions,\n",
    "        comparison_chart,\n",
    "        subsets, ):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "\n",
    "    features = []\n",
    "    for feature in feat_set:\n",
    "        features += [col for col in train.columns if feature in col]\n",
    "\n",
    "    cees = [.1,.5,1]\n",
    "    solver = ['newton-cg', 'lbfgs']\n",
    "    weights = [None, 'balanced']\n",
    "\n",
    "    selectors = list(product(cees, solver, weights))\n",
    "\n",
    "    for idx, item in enumerate(selectors):\n",
    "        model_id = 'LR_'+f'{idx}'\n",
    "        lr = LogisticRegression(C=item[0],\\\n",
    "                                solver=item[1],\n",
    "                                class_weight=item[2],\n",
    "                                max_iter=400,\n",
    "                                random_state=514)\n",
    "        \n",
    "        lr.fit(X_train[features], y_train)\n",
    "\n",
    "        comparison_chart[model_id] = model.compute_metrics(lr, X_train[features], y_train).values\n",
    "\n",
    "        score = lr.score(X_train[features], y_train).round(4)\n",
    "\n",
    "        model_descriptions.loc[idx+1] = {'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': 'Logistic Regression',\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': f'C: {item[0]}, Solver: {item[1]}, Class Weight: {item[2]}'\n",
    "        }\n",
    "\n",
    "    return model_descriptions, comparison_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/sinao/codeup-data-science/nlp_project/model.py'>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions, comparison_chart = model_lr(feat_set, model_descriptions, comparison_chart, subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description and Comparison Charts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Basic Baseline         0.297872\n",
       "Knn                    0.386527\n",
       "Logistic Regression    0.329800\n",
       "Name: Accuracy(Score), dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions.groupby('Type')['Accuracy(Score)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR_8</td>\n",
       "      <td>0.4043</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_0</td>\n",
       "      <td>0.4043</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_2</td>\n",
       "      <td>0.4043</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR_4</td>\n",
       "      <td>0.4043</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.5, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR_6</td>\n",
       "      <td>0.4043</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.5, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy(Score)                 Type                 Features Used  \\\n",
       "9  LR_8           0.4043  Logistic Regression  ['word_count', 'lemmatized']   \n",
       "1  LR_0           0.4043  Logistic Regression  ['word_count', 'lemmatized']   \n",
       "3  LR_2           0.4043  Logistic Regression  ['word_count', 'lemmatized']   \n",
       "5  LR_4           0.4043  Logistic Regression  ['word_count', 'lemmatized']   \n",
       "7  LR_6           0.4043  Logistic Regression  ['word_count', 'lemmatized']   \n",
       "\n",
       "                                      Parameters  \n",
       "9    C: 1, Solver: newton-cg, Class Weight: None  \n",
       "1  C: 0.1, Solver: newton-cg, Class Weight: None  \n",
       "3      C: 0.1, Solver: lbfgs, Class Weight: None  \n",
       "5  C: 0.5, Solver: newton-cg, Class Weight: None  \n",
       "7      C: 0.5, Solver: lbfgs, Class Weight: None  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model descriptions\n",
    "model_descriptions.sort_values('Accuracy(Score)', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_10</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_11</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_7</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_5</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_3</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_1</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_9</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_8</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_7</th>\n",
       "      <td>0.7143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_4</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_2</th>\n",
       "      <td>0.7778</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_6</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_5</th>\n",
       "      <td>0.8571</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_3</th>\n",
       "      <td>0.8750</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "LR_9            0.5000             1.0              1.0             1.0   \n",
       "Knn_10          0.5000             0.0              0.0             1.0   \n",
       "LR_11           0.5000             1.0              1.0             1.0   \n",
       "LR_7            0.5000             1.0              1.0             1.0   \n",
       "LR_5            0.5000             1.0              1.0             1.0   \n",
       "LR_3            0.5000             1.0              1.0             1.0   \n",
       "LR_1            0.5000             1.0              1.0             1.0   \n",
       "Knn_9           0.6000             2.0              1.0             1.0   \n",
       "Knn_8           0.6667             3.0              1.0             1.0   \n",
       "Knn_7           0.7143             4.0              1.0             1.0   \n",
       "Knn_4           0.7500             5.0              1.0             1.0   \n",
       "Knn_2           0.7778             4.0              0.0             3.0   \n",
       "Knn_6           0.8333             4.0              1.0             1.0   \n",
       "Knn_5           0.8571             4.0              1.0             2.0   \n",
       "Knn_3           0.8750             5.0              0.0             2.0   \n",
       "DTC_0           1.0000             6.0              0.0             3.0   \n",
       "Knn_1           1.0000             6.0              0.0             3.0   \n",
       "RF_5            1.0000             6.0              0.0             3.0   \n",
       "RF_2            1.0000             6.0              0.0             3.0   \n",
       "DTC_2           1.0000             6.0              0.0             3.0   \n",
       "DTC_1           1.0000             6.0              0.0             3.0   \n",
       "LR_0            1.0000             1.0              0.0             0.0   \n",
       "Knn_13             NaN             0.0              0.0             0.0   \n",
       "Knn_14             NaN             0.0              0.0             0.0   \n",
       "Knn_12             NaN             0.0              0.0             0.0   \n",
       "\n",
       "        False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "LR_9                1.0      0.5000               0.5000              0.5000   \n",
       "Knn_10              1.0      0.0000               0.0000              1.0000   \n",
       "LR_11               1.0      0.5000               0.5000              0.5000   \n",
       "LR_7                1.0      0.5000               0.5000              0.5000   \n",
       "LR_5                1.0      0.5000               0.5000              0.5000   \n",
       "LR_3                1.0      0.5000               0.5000              0.5000   \n",
       "LR_1                1.0      0.5000               0.5000              0.5000   \n",
       "Knn_9               1.0      0.6667               0.5000              0.5000   \n",
       "Knn_8               1.0      0.7500               0.5000              0.5000   \n",
       "Knn_7               1.0      0.8000               0.5000              0.5000   \n",
       "Knn_4               1.0      0.8333               0.5000              0.5000   \n",
       "Knn_2               2.0      0.6667               0.0000              1.0000   \n",
       "Knn_6               0.0      1.0000               0.5000              0.5000   \n",
       "Knn_5               0.0      1.0000               0.3333              0.6667   \n",
       "Knn_3               1.0      0.8333               0.0000              1.0000   \n",
       "DTC_0               0.0      1.0000               0.0000              1.0000   \n",
       "Knn_1               0.0      1.0000               0.0000              1.0000   \n",
       "RF_5                0.0      1.0000               0.0000              1.0000   \n",
       "RF_2                0.0      1.0000               0.0000              1.0000   \n",
       "DTC_2               0.0      1.0000               0.0000              1.0000   \n",
       "DTC_1               0.0      1.0000               0.0000              1.0000   \n",
       "LR_0                0.0      1.0000               0.0000              0.0000   \n",
       "Knn_13              0.0      0.0000               0.0000              0.0000   \n",
       "Knn_14              0.0      0.0000               0.0000              0.0000   \n",
       "Knn_12              0.0      0.0000               0.0000              0.0000   \n",
       "\n",
       "        False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "LR_9                 0.5000     0.5000    0.5000               2.0   \n",
       "Knn_10               1.0000     0.0000    0.0000               1.0   \n",
       "LR_11                0.5000     0.5000    0.5000               2.0   \n",
       "LR_7                 0.5000     0.5000    0.5000               2.0   \n",
       "LR_5                 0.5000     0.5000    0.5000               2.0   \n",
       "LR_3                 0.5000     0.5000    0.5000               2.0   \n",
       "LR_1                 0.5000     0.5000    0.5000               2.0   \n",
       "Knn_9                0.3333     0.6667    0.6667               3.0   \n",
       "Knn_8                0.2500     0.7500    0.7500               4.0   \n",
       "Knn_7                0.2000     0.8000    0.8000               5.0   \n",
       "Knn_4                0.1667     0.8333    0.8333               6.0   \n",
       "Knn_2                0.3333     1.0000    0.8000               6.0   \n",
       "Knn_6                0.0000     0.8000    0.8889               4.0   \n",
       "Knn_5                0.0000     0.8000    0.8889               4.0   \n",
       "Knn_3                0.1667     1.0000    0.9091               6.0   \n",
       "DTC_0                0.0000     1.0000    1.0000               6.0   \n",
       "Knn_1                0.0000     1.0000    1.0000               6.0   \n",
       "RF_5                 0.0000     1.0000    1.0000               6.0   \n",
       "RF_2                 0.0000     1.0000    1.0000               6.0   \n",
       "DTC_2                0.0000     1.0000    1.0000               6.0   \n",
       "DTC_1                0.0000     1.0000    1.0000               6.0   \n",
       "LR_0                 0.0000     1.0000    1.0000               1.0   \n",
       "Knn_13               0.0000     0.0000    0.0000               0.0   \n",
       "Knn_14               0.0000     0.0000    0.0000               0.0   \n",
       "Knn_12               0.0000     0.0000    0.0000               0.0   \n",
       "\n",
       "        Support Negative  \n",
       "LR_9                 2.0  \n",
       "Knn_10               1.0  \n",
       "LR_11                2.0  \n",
       "LR_7                 2.0  \n",
       "LR_5                 2.0  \n",
       "LR_3                 2.0  \n",
       "LR_1                 2.0  \n",
       "Knn_9                2.0  \n",
       "Knn_8                2.0  \n",
       "Knn_7                2.0  \n",
       "Knn_4                2.0  \n",
       "Knn_2                3.0  \n",
       "Knn_6                2.0  \n",
       "Knn_5                3.0  \n",
       "Knn_3                2.0  \n",
       "DTC_0                3.0  \n",
       "Knn_1                3.0  \n",
       "RF_5                 3.0  \n",
       "RF_2                 3.0  \n",
       "DTC_2                3.0  \n",
       "DTC_1                3.0  \n",
       "LR_0                 0.0  \n",
       "Knn_13               0.0  \n",
       "Knn_14               0.0  \n",
       "Knn_12               0.0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_chart.T.sort_values(by='True Negatives', ascending=False).head(25).sort_values(by=['Accuracy/Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_2</th>\n",
       "      <td>0.7778</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_3</th>\n",
       "      <td>0.8750</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_10</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_8</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_6</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_8</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_7</th>\n",
       "      <td>0.7143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_4</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_0</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_1</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_6</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_4</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_5</th>\n",
       "      <td>0.8571</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_9</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_3</th>\n",
       "      <td>0.8000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_3</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "DTC_0          1.0000             6.0              0.0             3.0   \n",
       "Knn_2          0.7778             4.0              0.0             3.0   \n",
       "DTC_2          1.0000             6.0              0.0             3.0   \n",
       "RF_2           1.0000             6.0              0.0             3.0   \n",
       "RF_5           1.0000             6.0              0.0             3.0   \n",
       "LR_4           1.0000             1.0              0.0             0.0   \n",
       "LR_2           1.0000             1.0              0.0             0.0   \n",
       "Knn_3          0.8750             5.0              0.0             2.0   \n",
       "LR_10          1.0000             1.0              0.0             0.0   \n",
       "LR_8           1.0000             1.0              0.0             0.0   \n",
       "LR_6           1.0000             1.0              0.0             0.0   \n",
       "LR_0           1.0000             1.0              0.0             0.0   \n",
       "Knn_1          1.0000             6.0              0.0             3.0   \n",
       "DTC_1          1.0000             6.0              0.0             3.0   \n",
       "Knn_8          0.6667             3.0              1.0             1.0   \n",
       "Knn_7          0.7143             4.0              1.0             1.0   \n",
       "Knn_4          0.7500             5.0              1.0             1.0   \n",
       "RF_0           0.8000             4.0              1.0             0.0   \n",
       "RF_1           0.8333             5.0              1.0             0.0   \n",
       "Knn_6          0.8333             4.0              1.0             1.0   \n",
       "RF_4           0.8333             5.0              1.0             0.0   \n",
       "Knn_5          0.8571             4.0              1.0             2.0   \n",
       "Knn_9          0.6000             2.0              1.0             1.0   \n",
       "RF_3           0.8000             4.0              1.0             0.0   \n",
       "LR_3           0.5000             1.0              1.0             1.0   \n",
       "\n",
       "       False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "DTC_0              0.0      1.0000               0.0000              1.0000   \n",
       "Knn_2              2.0      0.6667               0.0000              1.0000   \n",
       "DTC_2              0.0      1.0000               0.0000              1.0000   \n",
       "RF_2               0.0      1.0000               0.0000              1.0000   \n",
       "RF_5               0.0      1.0000               0.0000              1.0000   \n",
       "LR_4               0.0      1.0000               0.0000              0.0000   \n",
       "LR_2               0.0      1.0000               0.0000              0.0000   \n",
       "Knn_3              1.0      0.8333               0.0000              1.0000   \n",
       "LR_10              0.0      1.0000               0.0000              0.0000   \n",
       "LR_8               0.0      1.0000               0.0000              0.0000   \n",
       "LR_6               0.0      1.0000               0.0000              0.0000   \n",
       "LR_0               0.0      1.0000               0.0000              0.0000   \n",
       "Knn_1              0.0      1.0000               0.0000              1.0000   \n",
       "DTC_1              0.0      1.0000               0.0000              1.0000   \n",
       "Knn_8              1.0      0.7500               0.5000              0.5000   \n",
       "Knn_7              1.0      0.8000               0.5000              0.5000   \n",
       "Knn_4              1.0      0.8333               0.5000              0.5000   \n",
       "RF_0               0.0      1.0000               1.0000              0.0000   \n",
       "RF_1               0.0      1.0000               1.0000              0.0000   \n",
       "Knn_6              0.0      1.0000               0.5000              0.5000   \n",
       "RF_4               0.0      1.0000               1.0000              0.0000   \n",
       "Knn_5              0.0      1.0000               0.3333              0.6667   \n",
       "Knn_9              1.0      0.6667               0.5000              0.5000   \n",
       "RF_3               0.0      1.0000               1.0000              0.0000   \n",
       "LR_3               1.0      0.5000               0.5000              0.5000   \n",
       "\n",
       "       False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "DTC_0               0.0000     1.0000    1.0000               6.0   \n",
       "Knn_2               0.3333     1.0000    0.8000               6.0   \n",
       "DTC_2               0.0000     1.0000    1.0000               6.0   \n",
       "RF_2                0.0000     1.0000    1.0000               6.0   \n",
       "RF_5                0.0000     1.0000    1.0000               6.0   \n",
       "LR_4                0.0000     1.0000    1.0000               1.0   \n",
       "LR_2                0.0000     1.0000    1.0000               1.0   \n",
       "Knn_3               0.1667     1.0000    0.9091               6.0   \n",
       "LR_10               0.0000     1.0000    1.0000               1.0   \n",
       "LR_8                0.0000     1.0000    1.0000               1.0   \n",
       "LR_6                0.0000     1.0000    1.0000               1.0   \n",
       "LR_0                0.0000     1.0000    1.0000               1.0   \n",
       "Knn_1               0.0000     1.0000    1.0000               6.0   \n",
       "DTC_1               0.0000     1.0000    1.0000               6.0   \n",
       "Knn_8               0.2500     0.7500    0.7500               4.0   \n",
       "Knn_7               0.2000     0.8000    0.8000               5.0   \n",
       "Knn_4               0.1667     0.8333    0.8333               6.0   \n",
       "RF_0                0.0000     0.8000    0.8889               4.0   \n",
       "RF_1                0.0000     0.8333    0.9091               5.0   \n",
       "Knn_6               0.0000     0.8000    0.8889               4.0   \n",
       "RF_4                0.0000     0.8333    0.9091               5.0   \n",
       "Knn_5               0.0000     0.8000    0.8889               4.0   \n",
       "Knn_9               0.3333     0.6667    0.6667               3.0   \n",
       "RF_3                0.0000     0.8000    0.8889               4.0   \n",
       "LR_3                0.5000     0.5000    0.5000               2.0   \n",
       "\n",
       "       Support Negative  \n",
       "DTC_0               3.0  \n",
       "Knn_2               3.0  \n",
       "DTC_2               3.0  \n",
       "RF_2                3.0  \n",
       "RF_5                3.0  \n",
       "LR_4                0.0  \n",
       "LR_2                0.0  \n",
       "Knn_3               2.0  \n",
       "LR_10               0.0  \n",
       "LR_8                0.0  \n",
       "LR_6                0.0  \n",
       "LR_0                0.0  \n",
       "Knn_1               3.0  \n",
       "DTC_1               3.0  \n",
       "Knn_8               2.0  \n",
       "Knn_7               2.0  \n",
       "Knn_4               2.0  \n",
       "RF_0                1.0  \n",
       "RF_1                1.0  \n",
       "Knn_6               2.0  \n",
       "RF_4                1.0  \n",
       "Knn_5               3.0  \n",
       "Knn_9               2.0  \n",
       "RF_3                1.0  \n",
       "LR_3                2.0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_chart.T.sort_values(by='Accuracy/Score', ascending=False).head(25).sort_values(by=['False Positives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>Basic Baseline</td>\n",
       "      <td>Baseline Prediction</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_0</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR_1</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: newton-cg, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR_2</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR_3</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.1, Solver: lbfgs, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR_4</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.5, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR_5</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.5, Solver: newton-cg, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR_6</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.5, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR_7</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 0.5, Solver: lbfgs, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR_8</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 1, Solver: newton-cg, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LR_9</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 1, Solver: newton-cg, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LR_10</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 1, Solver: lbfgs, Class Weight: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR_11</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>C: 1, Solver: lbfgs, Class Weight: balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Knn_9</td>\n",
       "      <td>0.361700</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Knn_10</td>\n",
       "      <td>0.361700</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Knn_11</td>\n",
       "      <td>0.404260</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Knn_12</td>\n",
       "      <td>0.404260</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Knn_13</td>\n",
       "      <td>0.404260</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Knn_14</td>\n",
       "      <td>0.382980</td>\n",
       "      <td>Knn</td>\n",
       "      <td>['word_count', 'lemmatized']</td>\n",
       "      <td>K-Neighbors: 14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy(Score)                 Type  \\\n",
       "0   Baseline         0.297872       Basic Baseline   \n",
       "1       LR_0         0.404300  Logistic Regression   \n",
       "2       LR_1         0.255300  Logistic Regression   \n",
       "3       LR_2         0.404300  Logistic Regression   \n",
       "4       LR_3         0.255300  Logistic Regression   \n",
       "5       LR_4         0.404300  Logistic Regression   \n",
       "6       LR_5         0.255300  Logistic Regression   \n",
       "7       LR_6         0.404300  Logistic Regression   \n",
       "8       LR_7         0.255300  Logistic Regression   \n",
       "9       LR_8         0.404300  Logistic Regression   \n",
       "10      LR_9         0.255300  Logistic Regression   \n",
       "11     LR_10         0.404300  Logistic Regression   \n",
       "12     LR_11         0.255300  Logistic Regression   \n",
       "13     Knn_9         0.361700                  Knn   \n",
       "14    Knn_10         0.361700                  Knn   \n",
       "15    Knn_11         0.404260                  Knn   \n",
       "16    Knn_12         0.404260                  Knn   \n",
       "17    Knn_13         0.404260                  Knn   \n",
       "18    Knn_14         0.382980                  Knn   \n",
       "\n",
       "                   Features Used  \\\n",
       "0            Baseline Prediction   \n",
       "1   ['word_count', 'lemmatized']   \n",
       "2   ['word_count', 'lemmatized']   \n",
       "3   ['word_count', 'lemmatized']   \n",
       "4   ['word_count', 'lemmatized']   \n",
       "5   ['word_count', 'lemmatized']   \n",
       "6   ['word_count', 'lemmatized']   \n",
       "7   ['word_count', 'lemmatized']   \n",
       "8   ['word_count', 'lemmatized']   \n",
       "9   ['word_count', 'lemmatized']   \n",
       "10  ['word_count', 'lemmatized']   \n",
       "11  ['word_count', 'lemmatized']   \n",
       "12  ['word_count', 'lemmatized']   \n",
       "13  ['word_count', 'lemmatized']   \n",
       "14  ['word_count', 'lemmatized']   \n",
       "15  ['word_count', 'lemmatized']   \n",
       "16  ['word_count', 'lemmatized']   \n",
       "17  ['word_count', 'lemmatized']   \n",
       "18  ['word_count', 'lemmatized']   \n",
       "\n",
       "                                           Parameters  \n",
       "0                                                 n/a  \n",
       "1       C: 0.1, Solver: newton-cg, Class Weight: None  \n",
       "2   C: 0.1, Solver: newton-cg, Class Weight: balanced  \n",
       "3           C: 0.1, Solver: lbfgs, Class Weight: None  \n",
       "4       C: 0.1, Solver: lbfgs, Class Weight: balanced  \n",
       "5       C: 0.5, Solver: newton-cg, Class Weight: None  \n",
       "6   C: 0.5, Solver: newton-cg, Class Weight: balanced  \n",
       "7           C: 0.5, Solver: lbfgs, Class Weight: None  \n",
       "8       C: 0.5, Solver: lbfgs, Class Weight: balanced  \n",
       "9         C: 1, Solver: newton-cg, Class Weight: None  \n",
       "10    C: 1, Solver: newton-cg, Class Weight: balanced  \n",
       "11            C: 1, Solver: lbfgs, Class Weight: None  \n",
       "12        C: 1, Solver: lbfgs, Class Weight: balanced  \n",
       "13                                     K-Neighbors: 9  \n",
       "14                                    K-Neighbors: 10  \n",
       "15                                    K-Neighbors: 11  \n",
       "16                                    K-Neighbors: 12  \n",
       "17                                    K-Neighbors: 13  \n",
       "18                                    K-Neighbors: 14  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation Takeaways\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation Takeaways\n",
    "- Goal:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20 = model_descriptions.sort_values('Accuracy(Score)', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selectors(parameters):\n",
    "    removal_list = ['Depth: ','K-Neighbors: ','Leaves: ','C: ',' Solver: ', ' Class Weight: ']\n",
    "\n",
    "    for word in removal_list:\n",
    "        parameters = parameters.replace(word, \"\")\n",
    "\n",
    "    return parameters.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_on_validation(descriptions, subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_validate= subsets[3]\n",
    "    y_validate = subsets[4]\n",
    "\n",
    "    \n",
    "    validate_metrics = create_comp_chart()\n",
    "    val_descriptions = create_description_chart(y_validate)\n",
    "    \n",
    "    print(descriptions.index)\n",
    "    for idx in descriptions.index:\n",
    "        i = 1\n",
    "        model_id = descriptions.loc[idx]['Model']\n",
    "        feat_set = descriptions.loc[idx]['Features Used'].strip('\\[]\\'').split('\\', \\'')\n",
    "        selectors = get_selectors(descriptions.loc[idx]['Parameters'])\n",
    "\n",
    "        features = []\n",
    "\n",
    "        for feature in feat_set:\n",
    "            features += [col for col in train.columns if feature in col]\n",
    "\n",
    "        if model_id.startswith('DTC'):\n",
    "            val_model = DecisionTreeClassifier(max_depth=int(selectors[0]),\\\n",
    "                                                random_state=514)\n",
    "        elif model_id.startswith('RF'):\n",
    "            val_model = RandomForestClassifier(max_depth=int(selectors[0]),\\\n",
    "                                            min_samples_leaf=int(selectors[1]),\n",
    "                                            random_state=514)\n",
    "        elif model_id.startswith('Knn'):\n",
    "            val_model = KNeighborsClassifier(n_neighbors = int(selectors[0]))\n",
    "        elif model_id.startswith('LR'):\n",
    "            if selectors[2]== 'None':\n",
    "                selectors[2] = None\n",
    "            val_model = LogisticRegression(C=float(selectors[0]),\\\n",
    "                                            solver=selectors[1],\n",
    "                                            class_weight=selectors[2],\n",
    "                                            max_iter=200,\n",
    "                                            random_state=514)  \n",
    "\n",
    "        #print(X_train[features], y_train)  \n",
    "        try:                       \n",
    "            val_model.fit(X_train[features], y_train)\n",
    "        except:\n",
    "            problem = X_train[features]\n",
    "            problem_y = y_train\n",
    "            # return problem, problem_y\n",
    "        \n",
    "        validate_metrics[model_id] = model.compute_metrics(val_model, X_validate[features], y_validate).values\n",
    "\n",
    "        score = val_model.score(X_validate[features], y_validate).round(4)\n",
    "\n",
    "        val_descriptions.loc[idx+1] = {'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': descriptions.loc[idx]['Type'],\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': descriptions.loc[idx]['Parameters']\n",
    "        }\n",
    "        \n",
    "    val_descriptions.insert(loc=2, column='Sensitivity', value=0)\n",
    "\n",
    "    for idx in val_descriptions.index:\n",
    "        model_id = val_descriptions.loc[idx]['Model']\n",
    "        if model_id != 'Baseline':\n",
    "            val_descriptions.loc[idx, 'Sensitivity'] = validate_metrics.T.loc[model_id]['True Negative Rate']        \n",
    "\n",
    "\n",
    "    return val_descriptions, validate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [language, lemmatized, word_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.word_count == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/sinao/codeup-data-science/nlp_project/model.py'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([9, 1, 3, 5, 7, 11, 17, 16, 15, 18, 13, 14, 0, 10, 8, 12, 6, 4, 2], dtype='int64')\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "    word_count  lemmatized\n",
      "28         0.0       162.0\n",
      "2          0.0         5.0\n",
      "61         0.0        63.0\n",
      "78         0.0        69.0\n",
      "26         0.0       851.0\n",
      "70         0.0       126.0\n",
      "73         0.0         6.0\n",
      "5          0.0       571.0\n",
      "31         0.0       247.0\n",
      "29         0.0        48.0\n",
      "14         0.0       663.0\n",
      "45         0.0       250.0\n",
      "6          0.0        91.0\n",
      "46         0.0       224.0\n",
      "53         0.0       498.0\n",
      "43         0.0       621.0\n",
      "47         0.0        65.0\n",
      "21         0.0       321.0\n",
      "65         0.0       189.0\n",
      "49         0.0         1.0\n",
      "42         0.0       682.0\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [28, 2, 61, 78, 26, 70, 73, 5, 31, 29, 14, 45, 6, 46, 53, 43, 47, 21, 65, 49, 42]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n",
      "/Users/sinao/codeup-data-science/nlp_project/model.py:260: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  #accuracy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sinao/codeup-data-science/nlp_project/model.ipynb Cell 57\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m val_descriptions, validate_metrics \u001b[39m=\u001b[39m score_on_validation(top_20, subsets)\n",
      "\u001b[1;32m/Users/sinao/codeup-data-science/nlp_project/model.ipynb Cell 57\u001b[0m in \u001b[0;36mscore_on_validation\u001b[0;34m(descriptions, subsets)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39m# return problem, problem_y\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mprint\u001b[39m(X_validate[features])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m validate_metrics[model_id] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mcompute_metrics(val_model, X_validate[features], y_validate)\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m score \u001b[39m=\u001b[39m val_model\u001b[39m.\u001b[39mscore(X_validate[features], y_validate)\u001b[39m.\u001b[39mround(\u001b[39m4\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m val_descriptions\u001b[39m.\u001b[39mloc[idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m'\u001b[39m: model_id,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAccuracy(Score)\u001b[39m\u001b[39m'\u001b[39m: score,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mType\u001b[39m\u001b[39m'\u001b[39m: descriptions\u001b[39m.\u001b[39mloc[idx][\u001b[39m'\u001b[39m\u001b[39mType\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mFeatures Used\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfeat_set\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mParameters\u001b[39m\u001b[39m'\u001b[39m: descriptions\u001b[39m.\u001b[39mloc[idx][\u001b[39m'\u001b[39m\u001b[39mParameters\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sinao/codeup-data-science/nlp_project/model.ipynb#Y100sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m }\n",
      "File \u001b[0;32m~/codeup-data-science/nlp_project/model.py:243\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(model, X_df, y_df)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mpurpose: function executes performs computations to produce evaulation metrics for a given model\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mReturns: a rounded pandas Series that can be adding to an evaulation metric comparison chart\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39m# Make Predictions\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_df)\n\u001b[1;32m    245\u001b[0m \u001b[39m# Estimate Probability \u001b[39;00m\n\u001b[1;32m    246\u001b[0m y_pred_proba \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(X_df)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:214\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    201\u001b[0m     \u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m        Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     neigh_dist, neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X)\n\u001b[1;32m    215\u001b[0m     classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m    216\u001b[0m     _y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py:717\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    715\u001b[0m         X \u001b[39m=\u001b[39m _check_precomputed(X)\n\u001b[1;32m    716\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    718\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     query_is_train \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    567\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:665\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    662\u001b[0m                     has_pd_integer_array \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    664\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 665\u001b[0m         dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes_orig)\n\u001b[1;32m    667\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric:\n\u001b[1;32m    668\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dtype_orig\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    669\u001b[0m         \u001b[39m# if input is object, convert to float.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "val_descriptions, validate_metrics = score_on_validation(top_20, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [72, 36, 10, 80, 0, 39, 69, 90, 103, 17, 100, 35, 12, 50, 23, 58, 97, 107, 11, 87, 84, 74, 48, 94, 57, 18, 62, 1, 101, 85, 102, 88, 41, 60, 7, 38, 15, 3, 89, 51, 71, 81, 83, 95, 37, 20, 68]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(validate_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>TPR/Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTC_0</th>\n",
       "      <td>0.9665</td>\n",
       "      <td>11718.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC_1</th>\n",
       "      <td>0.9665</td>\n",
       "      <td>11718.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_5</th>\n",
       "      <td>0.9679</td>\n",
       "      <td>11737.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_2</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_16</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_0</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_4</th>\n",
       "      <td>0.9683</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_5</th>\n",
       "      <td>0.9671</td>\n",
       "      <td>11740.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_8</th>\n",
       "      <td>0.9672</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn_10</th>\n",
       "      <td>0.9671</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>11742.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy/Score  True Positives  False Positives  True Negatives  \\\n",
       "DTC_0           0.9665         11718.0            384.0            68.0   \n",
       "DTC_1           0.9665         11718.0            384.0            68.0   \n",
       "RF_5            0.9679         11737.0            386.0            66.0   \n",
       "LR_2            0.9683         11742.0            387.0            65.0   \n",
       "LR_16           0.9683         11742.0            387.0            65.0   \n",
       "LR_0            0.9683         11742.0            387.0            65.0   \n",
       "LR_4            0.9683         11742.0            387.0            65.0   \n",
       "Knn_5           0.9671         11740.0            399.0            53.0   \n",
       "Knn_8           0.9672         11742.0            400.0            52.0   \n",
       "Knn_10          0.9671         11742.0            401.0            51.0   \n",
       "\n",
       "        False Negatives  TPR/Recall  False Positive Rate  True Negative Rate  \\\n",
       "DTC_0              24.0      0.9980               0.8496              0.1504   \n",
       "DTC_1              24.0      0.9980               0.8496              0.1504   \n",
       "RF_5                5.0      0.9996               0.8540              0.1460   \n",
       "LR_2                0.0      1.0000               0.8562              0.1438   \n",
       "LR_16               0.0      1.0000               0.8562              0.1438   \n",
       "LR_0                0.0      1.0000               0.8562              0.1438   \n",
       "LR_4                0.0      1.0000               0.8562              0.1438   \n",
       "Knn_5               2.0      0.9998               0.8827              0.1173   \n",
       "Knn_8               0.0      1.0000               0.8850              0.1150   \n",
       "Knn_10              0.0      1.0000               0.8872              0.1128   \n",
       "\n",
       "        False Negative Rate  Precision  F1-Score  Support Positive  \\\n",
       "DTC_0                0.0020     0.9683    0.9829           11742.0   \n",
       "DTC_1                0.0020     0.9683    0.9829           11742.0   \n",
       "RF_5                 0.0004     0.9682    0.9836           11742.0   \n",
       "LR_2                 0.0000     0.9681    0.9838           11742.0   \n",
       "LR_16                0.0000     0.9681    0.9838           11742.0   \n",
       "LR_0                 0.0000     0.9681    0.9838           11742.0   \n",
       "LR_4                 0.0000     0.9681    0.9838           11742.0   \n",
       "Knn_5                0.0002     0.9671    0.9832           11742.0   \n",
       "Knn_8                0.0000     0.9671    0.9833           11742.0   \n",
       "Knn_10               0.0000     0.9670    0.9832           11742.0   \n",
       "\n",
       "        Support Negative  \n",
       "DTC_0              452.0  \n",
       "DTC_1              452.0  \n",
       "RF_5               452.0  \n",
       "LR_2               452.0  \n",
       "LR_16              452.0  \n",
       "LR_0               452.0  \n",
       "LR_4               452.0  \n",
       "Knn_5              452.0  \n",
       "Knn_8              452.0  \n",
       "Knn_10             452.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validate_metrics.T.sort_values(by='True Negative Rate', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "> Initial: All three chosen sets perform baseline. Need to re-adjust and re-attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = val_descriptions[val_descriptions.Model == 'DTC_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(Score)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_0</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>['marital_status', 'occupation', 'race', 'educ...</td>\n",
       "      <td>Depth: 20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Accuracy(Score)                      Type  \\\n",
       "1  DTC_0           0.9665  Decision Tree Classifier   \n",
       "\n",
       "                                       Features Used Parameters  \n",
       "1  ['marital_status', 'occupation', 'race', 'educ...  Depth: 20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC_0\n"
     ]
    }
   ],
   "source": [
    "for idx in top_model.index:\n",
    "    print(top_model.loc[idx]['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_on_test(descriptions, subsets):\n",
    "    \n",
    "    train=subsets[0]\n",
    "    X_train=subsets[1]\n",
    "    y_train=subsets[2]\n",
    "    X_test = subsets[5]\n",
    "    y_test = subsets[6]\n",
    "\n",
    "    test_metrics = create_comp_chart()\n",
    "    test_descriptions = create_description_chart(y_test)\n",
    "        \n",
    "    for idx in descriptions.index:\n",
    "        \n",
    "        model_id = descriptions.loc[idx]['Model']\n",
    "        feat_set = descriptions.loc[idx]['Features Used'].strip('\\[]\\'').split('\\', \\'')\n",
    "        selectors = get_selectors(descriptions.loc[idx]['Parameters'])\n",
    "\n",
    "        features = []\n",
    "\n",
    "        for feature in feat_set:\n",
    "            features += [col for col in train.columns if feature in col]\n",
    "\n",
    "        if model_id.startswith('DTC'):\n",
    "            test_model = DecisionTreeClassifier(max_depth=int(selectors[0]),\\\n",
    "                                                random_state=514)\n",
    "        elif model_id.startswith('RF'):\n",
    "            test_model = RandomForestClassifier(max_depth=int(selectors[0]),\\\n",
    "                                            min_samples_leaf=int(selectors[1]),\n",
    "                                            random_state=514)\n",
    "        elif model_id.startswith('Knn'):\n",
    "            test_model = KNeighborsClassifier(n_neighbors = int(selectors[0]))\n",
    "        elif model_id.startswith('LR'):\n",
    "            test_model = LogisticRegression(C=float(selectors[0]),\\\n",
    "                                            solver=selectors[1],\n",
    "                                            class_weight=selectors[2],\n",
    "                                            max_iter=200,\n",
    "                                            random_state=514)  \n",
    "                                    \n",
    "        test_model.fit(X_train[features], y_train)\n",
    "\n",
    "        test_metrics[model_id] = compute_metrics(test_model, X_test[features], y_test).values\n",
    "\n",
    "        score = test_model.score(X_test[features], y_test).round(4)\n",
    "\n",
    "        test_descriptions.loc[idx+1] = {'Model': model_id,\n",
    "            'Accuracy(Score)': score,\n",
    "            'Type': descriptions.loc[idx]['Type'],\n",
    "            'Features Used': f'{feat_set}',\n",
    "            'Parameters': descriptions.loc[idx]['Parameters']\n",
    "        }\n",
    "\n",
    "    return test_descriptions, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_descriptions, test_metrics = score_on_test(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTC_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positives</th>\n",
       "      <td>9771.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positives</th>\n",
       "      <td>328.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negatives</th>\n",
       "      <td>49.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negatives</th>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR/Recall</th>\n",
       "      <td>0.9986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative Rate</th>\n",
       "      <td>0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.9828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Positive</th>\n",
       "      <td>9785.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Negative</th>\n",
       "      <td>377.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DTC_0\n",
       "Accuracy/Score          0.9663\n",
       "True Positives       9771.0000\n",
       "False Positives       328.0000\n",
       "True Negatives         49.0000\n",
       "False Negatives        14.0000\n",
       "TPR/Recall              0.9986\n",
       "False Positive Rate     0.8700\n",
       "True Negative Rate      0.1300\n",
       "False Negative Rate     0.0014\n",
       "Precision               0.9675\n",
       "F1-Score                0.9828\n",
       "Support Positive     9785.0000\n",
       "Support Negative      377.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_chart():\n",
    "    \"\"\"\n",
    "    purpose: to create a dataframe with an index reflecting compuation metrics for future models\n",
    "\n",
    "    returns: a pandas dataframe with appropriately set index\n",
    "    \"\"\"\n",
    "    statistics = ['Accuracy/Score',\n",
    "    'True Positives' , 'False Positives', 'True Negatives', 'False Negatives', \\\n",
    "    'TPR/Recall', 'False Positive Rate', 'True Negative Rate', 'False Negative Rate', \\\n",
    "    'Precision', 'F1-Score', 'Support Positive', 'Support Negative']\n",
    "\n",
    "\n",
    "    return pd.DataFrame({}, index=statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X, y, feature_groups, subsets):\n",
    "    \n",
    "   #take in features sets and run them through each of the different types\n",
    "   #of models and their variations\n",
    "   train_descriptions = create_description_chart(y)\n",
    "   train_metrics = create_comp_chart()\n",
    "\n",
    "   for features in feature_groups:\n",
    "      \n",
    "      train_descriptions, train_metrics = model_dtc(features, train_descriptions, train_metrics, subsets)\n",
    "      train_descriptions, train_metrics = model_rf(features, train_descriptions, train_metrics, subsets)\n",
    "      #train_descriptions, train_metrics = model_knn(features, train_descriptions, train_metrics, subsets)\n",
    "      train_descriptions, train_metrics = model_lr(features, train_descriptions, train_metrics, subsets)\n",
    "\n",
    "   train_descriptions.insert(loc=2, column='Sensitivity', value=0)\n",
    "\n",
    "   for idx in train_descriptions.index:\n",
    "      model_id = train_descriptions.iloc[idx]['Model']\n",
    "      if model_id != 'Baseline':\n",
    "         train_descriptions.loc[idx, 'Sensitivity'] = train_metrics.T.loc[model_id]['True Negative Rate']\n",
    "         \n",
    "   return train_descriptions, train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_final_report(train, feature_bank):\n",
    "\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = split_X_y(train)\n",
    "\n",
    "    subsets=[train, X_train, y_train, X_validate, y_validate, X_test, y_test]\n",
    "\n",
    "    train_descriptions, train_metrics = train_models(X_train, y_train, feature_bank, subsets)\n",
    "\n",
    "    train_descriptions[train_descriptions.Sensitivity > .20].\\\n",
    "        sort_values('Accuracy(Score)', ascending=False).\\\n",
    "        head(20)\n",
    "\n",
    "    top_4 = train_descriptions[train_descriptions.Sensitivity > .20].\\\n",
    "        sort_values('Accuracy(Score)', ascending=False).\\\n",
    "        head(4)\n",
    "\n",
    "    val_descriptions, validate_metrics = score_on_validation(top_4, subsets)\n",
    "\n",
    "    top_1 = val_descriptions[(val_descriptions.Sensitivity > .20) & (val_descriptions['Accuracy(Score)'] > .66)].\\\n",
    "        sort_values('Sensitivity', ascending=False).\\\n",
    "        head(1)\n",
    "\n",
    "    test_descriptions, test_metrics = score_on_test(top_1, subsets)\n",
    "\n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([12, 8, 10, 14], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy/Score</th>\n",
       "      <td>0.6684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positives</th>\n",
       "      <td>6554.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positives</th>\n",
       "      <td>139.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negatives</th>\n",
       "      <td>238.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negatives</th>\n",
       "      <td>3231.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR/Recall</th>\n",
       "      <td>0.6698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative Rate</th>\n",
       "      <td>0.6313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.3302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.7955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Positive</th>\n",
       "      <td>9785.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Negative</th>\n",
       "      <td>377.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          LR_7\n",
       "Accuracy/Score          0.6684\n",
       "True Positives       6554.0000\n",
       "False Positives       139.0000\n",
       "True Negatives        238.0000\n",
       "False Negatives      3231.0000\n",
       "TPR/Recall              0.6698\n",
       "False Positive Rate     0.3687\n",
       "True Negative Rate      0.6313\n",
       "False Negative Rate     0.3302\n",
       "Precision               0.9792\n",
       "F1-Score                0.7955\n",
       "Support Positive     9785.0000\n",
       "Support Negative      377.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for_final_report(train, [feat_set])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
