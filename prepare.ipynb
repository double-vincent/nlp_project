{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b097c195",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7234b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from bs4 import BeautifulSoup as soupify\n",
    "from os import path\n",
    "from requests import get\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import wrangle\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e5d11",
   "metadata": {},
   "source": [
    "Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "Lowercase everything\n",
    "Normalize unicode characters\n",
    "Replace anything that is not a letter, number, whitespace or a single quote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b44ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = wrangle.get_search_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66f1597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        \n",
    "    ---\n",
    "    Parameters:\n",
    "        \n",
    "    ---\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "\n",
    "    text = unicodedata.normalize('NFKD', text)\\\n",
    "                        .encode('ascii', 'ignore')\\\n",
    "                        .decode('utf-8', 'ignore')\n",
    "    \n",
    "    text = re.sub(r\"[^a-z0-9'\\s]\", '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e58e81",
   "metadata": {},
   "source": [
    "Define a function named tokenize. It should take in a string and tokenize all the words in the string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dca019ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        takes a string and tokenizes all words in t\n",
    "    ---\n",
    "    Parameters:\n",
    "        \n",
    "    ---\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\" \n",
    "    tokenizer = ToktokTokenizer()\n",
    "\n",
    "    text = tokenizer.tokenize(text, return_str=True)\n",
    "\n",
    "    return text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e675b1b3",
   "metadata": {},
   "source": [
    "Define a function named stem. It should accept some text and return the text after applying stemming to all the words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fc51907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "\n",
    "def stem(text):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        to apply stemming to input text\n",
    "    ---\n",
    "    Parameters:\n",
    "        text: the text to be stemmed\n",
    "    ---\n",
    "    Returns:\n",
    "        text: text that has had stemming applied to it\n",
    "    \"\"\"\n",
    "\n",
    "    #create the nltk stemmer object\n",
    "    ps = PorterStemmer()    \n",
    "\n",
    "    stems = [ps.stem(word) for word in text.split()]\n",
    "    text = ' '.join(stems)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca132b42",
   "metadata": {},
   "source": [
    "Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e653fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "def lemmatize(text):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        applies lemmatization to input text \n",
    "    ---\n",
    "    Parameters:\n",
    "        text: the text to be lemmatized\n",
    "    ---\n",
    "    Returns:\n",
    "        text: text that has been lemmatized\n",
    "    \"\"\"\n",
    "    #create lemmatize object\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    lemmas = [wnl.lemmatize(word) for word in text.split()]\n",
    "    text = ' '.join(lemmas)\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee200b",
   "metadata": {},
   "source": [
    "Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "134a61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text, extra_words=None, exclude_words=None):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        to remove stopwords from input text \n",
    "    ---\n",
    "    Parameters:\n",
    "        text: text from which to remove stop words\n",
    "    ---\n",
    "    Returns:\n",
    "        text: text that has had stopwords removed\n",
    "    \"\"\"\n",
    "\n",
    "    stopwords_list = stopwords.words('english')\n",
    "\n",
    "    if extra_words != None:\n",
    "        stopwords_list.extend(extra_words)\n",
    "\n",
    "    if exclude_words != None:\n",
    "        for w in exclude_words:\n",
    "            stopwords_list.remove(w)\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    filtered_words = [w for w in words if w not in stopwords_list]\n",
    "\n",
    "    print()\n",
    "    print('Removed {} stopwords'.format(len(words) - len(filtered_words)))\n",
    "    print('---')\n",
    "\n",
    "    text = ' '.join(filtered_words)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e3d3a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, extra_words=None, exclude_words=None):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        performs basic clean, tokenization, and removal of stopwords on input text\n",
    "    ---\n",
    "    Parameters:\n",
    "        text\n",
    "        extra_words\n",
    "        exclude_words\n",
    "    ---\n",
    "    Returns:\n",
    "        text\n",
    "    \"\"\"\n",
    "\n",
    "    text = basic_clean(text)\n",
    "    \n",
    "    text = tokenize(text)\n",
    "\n",
    "    text = remove_stopwords(text, extra_words, exclude_words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d5186",
   "metadata": {},
   "source": [
    "## Use your data from the acquire to produce a dataframe of the READMEs.\n",
    "\n",
    "* Produce the following columns:\n",
    "\n",
    "        title to hold the title\n",
    "        language to hold the language\n",
    "        readme.txt to hold the original article/post content\n",
    "        clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "        stemmed to hold the stemmed version of the cleaned data.\n",
    "        lemmatized to hold the lemmatized version of the cleaned data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7fae119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle.get_search_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for dropping na's and doing check for  non-english langauge READMEs\n",
    "# df = df.dropna()\n",
    "# def isEnglish(s):\n",
    "#     try:\n",
    "#         s.encode(encoding='utf-8').decode('ascii')\n",
    "#     except UnicodeDecodeError:\n",
    "#         return False\n",
    "#     else:\n",
    "#         return True\n",
    "# df['is_english'] = df.readme_txt.apply(isEnglish)\n",
    "# #columns containing non-english characters\n",
    "# df = df.drop([4, 13, 66, 86])\n",
    "# df[df.is_english == False ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10688ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.classify.textcat import TextCat\n",
    "#loop for guessing language of input text\n",
    "# for i in df.index:\n",
    "\n",
    "#     txtcat = TextCat()\n",
    "#     guess = txtcat.guess_language(df.iloc[i]['readme_txt'])\n",
    "#     print(i + 19, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c1d8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_text(df):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        \n",
    "    ---\n",
    "    Parameters:\n",
    "        \n",
    "    ---\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df.dropna()\n",
    "    df = df.drop([4, 13, 66, 86])\n",
    "\n",
    "    df['clean'] = df.readme_txt.apply(clean)\n",
    "    df['stemmed'] = df.clean.apply(stem)\n",
    "    df['lemmatized'] = df.clean.apply(lemmatize)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce324dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wrangle' from '/Users/sinao/codeup-data-science/nlp_project/wrangle.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(wrangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86ee2769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 201 stopwords\n",
      "---\n",
      "\n",
      "Removed 49 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n",
      "\n",
      "Removed 218 stopwords\n",
      "---\n",
      "\n",
      "Removed 401 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 50 stopwords\n",
      "---\n",
      "\n",
      "Removed 8 stopwords\n",
      "---\n",
      "\n",
      "Removed 158 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 44 stopwords\n",
      "---\n",
      "\n",
      "Removed 110 stopwords\n",
      "---\n",
      "\n",
      "Removed 500 stopwords\n",
      "---\n",
      "\n",
      "Removed 494 stopwords\n",
      "---\n",
      "\n",
      "Removed 31 stopwords\n",
      "---\n",
      "\n",
      "Removed 427 stopwords\n",
      "---\n",
      "\n",
      "Removed 76 stopwords\n",
      "---\n",
      "\n",
      "Removed 1 stopwords\n",
      "---\n",
      "\n",
      "Removed 175 stopwords\n",
      "---\n",
      "\n",
      "Removed 731 stopwords\n",
      "---\n",
      "\n",
      "Removed 68 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 358 stopwords\n",
      "---\n",
      "\n",
      "Removed 52 stopwords\n",
      "---\n",
      "\n",
      "Removed 15 stopwords\n",
      "---\n",
      "\n",
      "Removed 48 stopwords\n",
      "---\n",
      "\n",
      "Removed 100 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 134 stopwords\n",
      "---\n",
      "\n",
      "Removed 320 stopwords\n",
      "---\n",
      "\n",
      "Removed 27 stopwords\n",
      "---\n",
      "\n",
      "Removed 74 stopwords\n",
      "---\n",
      "\n",
      "Removed 88 stopwords\n",
      "---\n",
      "\n",
      "Removed 8 stopwords\n",
      "---\n",
      "\n",
      "Removed 272 stopwords\n",
      "---\n",
      "\n",
      "Removed 123 stopwords\n",
      "---\n",
      "\n",
      "Removed 389 stopwords\n",
      "---\n",
      "\n",
      "Removed 81 stopwords\n",
      "---\n",
      "\n",
      "Removed 187 stopwords\n",
      "---\n",
      "\n",
      "Removed 23 stopwords\n",
      "---\n",
      "\n",
      "Removed 25 stopwords\n",
      "---\n",
      "\n",
      "Removed 114 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 199 stopwords\n",
      "---\n",
      "\n",
      "Removed 95 stopwords\n",
      "---\n",
      "\n",
      "Removed 22 stopwords\n",
      "---\n",
      "\n",
      "Removed 220 stopwords\n",
      "---\n",
      "\n",
      "Removed 56 stopwords\n",
      "---\n",
      "\n",
      "Removed 20 stopwords\n",
      "---\n",
      "\n",
      "Removed 2 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 10 stopwords\n",
      "---\n",
      "\n",
      "Removed 512 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 24 stopwords\n",
      "---\n",
      "\n",
      "Removed 926 stopwords\n",
      "---\n",
      "\n",
      "Removed 42 stopwords\n",
      "---\n",
      "\n",
      "Removed 115 stopwords\n",
      "---\n",
      "\n",
      "Removed 6 stopwords\n",
      "---\n",
      "\n",
      "Removed 30 stopwords\n",
      "---\n",
      "\n",
      "Removed 852 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 115 stopwords\n",
      "---\n",
      "\n",
      "Removed 61 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 0 stopwords\n",
      "---\n",
      "\n",
      "Removed 53 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 157 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 1030 stopwords\n",
      "---\n",
      "\n",
      "Removed 21 stopwords\n",
      "---\n",
      "\n",
      "Removed 116 stopwords\n",
      "---\n",
      "\n",
      "Removed 136 stopwords\n",
      "---\n",
      "\n",
      "Removed 16 stopwords\n",
      "---\n",
      "\n",
      "Removed 14 stopwords\n",
      "---\n",
      "\n",
      "Removed 61 stopwords\n",
      "---\n",
      "\n",
      "Removed 72 stopwords\n",
      "---\n",
      "\n",
      "Removed 52 stopwords\n",
      "---\n",
      "\n",
      "Removed 24 stopwords\n",
      "---\n",
      "\n",
      "Removed 13 stopwords\n",
      "---\n",
      "\n",
      "Removed 57 stopwords\n",
      "---\n",
      "\n",
      "Removed 84 stopwords\n",
      "---\n",
      "\n",
      "Removed 78 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n",
      "\n",
      "Removed 32 stopwords\n",
      "---\n",
      "\n",
      "Removed 185 stopwords\n",
      "---\n",
      "\n",
      "Removed 48 stopwords\n",
      "---\n",
      "\n",
      "Removed 150 stopwords\n",
      "---\n",
      "\n",
      "Removed 385 stopwords\n",
      "---\n",
      "\n",
      "Removed 561 stopwords\n",
      "---\n",
      "\n",
      "Removed 58 stopwords\n",
      "---\n",
      "\n",
      "Removed 64 stopwords\n",
      "---\n",
      "\n",
      "Removed 113 stopwords\n",
      "---\n",
      "\n",
      "Removed 110 stopwords\n",
      "---\n",
      "\n",
      "Removed 285 stopwords\n",
      "---\n",
      "\n",
      "Removed 33 stopwords\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "df = wrangle.prep_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "890d0e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_txt</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>homerchen19/nba-go</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>&lt;p align=center&gt;\\n&lt;img src=\"https://user-image...</td>\n",
       "      <td>p aligncenter img srchttpsuserimagesgithubuser...</td>\n",
       "      <td>p aligncent img srchttpsuserimagesgithubuserco...</td>\n",
       "      <td>p aligncenter img srchttpsuserimagesgithubuser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hegaojian/JetpackMvvm</td>\n",
       "      <td>Kotlin</td>\n",
       "      <td>[![Platform][1]][2] [![GitHub license][3]][4] ...</td>\n",
       "      <td>platform12 github license34 github license56 1...</td>\n",
       "      <td>platform12 github license34 github license56 1...</td>\n",
       "      <td>platform12 github license34 github license56 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>naoyashiga/Dunk</td>\n",
       "      <td>Swift</td>\n",
       "      <td># Dunk\\n![](https://raw.githubusercontent.com/...</td>\n",
       "      <td>dunk httpsrawgithubusercontentcomnaoyashigadun...</td>\n",
       "      <td>dunk httpsrawgithubusercontentcomnaoyashigadun...</td>\n",
       "      <td>dunk httpsrawgithubusercontentcomnaoyashigadun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>chonyy/AI-basketball-analysis</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;p align=center&gt;\\n    &lt;img src=\"./static/img/a...</td>\n",
       "      <td>p aligncenter img srcstaticimganalysisgif widt...</td>\n",
       "      <td>p aligncent img srcstaticimganalysisgif width9...</td>\n",
       "      <td>p aligncenter img srcstaticimganalysisgif widt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>bttmly/nba</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># nba\\n*Node.js client for nba.com API endpoin...</td>\n",
       "      <td>nba nodejs client nbacom api endpoints npm ins...</td>\n",
       "      <td>nba nodej client nbacom api endpoint npm insta...</td>\n",
       "      <td>nba nodejs client nbacom api endpoint npm inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>smuyyh/SprintNBA</td>\n",
       "      <td>Java</td>\n",
       "      <td># :basketball: SprintNBA\\n\\n## 完整的NBA第三方Androi...</td>\n",
       "      <td>basketball sprintnba nbaandroidnba apinbanbanb...</td>\n",
       "      <td>basketbal sprintnba nbaandroidnba apinbanbanba...</td>\n",
       "      <td>basketball sprintnba nbaandroidnba apinbanbanb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>linouk23/NBA-Player-Movements</td>\n",
       "      <td>Python</td>\n",
       "      <td># NBA Player Movements\\n\\nThis is a script for...</td>\n",
       "      <td>nba player movements script visualization nba ...</td>\n",
       "      <td>nba player movement script visual nba game raw...</td>\n",
       "      <td>nba player movement script visualization nba g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>FaridSafi/react-native-basketball</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># react-native-basketball\\n\\nReact-Native clon...</td>\n",
       "      <td>reactnativebasketball reactnative clone facebo...</td>\n",
       "      <td>reactnativebasketbal reactn clone facebook bas...</td>\n",
       "      <td>reactnativebasketball reactnative clone facebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>TryKickoff/kickoff</td>\n",
       "      <td>CSS</td>\n",
       "      <td>![Kickoff](http://i.imgur.com/bfMlVwe.jpg)\\n\\n...</td>\n",
       "      <td>kickoffhttpiimgurcombfmlvwejpg lightweight fro...</td>\n",
       "      <td>kickoffhttpiimgurcombfmlvwejpg lightweight fro...</td>\n",
       "      <td>kickoffhttpiimgurcombfmlvwejpg lightweight fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>kshvmdn/nba.js</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>## nba.js\\n\\n[![npm version](https://badge.fur...</td>\n",
       "      <td>nbajs npm versionhttpsbadgefuryiojsnbajssvghtt...</td>\n",
       "      <td>nbaj npm versionhttpsbadgefuryiojsnbajssvghttp...</td>\n",
       "      <td>nbajs npm versionhttpsbadgefuryiojsnbajssvghtt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>jaebradley/basketball_reference_web_scraper</td>\n",
       "      <td>HTML</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n    &lt;a href=\"#\" target=\"_b...</td>\n",
       "      <td>p aligncenter href targetblank relnoopener nor...</td>\n",
       "      <td>p aligncent href targetblank relnoopen norefer...</td>\n",
       "      <td>p aligncenter href targetblank relnoopener nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>cwendt94/espn-api</td>\n",
       "      <td>Python</td>\n",
       "      <td>![](https://github.com/cwendt94/espn-api/workf...</td>\n",
       "      <td>httpsgithubcomcwendt94espnapiworkflowsespn20ap...</td>\n",
       "      <td>httpsgithubcomcwendt94espnapiworkflowsespn20ap...</td>\n",
       "      <td>httpsgithubcomcwendt94espnapiworkflowsespn20ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>zengm-games/zengm</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td># Basketball GM, Football GM, ZenGM Baseball, ...</td>\n",
       "      <td>basketball gm football gm zengm baseball zengm...</td>\n",
       "      <td>basketbal gm footbal gm zengm basebal zengm ho...</td>\n",
       "      <td>basketball gm football gm zengm baseball zengm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>jrbadiabo/Bet-on-Sibyl</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>======================![Sibyl Logo](Images/Sib...</td>\n",
       "      <td>sibyl logoimagessibylwhitelogopng sport game o...</td>\n",
       "      <td>sibyl logoimagessibylwhitelogopng sport game o...</td>\n",
       "      <td>sibyl logoimagessibylwhitelogopng sport game o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>stephanj/basketballVideoAnalysis</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Sports Video Analysis\\n\\nSee wiki page for [...</td>\n",
       "      <td>sports video analysis see wiki page detailshtt...</td>\n",
       "      <td>sport video analysi see wiki page detailshttps...</td>\n",
       "      <td>sport video analysis see wiki page detailshttp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>KengoA/fantasy-basketball</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>\\nNote (March 2022) This repository is under m...</td>\n",
       "      <td>note march 2022 repository major refactoring n...</td>\n",
       "      <td>note march 2022 repositori major refactor nba ...</td>\n",
       "      <td>note march 2022 repository major refactoring n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>vishaalagartha/basketball_reference_scraper</td>\n",
       "      <td>Python</td>\n",
       "      <td># basketball_reference_scraper\\n\\n[Basketball ...</td>\n",
       "      <td>basketballreferencescraper basketball referenc...</td>\n",
       "      <td>basketballreferencescrap basketbal referenceht...</td>\n",
       "      <td>basketballreferencescraper basketball referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>xwjdsh/nba-live</td>\n",
       "      <td>Go</td>\n",
       "      <td>```text\\n          __                ___      ...</td>\n",
       "      <td>text releasehttpgithubreleaseversionherokuappc...</td>\n",
       "      <td>text releasehttpgithubreleaseversionherokuappc...</td>\n",
       "      <td>text releasehttpgithubreleaseversionherokuappc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>neeilan/DeepPlayByPlay</td>\n",
       "      <td>Python</td>\n",
       "      <td># Deep Play-by-Play\\n\\nThis repo contains mode...</td>\n",
       "      <td>deep playbyplay repo contains model data colle...</td>\n",
       "      <td>deep playbyplay repo contain model data collec...</td>\n",
       "      <td>deep playbyplay repo contains model data colle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>lbenz730/ncaahoopR</td>\n",
       "      <td>R</td>\n",
       "      <td># ncaahoopR &lt;img src=\"figures/logo.png\" align=...</td>\n",
       "      <td>ncaahoopr img srcfigureslogopng alignright nca...</td>\n",
       "      <td>ncaahoopr img srcfigureslogopng alignright nca...</td>\n",
       "      <td>ncaahoopr img srcfigureslogopng alignright nca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                         repo          language  \\\n",
       "0            0                           homerchen19/nba-go        JavaScript   \n",
       "1            1                        hegaojian/JetpackMvvm            Kotlin   \n",
       "2            2                              naoyashiga/Dunk             Swift   \n",
       "3            3                chonyy/AI-basketball-analysis            Python   \n",
       "5            5                                   bttmly/nba        JavaScript   \n",
       "6            6                             smuyyh/SprintNBA              Java   \n",
       "7            7                linouk23/NBA-Player-Movements            Python   \n",
       "8            8            FaridSafi/react-native-basketball        JavaScript   \n",
       "9            9                           TryKickoff/kickoff               CSS   \n",
       "10          10                               kshvmdn/nba.js        JavaScript   \n",
       "11          11  jaebradley/basketball_reference_web_scraper              HTML   \n",
       "12          12                            cwendt94/espn-api            Python   \n",
       "14          14                            zengm-games/zengm        TypeScript   \n",
       "15          15                       jrbadiabo/Bet-on-Sibyl  Jupyter Notebook   \n",
       "16          16             stephanj/basketballVideoAnalysis  Jupyter Notebook   \n",
       "17          17                    KengoA/fantasy-basketball  Jupyter Notebook   \n",
       "18          18  vishaalagartha/basketball_reference_scraper            Python   \n",
       "20          20                              xwjdsh/nba-live                Go   \n",
       "21          21                       neeilan/DeepPlayByPlay            Python   \n",
       "22          22                           lbenz730/ncaahoopR                 R   \n",
       "\n",
       "                                           readme_txt  \\\n",
       "0   <p align=center>\\n<img src=\"https://user-image...   \n",
       "1   [![Platform][1]][2] [![GitHub license][3]][4] ...   \n",
       "2   # Dunk\\n![](https://raw.githubusercontent.com/...   \n",
       "3   <p align=center>\\n    <img src=\"./static/img/a...   \n",
       "5   # nba\\n*Node.js client for nba.com API endpoin...   \n",
       "6   # :basketball: SprintNBA\\n\\n## 完整的NBA第三方Androi...   \n",
       "7   # NBA Player Movements\\n\\nThis is a script for...   \n",
       "8   # react-native-basketball\\n\\nReact-Native clon...   \n",
       "9   ![Kickoff](http://i.imgur.com/bfMlVwe.jpg)\\n\\n...   \n",
       "10  ## nba.js\\n\\n[![npm version](https://badge.fur...   \n",
       "11  <p align=\"center\">\\n    <a href=\"#\" target=\"_b...   \n",
       "12  ![](https://github.com/cwendt94/espn-api/workf...   \n",
       "14  # Basketball GM, Football GM, ZenGM Baseball, ...   \n",
       "15  ======================![Sibyl Logo](Images/Sib...   \n",
       "16  # Sports Video Analysis\\n\\nSee wiki page for [...   \n",
       "17  \\nNote (March 2022) This repository is under m...   \n",
       "18  # basketball_reference_scraper\\n\\n[Basketball ...   \n",
       "20  ```text\\n          __                ___      ...   \n",
       "21  # Deep Play-by-Play\\n\\nThis repo contains mode...   \n",
       "22  # ncaahoopR <img src=\"figures/logo.png\" align=...   \n",
       "\n",
       "                                                clean  \\\n",
       "0   p aligncenter img srchttpsuserimagesgithubuser...   \n",
       "1   platform12 github license34 github license56 1...   \n",
       "2   dunk httpsrawgithubusercontentcomnaoyashigadun...   \n",
       "3   p aligncenter img srcstaticimganalysisgif widt...   \n",
       "5   nba nodejs client nbacom api endpoints npm ins...   \n",
       "6   basketball sprintnba nbaandroidnba apinbanbanb...   \n",
       "7   nba player movements script visualization nba ...   \n",
       "8   reactnativebasketball reactnative clone facebo...   \n",
       "9   kickoffhttpiimgurcombfmlvwejpg lightweight fro...   \n",
       "10  nbajs npm versionhttpsbadgefuryiojsnbajssvghtt...   \n",
       "11  p aligncenter href targetblank relnoopener nor...   \n",
       "12  httpsgithubcomcwendt94espnapiworkflowsespn20ap...   \n",
       "14  basketball gm football gm zengm baseball zengm...   \n",
       "15  sibyl logoimagessibylwhitelogopng sport game o...   \n",
       "16  sports video analysis see wiki page detailshtt...   \n",
       "17  note march 2022 repository major refactoring n...   \n",
       "18  basketballreferencescraper basketball referenc...   \n",
       "20  text releasehttpgithubreleaseversionherokuappc...   \n",
       "21  deep playbyplay repo contains model data colle...   \n",
       "22  ncaahoopr img srcfigureslogopng alignright nca...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "0   p aligncent img srchttpsuserimagesgithubuserco...   \n",
       "1   platform12 github license34 github license56 1...   \n",
       "2   dunk httpsrawgithubusercontentcomnaoyashigadun...   \n",
       "3   p aligncent img srcstaticimganalysisgif width9...   \n",
       "5   nba nodej client nbacom api endpoint npm insta...   \n",
       "6   basketbal sprintnba nbaandroidnba apinbanbanba...   \n",
       "7   nba player movement script visual nba game raw...   \n",
       "8   reactnativebasketbal reactn clone facebook bas...   \n",
       "9   kickoffhttpiimgurcombfmlvwejpg lightweight fro...   \n",
       "10  nbaj npm versionhttpsbadgefuryiojsnbajssvghttp...   \n",
       "11  p aligncent href targetblank relnoopen norefer...   \n",
       "12  httpsgithubcomcwendt94espnapiworkflowsespn20ap...   \n",
       "14  basketbal gm footbal gm zengm basebal zengm ho...   \n",
       "15  sibyl logoimagessibylwhitelogopng sport game o...   \n",
       "16  sport video analysi see wiki page detailshttps...   \n",
       "17  note march 2022 repositori major refactor nba ...   \n",
       "18  basketballreferencescrap basketbal referenceht...   \n",
       "20  text releasehttpgithubreleaseversionherokuappc...   \n",
       "21  deep playbyplay repo contain model data collec...   \n",
       "22  ncaahoopr img srcfigureslogopng alignright nca...   \n",
       "\n",
       "                                           lemmatized  \n",
       "0   p aligncenter img srchttpsuserimagesgithubuser...  \n",
       "1   platform12 github license34 github license56 1...  \n",
       "2   dunk httpsrawgithubusercontentcomnaoyashigadun...  \n",
       "3   p aligncenter img srcstaticimganalysisgif widt...  \n",
       "5   nba nodejs client nbacom api endpoint npm inst...  \n",
       "6   basketball sprintnba nbaandroidnba apinbanbanb...  \n",
       "7   nba player movement script visualization nba g...  \n",
       "8   reactnativebasketball reactnative clone facebo...  \n",
       "9   kickoffhttpiimgurcombfmlvwejpg lightweight fro...  \n",
       "10  nbajs npm versionhttpsbadgefuryiojsnbajssvghtt...  \n",
       "11  p aligncenter href targetblank relnoopener nor...  \n",
       "12  httpsgithubcomcwendt94espnapiworkflowsespn20ap...  \n",
       "14  basketball gm football gm zengm baseball zengm...  \n",
       "15  sibyl logoimagessibylwhitelogopng sport game o...  \n",
       "16  sport video analysis see wiki page detailshttp...  \n",
       "17  note march 2022 repository major refactoring n...  \n",
       "18  basketballreferencescraper basketball referenc...  \n",
       "20  text releasehttpgithubreleaseversionherokuappc...  \n",
       "21  deep playbyplay repo contains model data colle...  \n",
       "22  ncaahoopr img srcfigureslogopng alignright nca...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a03b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'acquire' from '/Users/sinao/codeup-data-science/natural-language-processing-exercises/acquire.py'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(acquire)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
